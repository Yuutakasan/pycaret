#!/usr/bin/env python3
"""
RAPIDS + PyCaret GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
=========================================
GPUã€CUDAã€RAPIDSã€PyCaretã€é–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç’°å¢ƒã‚’åŒ…æ‹¬çš„ã«ãƒã‚§ãƒƒã‚¯
"""

import subprocess
import sys
import warnings

warnings.filterwarnings('ignore')

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›ç”¨
class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'

def print_header(title):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤º"""
    print(f"\n{Colors.BLUE}{Colors.BOLD}{'='*60}{Colors.ENDC}")
    print(f"{Colors.BLUE}{Colors.BOLD}{title:^60}{Colors.ENDC}")
    print(f"{Colors.BLUE}{Colors.BOLD}{'='*60}{Colors.ENDC}")

def check_status(condition, success_msg, fail_msg):
    """æ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦çµæœã‚’è¡¨ç¤º"""
    if condition:
        print(f"{Colors.GREEN}âœ… {success_msg}{Colors.ENDC}")
        return True
    else:
        print(f"{Colors.RED}âŒ {fail_msg}{Colors.ENDC}")
        return False

def check_gpu_hardware():
    """GPU ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®ãƒã‚§ãƒƒã‚¯"""
    print_header("GPU ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒã‚§ãƒƒã‚¯")

    try:
        # nvidia-smiã®å®Ÿè¡Œ
        result = subprocess.run(['nvidia-smi', '--query-gpu=index,name,memory.total,driver_version',
                               '--format=csv,noheader'],
                               capture_output=True, text=True)

        if result.returncode == 0:
            print(f"{Colors.GREEN}âœ… GPUæ¤œå‡ºæˆåŠŸ:{Colors.ENDC}")
            for line in result.stdout.strip().split('\n'):
                parts = [p.strip() for p in line.split(',')]
                print(f"   GPU {parts[0]}: {parts[1]} (VRAM: {parts[2]}, Driver: {parts[3]})")
            return True
        else:
            print(f"{Colors.RED}âŒ GPUãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ{Colors.ENDC}")
            return False
    except FileNotFoundError:
        print(f"{Colors.RED}âŒ nvidia-smiãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“{Colors.ENDC}")
        return False

def check_cuda_environment():
    """CUDAç’°å¢ƒã®ãƒã‚§ãƒƒã‚¯"""
    print_header("CUDAç’°å¢ƒãƒã‚§ãƒƒã‚¯")

    success = True

    # CUDAãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒã‚§ãƒƒã‚¯
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        if cuda_available:
            print(f"{Colors.GREEN}âœ… PyTorch CUDA: åˆ©ç”¨å¯èƒ½ (CUDA {torch.version.cuda}){Colors.ENDC}")
            print(f"   ãƒ‡ãƒã‚¤ã‚¹æ•°: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   ãƒ‡ãƒã‚¤ã‚¹{i}: {torch.cuda.get_device_name(i)}")
        else:
            print(f"{Colors.YELLOW}âš ï¸  PyTorch CUDA: åˆ©ç”¨ä¸å¯{Colors.ENDC}")
            success = False
    except ImportError:
        print(f"{Colors.YELLOW}âš ï¸  PyTorchãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“{Colors.ENDC}")

    # CuPyãƒã‚§ãƒƒã‚¯
    try:
        import cupy as cp
        print(f"{Colors.GREEN}âœ… CuPy: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {cp.__version__}{Colors.ENDC}")

        # GPUãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
        try:
            cp.cuda.MemoryPool(cp.cuda.malloc_managed)
            print(f"   ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«: åˆæœŸåŒ–æˆåŠŸ")
        except Exception as e:
            print(f"   ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«: åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ - {e}")
    except ImportError:
        print(f"{Colors.RED}âŒ CuPyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“{Colors.ENDC}")
        success = False

    # Numbaãƒã‚§ãƒƒã‚¯
    try:
        from numba import cuda
        print(f"{Colors.GREEN}âœ… Numba CUDA: åˆ©ç”¨å¯èƒ½{Colors.ENDC}")
        if cuda.is_available():
            print(f"   ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡º: OK")
    except ImportError:
        print(f"{Colors.YELLOW}âš ï¸  Numba CUDAãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“{Colors.ENDC}")

    return success

def check_rapids_libraries():
    """RAPIDSãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒã‚§ãƒƒã‚¯"""
    print_header("RAPIDSãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯")

    rapids_libs = {
        'cudf': None,
        'cuml': None,
        'cugraph': None,
        'cuspatial': None,
        'cuxfilter': None,
        'cupy': None,
        'dask_cuda': None
    }

    success = True

    for lib_name in rapids_libs:
        try:
            lib = __import__(lib_name)
            version = getattr(lib, '__version__', 'Unknown')
            rapids_libs[lib_name] = version
            print(f"{Colors.GREEN}âœ… {lib_name}: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {version}{Colors.ENDC}")
        except ImportError:
            print(f"{Colors.YELLOW}âš ï¸  {lib_name}: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«{Colors.ENDC}")
            if lib_name in ['cudf', 'cuml']:
                success = False

    # cudf.pandasã®ãƒã‚§ãƒƒã‚¯
    try:
        import cudf.pandas
        print(f"{Colors.GREEN}âœ… cudf.pandas: åˆ©ç”¨å¯èƒ½{Colors.ENDC}")
    except ImportError:
        print(f"{Colors.YELLOW}âš ï¸  cudf.pandas: åˆ©ç”¨ä¸å¯{Colors.ENDC}")

    return success

def check_pycaret_gpu():
    """PyCaretã®GPUå¯¾å¿œãƒã‚§ãƒƒã‚¯"""
    print_header("PyCaret GPUå¯¾å¿œãƒã‚§ãƒƒã‚¯")

    try:
        import pycaret
        print(f"{Colors.GREEN}âœ… PyCaret: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {pycaret.__version__}{Colors.ENDC}")

        # GPUå¯¾å¿œã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒã‚§ãƒƒã‚¯
        gpu_algorithms = {
            'xgboost': 'XGBoost',
            'lightgbm': 'LightGBM',
            'catboost': 'CatBoost'
        }

        print(f"\n{Colors.BOLD}GPUå¯¾å¿œã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :{Colors.ENDC}")
        for module, name in gpu_algorithms.items():
            try:
                lib = __import__(module)
                version = getattr(lib, '__version__', 'Unknown')
                print(f"{Colors.GREEN}âœ… {name}: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {version}{Colors.ENDC}")

                # XGBoostã®GPUç¢ºèª
                if module == 'xgboost':
                    try:
                        import xgboost as xgb

                        # GPUå¯¾å¿œã®ç¢ºèªï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰
                        print(f"   GPUå¯¾å¿œ: device='cuda'ã§åˆ©ç”¨å¯èƒ½")
                    except Exception:
                        pass

            except ImportError:
                print(f"{Colors.YELLOW}âš ï¸  {name}: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«{Colors.ENDC}")

        return True
    except ImportError:
        print(f"{Colors.RED}âŒ PyCaretãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“{Colors.ENDC}")
        return False

def check_analysis_tools():
    """åˆ†æãƒ„ãƒ¼ãƒ«ã®ãƒã‚§ãƒƒã‚¯"""
    print_header("åˆ†æãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯")

    tools = {
        'autoviz': 'AutoViz',
        'explainerdashboard': 'ExplainerDashboard',
        'shap': 'SHAP',
        'interpret': 'InterpretML',
        'ydata_profiling': 'YData Profiling',
        'japanize_matplotlib': 'æ—¥æœ¬èªMatplotlib'
    }

    all_installed = True

    for module, name in tools.items():
        try:
            lib = __import__(module)
            version = getattr(lib, '__version__', 'OK')
            print(f"{Colors.GREEN}âœ… {name}: {version}{Colors.ENDC}")

            # SHAPã®GPUç¢ºèª
            if module == 'shap':
                try:
                    from shap.explainers import GPUTree
                    print(f"   GPU TreeExplainer: åˆ©ç”¨å¯èƒ½")
                except ImportError:
                    print(f"   GPU TreeExplainer: åˆ©ç”¨ä¸å¯")

        except ImportError:
            print(f"{Colors.YELLOW}âš ï¸  {name}: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«{Colors.ENDC}")
            all_installed = False

    return all_installed

def check_memory_info():
    """ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®ãƒã‚§ãƒƒã‚¯"""
    print_header("ãƒ¡ãƒ¢ãƒªæƒ…å ±")

    # GPUãƒ¡ãƒ¢ãƒª
    try:
        import pynvml
        pynvml.nvmlInit()
        device_count = pynvml.nvmlDeviceGetCount()

        print(f"{Colors.BOLD}GPU ãƒ¡ãƒ¢ãƒª:{Colors.ENDC}")
        for i in range(device_count):
            handle = pynvml.nvmlDeviceGetHandleByIndex(i)
            info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            total_gb = info.total / (1024**3)
            used_gb = info.used / (1024**3)
            free_gb = info.free / (1024**3)

            print(f"  GPU {i}: åˆè¨ˆ {total_gb:.1f}GB, ä½¿ç”¨ {used_gb:.1f}GB, ç©ºã {free_gb:.1f}GB")
    except Exception as e:
        print(f"{Colors.YELLOW}âš ï¸  GPUãƒ¡ãƒ¢ãƒªæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“: {e}{Colors.ENDC}")

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª
    try:
        import psutil
        mem = psutil.virtual_memory()
        print(f"\n{Colors.BOLD}ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª:{Colors.ENDC}")
        print(f"  åˆè¨ˆ: {mem.total/(1024**3):.1f}GB")
        print(f"  ä½¿ç”¨: {mem.used/(1024**3):.1f}GB ({mem.percent:.1f}%)")
        print(f"  ç©ºã: {mem.available/(1024**3):.1f}GB")
    except ImportError:
        print(f"\n{Colors.YELLOW}âš ï¸  psutilãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“{Colors.ENDC}")

def test_gpu_computation():
    """GPUè¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
    print_header("GPUè¨ˆç®—ãƒ†ã‚¹ãƒˆ")

    # CuDFãƒ†ã‚¹ãƒˆ
    try:
        import time

        import cudf
        import numpy as np
        import pandas as pd

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        n = 1000000
        print(f"\n{Colors.BOLD}CuDFæ€§èƒ½ãƒ†ã‚¹ãƒˆ (n={n:,}):{Colors.ENDC}")

        # CPUç‰ˆ
        start = time.time()
        df_cpu = pd.DataFrame({
            'a': np.random.randn(n),
            'b': np.random.randn(n)
        })
        df_cpu['c'] = df_cpu['a'] + df_cpu['b']
        cpu_time = time.time() - start

        # GPUç‰ˆ
        start = time.time()
        df_gpu = cudf.DataFrame({
            'a': np.random.randn(n),
            'b': np.random.randn(n)
        })
        df_gpu['c'] = df_gpu['a'] + df_gpu['b']
        gpu_time = time.time() - start

        speedup = cpu_time / gpu_time
        print(f"  CPUæ™‚é–“: {cpu_time:.3f}ç§’")
        print(f"  GPUæ™‚é–“: {gpu_time:.3f}ç§’")
        print(f"  é«˜é€ŸåŒ–: {speedup:.1f}å€")

        check_status(speedup > 1, "GPUè¨ˆç®—ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™", "GPUè¨ˆç®—ãŒæœŸå¾…é€šã‚Šå‹•ä½œã—ã¦ã„ã¾ã›ã‚“")

    except Exception as e:
        print(f"{Colors.RED}âŒ GPUè¨ˆç®—ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}{Colors.ENDC}")

def print_recommendations():
    """æ¨å¥¨äº‹é …ã®è¡¨ç¤º"""
    print_header("æ¨å¥¨äº‹é …ã¨ãƒ’ãƒ³ãƒˆ")

    print(f"{Colors.BOLD}1. cudf.pandasã®ä½¿ç”¨:{Colors.ENDC}")
    print("   ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®æœ€åˆã«ä»¥ä¸‹ã‚’å®Ÿè¡Œ:")
    print("   %load_ext cudf.pandas")

    print(f"\n{Colors.BOLD}2. PyCaretã§GPUã‚’ä½¿ç”¨:{Colors.ENDC}")
    print("   setup(data, target='label', use_gpu=True)")

    print(f"\n{Colors.BOLD}3. ãƒ¡ãƒ¢ãƒªç®¡ç†:{Colors.ENDC}")
    print("   å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€ä»¥ä¸‹ã‚’è¨­å®š:")
    print("   import cudf")
    print("   cudf.set_option('spill', True)")

    print(f"\n{Colors.BOLD}4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°:{Colors.ENDC}")
    print("   nvtop ã¾ãŸã¯ nvidia-smi -l 1 ã§GPUä½¿ç”¨çŠ¶æ³ã‚’ç›£è¦–")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print(f"\n{Colors.BOLD}ğŸš€ RAPIDS + PyCaret GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯ã‚’é–‹å§‹ã—ã¾ã™...{Colors.ENDC}\n")

    # å„ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ
    checks = {
        "GPU ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢": check_gpu_hardware(),
        "CUDA ç’°å¢ƒ": check_cuda_environment(),
        "RAPIDS ãƒ©ã‚¤ãƒ–ãƒ©ãƒª": check_rapids_libraries(),
        "PyCaret GPUå¯¾å¿œ": check_pycaret_gpu(),
        "åˆ†æãƒ„ãƒ¼ãƒ«": check_analysis_tools()
    }

    # ãƒ¡ãƒ¢ãƒªæƒ…å ±
    check_memory_info()

    # GPUè¨ˆç®—ãƒ†ã‚¹ãƒˆ
    test_gpu_computation()

    # çµæœã‚µãƒãƒªãƒ¼
    print_header("ç’°å¢ƒãƒã‚§ãƒƒã‚¯çµæœã‚µãƒãƒªãƒ¼")

    all_passed = True
    for check_name, passed in checks.items():
        if passed:
            print(f"{Colors.GREEN}âœ… {check_name}: OK{Colors.ENDC}")
        else:
            print(f"{Colors.RED}âŒ {check_name}: NG{Colors.ENDC}")
            all_passed = False

    # æ¨å¥¨äº‹é …
    print_recommendations()

    # æœ€çµ‚çµæœ
    print(f"\n{Colors.BOLD}{'='*60}{Colors.ENDC}")
    if all_passed:
        print(f"{Colors.GREEN}{Colors.BOLD}âœ… GPUç’°å¢ƒã¯æ­£å¸¸ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ï¼{Colors.ENDC}")
        print(f"{Colors.GREEN}   é«˜é€ŸãªGPUæ©Ÿæ¢°å­¦ç¿’ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚{Colors.ENDC}")
    else:
        print(f"{Colors.YELLOW}{Colors.BOLD}âš ï¸  ä¸€éƒ¨ã®æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™{Colors.ENDC}")
        print(f"{Colors.YELLOW}   ä¸Šè¨˜ã®NGã®é …ç›®ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚{Colors.ENDC}")
    print(f"{Colors.BOLD}{'='*60}{Colors.ENDC}\n")

if __name__ == "__main__":
    main()
