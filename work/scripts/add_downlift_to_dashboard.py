#!/usr/bin/env python3
"""
åº—èˆ—åˆ¥åŒ…æ‹¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰_v6.1_ææ¡ˆå¼·åŒ–.ipynb ã«downliftåˆ†æã‚»ãƒ«ã‚’è¿½åŠ 
"""

import json
from pathlib import Path

# Downliftåˆ†æã‚»ãƒ«ã®ã‚³ãƒ¼ãƒ‰
downlift_cell_code = """# ========================================
# ğŸ“‰ Downliftåˆ†æï¼šå£²ä¸Šæ¸›å°‘è¦å› ã®ç‰¹å®š
# ========================================

print('\\n' + '='*80)
print('ğŸ“‰ Downliftåˆ†æï¼šãƒˆãƒªã‚¬ãƒ¼åˆ¥ã®å£²ä¸Šæ¸›å°‘ã‚«ãƒ†ã‚´ãƒª')
print('='*80)

# é™é›¨æ™‚ã«å£²ä¸ŠãŒæ¸›å°‘ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªï¼ˆdownliftï¼‰
downlift_results = {}

for trigger_col in ['é™é›¨ãƒ•ãƒ©ã‚°', 'é€±æœ«ãƒ•ãƒ©ã‚°', 'çŒ›æš‘æ—¥', 'çœŸå¤æ—¥', 'å¤æ—¥', 'çµ¦æ–™æ—¥', 'çµ¦æ–™æ—¥ç›´å¾Œ', 'æœˆåˆ3æ—¥', 'æœˆæœ«3æ—¥']:
    if trigger_col not in df.columns:
        continue

    # ãƒˆãƒªã‚¬ãƒ¼ON/OFFæ™‚ã®å£²ä¸Šæ¯”è¼ƒï¼ˆdownlift: flag1 < flag0ï¼‰
    comparison = df.groupby([trigger_col, 'category_l'], as_index=False)['å£²ä¸Šé‡‘é¡'].mean()

    pivot = comparison.pivot_table(
        index='category_l',
        columns=trigger_col,
        values='å£²ä¸Šé‡‘é¡',
        aggfunc='mean'
    )

    if 1.0 not in pivot.columns or 0.0 not in pivot.columns:
        continue

    # Downliftè¨ˆç®—ï¼š(OFF - ON) / OFF ï¼ˆæ­£ã®å€¤ = å£²ä¸Šæ¸›å°‘ï¼‰
    pivot['downlift'] = (pivot[0.0] - pivot[1.0]) / pivot[0.0]

    # å£²ä¸Šæ¸›å°‘ãŒå¤§ãã„é †ï¼ˆdownlift > 0.1 = 10%ä»¥ä¸Šæ¸›å°‘ï¼‰
    significant_down = pivot[pivot['downlift'] > 0.1].copy()

    if len(significant_down) > 0:
        significant_down = significant_down.sort_values('downlift', ascending=False)
        significant_down = significant_down.rename(columns={
            0.0: 'sales_amt_flag0',
            1.0: 'sales_amt_flag1'
        })

        downlift_results[trigger_col] = significant_down[['sales_amt_flag1', 'sales_amt_flag0', 'downlift']].head(5)

# ========================================
# çµæœè¡¨ç¤º
# ========================================

if downlift_results:
    print('\\n--- ææ¡ˆï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šæ¸›å°‘ãŒå¤§ãã„é †ï¼‰---')
    for trigger_key, result_df in downlift_results.items():
        if len(result_df) > 0:
            print(f'\\n[ææ¡ˆã‚­ãƒ¼: {trigger_key}]')
            print(result_df.reset_index().to_string(index=False))

    print('\\n' + '='*80)
    print('ğŸ’¡ Downliftæ´»ç”¨æ–¹æ³•')
    print('='*80)
    print('''
ã€åœ¨åº«æœ€é©åŒ–ã€‘
- é™é›¨æ™‚ã«å£²ä¸ŠãŒæ¸›ã‚‹ã‚«ãƒ†ã‚´ãƒª â†’ é›¨äºˆå ±ã®æ—¥ã¯ç™ºæ³¨ã‚’æ§ãˆã‚‹
- é€±æœ«ã«å£²ä¸ŠãŒæ¸›ã‚‹ã‚«ãƒ†ã‚´ãƒª â†’ å¹³æ—¥ã«åœ¨åº«ã‚’åšãã™ã‚‹

ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ä¼ç”»ã€‘
- å£²ä¸Šæ¸›å°‘ã‚«ãƒ†ã‚´ãƒªã«å¯¾ã—ã¦ã€Œé›¨ã®æ—¥å‰²å¼•ã€ã€Œé€±æœ«ç‰¹å£²ã€ãªã©ã§éœ€è¦å–šèµ·
- ä¾‹ï¼šé™é›¨æ™‚10%æ¸›ã®ã‚«ãƒ†ã‚´ãƒª â†’ é›¨ã®æ—¥10%å‰²å¼•ã§éœ€è¦ã‚’ç¶­æŒ

ã€è²©å£²è¨ˆç”»ã€‘
- Downliftç‡ã‚’è€ƒæ…®ã—ãŸå£²ä¸Šäºˆæ¸¬ï¼ˆä¿å®ˆçš„è¦‹ç©ã‚‚ã‚Šï¼‰
- ä¾‹ï¼šçµ¦æ–™æ—¥ç›´å¾Œ-15%ã€æœˆæœ«-20%ãªã©å­£ç¯€å¤‰å‹•ã‚’åæ˜ 
    ''')
else:
    print('\\nâš ï¸ æœ‰æ„ãªdownliftï¼ˆå£²ä¸Šæ¸›å°‘10%ä»¥ä¸Šï¼‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ')

# ========================================
# ğŸ“Š Uplift vs Downliftã®çµ±åˆãƒ“ãƒ¥ãƒ¼
# ========================================

print('\\n' + '='*80)
print('ğŸ“Š çµ±åˆåˆ†æï¼šUplift + Downlift')
print('='*80)

# ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å£²ä¸Šå¤‰å‹•å¹…ã‚’è¨ˆç®—
category_volatility = []

for category in df['category_l'].dropna().unique():
    cat_data = df[df['category_l'] == category]

    max_uplifts = []
    max_downlifts = []

    for trigger_col in ['é™é›¨ãƒ•ãƒ©ã‚°', 'é€±æœ«ãƒ•ãƒ©ã‚°', 'çŒ›æš‘æ—¥', 'çœŸå¤æ—¥', 'å¤æ—¥']:
        if trigger_col not in df.columns:
            continue

        comparison = cat_data.groupby(trigger_col)['å£²ä¸Šé‡‘é¡'].mean()

        if 1.0 in comparison.index and 0.0 in comparison.index:
            uplift = (comparison[1.0] - comparison[0.0]) / comparison[0.0]
            downlift = (comparison[0.0] - comparison[1.0]) / comparison[0.0]

            max_uplifts.append(max(0, uplift))
            max_downlifts.append(max(0, downlift))

    if max_uplifts and max_downlifts:
        category_volatility.append({
            'ã‚«ãƒ†ã‚´ãƒª': category,
            'æœ€å¤§Uplift': max(max_uplifts),
            'æœ€å¤§Downlift': max(max_downlifts),
            'å£²ä¸Šå¤‰å‹•å¹…': max(max_uplifts) + max(max_downlifts),
            'äºˆæ¸¬é›£æ˜“åº¦': 'A:é«˜é›£æ˜“åº¦' if (max(max_uplifts) + max(max_downlifts)) > 1.5 else
                         'B:ä¸­é›£æ˜“åº¦' if (max(max_uplifts) + max(max_downlifts)) > 0.5 else
                         'C:ä½é›£æ˜“åº¦'
        })

volatility_df = pd.DataFrame(category_volatility).sort_values('å£²ä¸Šå¤‰å‹•å¹…', ascending=False)

print('\\nã€ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šå¤‰å‹•å¹…ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆTop 10ï¼‰ã€‘')
print(volatility_df.head(10).to_string(index=False))

print('\\nğŸ’¡ äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ¨å¥¨æˆ¦ç•¥:')
print('  A:é«˜é›£æ˜“åº¦ï¼ˆå¤‰å‹•å¹…1.5å€ä»¥ä¸Šï¼‰ â†’ å€‹åˆ¥ãƒ¢ãƒ‡ãƒ« + ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¼·åŒ–')
print('  B:ä¸­é›£æ˜“åº¦ï¼ˆå¤‰å‹•å¹…0.5-1.5å€ï¼‰ â†’ ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¢ãƒ‡ãƒ«')
print('  C:ä½é›£æ˜“åº¦ï¼ˆå¤‰å‹•å¹…0.5å€æœªæº€ï¼‰ â†’ çµ±åˆãƒ¢ãƒ‡ãƒ«ã§OK')

# CSVä¿å­˜
output_path = Path('output/category_uplift_downlift_analysis.csv')
volatility_df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f'\\nâœ… åˆ†æçµæœã‚’ä¿å­˜: {output_path}')
"""

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯èª­ã¿è¾¼ã¿
notebook_path = Path('/mnt/d/github/pycaret/work/åº—èˆ—åˆ¥åŒ…æ‹¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰_v6.1_ææ¡ˆå¼·åŒ–.ipynb')

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Upliftåˆ†æã‚»ãƒ«ã‚’æ¢ã™
uplift_cell_index = None
for i, cell in enumerate(nb['cells']):
    if cell['cell_type'] == 'code':
        source = ''.join(cell['source'])
        if 'ææ¡ˆã‚­ãƒ¼' in source and 'uplift' in source and 'category_l' in source:
            uplift_cell_index = i
            print(f"âœ… Upliftåˆ†æã‚»ãƒ«ã‚’æ¤œå‡º: Cell {i}")
            break

if uplift_cell_index is not None:
    # Upliftã‚»ãƒ«ã®ç›´å¾Œã«Downliftã‚»ãƒ«ã‚’æŒ¿å…¥
    new_cell = {
        'cell_type': 'code',
        'execution_count': None,
        'id': 'downlift_analysis_cell',
        'metadata': {},
        'outputs': [],
        'source': downlift_cell_code.split('\n')
    }

    # å„è¡Œã«æ”¹è¡Œã‚’è¿½åŠ ï¼ˆæœ€å¾Œã®è¡Œä»¥å¤–ï¼‰
    new_cell['source'] = [line + '\n' if i < len(new_cell['source'])-1 else line
                         for i, line in enumerate(new_cell['source'])]

    nb['cells'].insert(uplift_cell_index + 1, new_cell)

    # ä¿å­˜
    with open(notebook_path, 'w', encoding='utf-8') as f:
        json.dump(nb, f, ensure_ascii=False, indent=1)

    print(f"âœ… Downliftåˆ†æã‚»ãƒ«ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼ˆCell {uplift_cell_index + 1}ï¼‰")
    print(f"âœ… ä¿å­˜å®Œäº†: {notebook_path}")
else:
    print("âš ï¸ Upliftåˆ†æã‚»ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    print("æ‰‹å‹•ã§Downliftã‚»ãƒ«ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")

    # ã‚³ãƒ¼ãƒ‰ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    code_path = Path('scripts/downlift_analysis_code.py')
    with open(code_path, 'w', encoding='utf-8') as f:
        f.write(downlift_cell_code)
    print(f"ğŸ“ Downliftåˆ†æã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜: {code_path}")
