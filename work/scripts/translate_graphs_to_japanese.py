#!/usr/bin/env python3
"""
ã‚°ãƒ©ãƒ•ã®æ—¥æœ¬èªåŒ–ã¨æ³¨é‡ˆè¿½åŠ ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„:
1. å…¨ã‚°ãƒ©ãƒ•ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ãƒ©ãƒ™ãƒ«ã‚’æ—¥æœ¬èªåŒ–
2. å„ã‚°ãƒ©ãƒ•ã«åˆ¤æ–­åŸºæº–ã®æ³¨é‡ˆã‚’è¿½åŠ 
3. æ—¥æœ¬äººã«ã‚ã‹ã‚Šã‚„ã™ã„è¡¨ç¾ã«çµ±ä¸€
"""

import json
import shutil
from pathlib import Path
from datetime import datetime


# è‹±èªâ†’æ—¥æœ¬èªã®ç¿»è¨³ãƒãƒƒãƒ”ãƒ³ã‚°
TRANSLATIONS = {
    # ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«
    'Executive Summary': 'çµŒå–¶ã‚µãƒãƒªãƒ¼',
    'Sales Trend': 'å£²ä¸Šæ¨ç§»',
    'YoY Growth': 'å‰å¹´æ¯”æˆé•·ç‡',
    'Avg Customer Spend': 'å¹³å‡å®¢å˜ä¾¡',
    'Feature Importance': 'ç‰¹å¾´é‡é‡è¦åº¦',
    'Sales Prediction': 'å£²ä¸Šäºˆæ¸¬',
    'Customer Count Trend': 'å®¢æ•°æ¨ç§»',
    'Avg Spend per Customer Trend': 'å®¢å˜ä¾¡æ¨ç§»',
    'Customer Count YoY Growth': 'å®¢æ•°å‰å¹´æ¯”',
    'Avg Spend YoY Growth': 'å®¢å˜ä¾¡å‰å¹´æ¯”',
    'Avg Daily Sales Comparison': 'å¹³å‡æ—¥å•†æ¯”è¼ƒ',
    'Gap from Top Store': 'ãƒˆãƒƒãƒ—åº—èˆ—ã¨ã®ã‚®ãƒ£ãƒƒãƒ—',

    # è»¸ãƒ©ãƒ™ãƒ«
    'Sales (JPY)': 'å£²ä¸Šé‡‘é¡ï¼ˆå††ï¼‰',
    'Sales': 'å£²ä¸Š',
    'Count': 'å®¢æ•°',
    'JPY': 'å††',
    'Importance Score': 'é‡è¦åº¦ã‚¹ã‚³ã‚¢',
    'Gap (JPY)': 'ã‚®ãƒ£ãƒƒãƒ—ï¼ˆå††ï¼‰',

    # å‡¡ä¾‹
    'Today': 'ä»Šå¹´',
    'Last Year': 'æ˜¨å¹´',
    'This Year': 'ä»Šå¹´',
    'Target': 'ç›®æ¨™',

    # ãã®ä»–
    'ALERTS': 'ã‚¢ãƒ©ãƒ¼ãƒˆ',
    'No Critical Alerts': 'é‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒˆãªã—',
    "KPIs (Latest)": 'ä¸»è¦æŒ‡æ¨™ï¼ˆæœ€æ–°ï¼‰',
    "TODAY'S ACTIONS": 'æœ¬æ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³',
    'Check TOP10 inventory': 'TOP10å•†å“ã®åœ¨åº«ç¢ºèª',
    'Adjust orders by weather': 'å¤©æ°—ã«å¿œã˜ãŸç™ºæ³¨èª¿æ•´',
    'Analyze YoY negative items': 'å‰å¹´æ¯”ãƒã‚¤ãƒŠã‚¹å•†å“ã®åˆ†æ',
    'Compare with other stores': 'ä»–åº—ã¨ã®æ¯”è¼ƒ',
}


def add_graph_annotations(source_code):
    """
    ã‚°ãƒ©ãƒ•ã‚³ãƒ¼ãƒ‰ã«æ—¥æœ¬èªã®æ³¨é‡ˆã¨ã‚¬ã‚¤ãƒ‰ã‚’è¿½åŠ 
    """
    annotations = []

    # ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã®æ³¨é‡ˆ
    if 'çµŒå–¶ã‚µãƒãƒªãƒ¼' in source_code or 'Executive Summary' in source_code:
        annotations.append("""
# ğŸ“Š ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹ã‚¬ã‚¤ãƒ‰
#
# ã€å£²ä¸Šæ¨ç§»ã‚°ãƒ©ãƒ•ã€‘ï¼ˆå·¦ä¸Šãƒ»å¤§ï¼‰
#   ãƒ»é’ç·šï¼ˆä»Šå¹´ï¼‰ãŒèµ¤ç·šï¼ˆæ˜¨å¹´ï¼‰ã‚ˆã‚Šä¸Š â†’ å¥½èª¿
#   ãƒ»é’ç·šãŒèµ¤ç‚¹ç·šï¼ˆç›®æ¨™ï¼‰ã‚’ä¸‹å›ã‚‹ â†’ è¦æ”¹å–„
#   âœ… åˆ¤æ–­åŸºæº–: æ˜¨å¹´æ¯”+5%ä»¥ä¸Šãªã‚‰å„ªç§€ã€-5%ä»¥ä¸‹ãªã‚‰å¯¾ç­–å¿…é ˆ
#
# ã€å‰å¹´æ¯”æˆé•·ç‡ã€‘ï¼ˆå³ä¸Šï¼‰
#   ãƒ»ç·‘ã®ãƒãƒ¼ â†’ ãƒ—ãƒ©ã‚¹æˆé•·ï¼ˆè‰¯å¥½ï¼‰
#   ãƒ»èµ¤ã®ãƒãƒ¼ â†’ ãƒã‚¤ãƒŠã‚¹æˆé•·ï¼ˆè¦æ³¨æ„ï¼‰
#   âœ… åˆ¤æ–­åŸºæº–: é€£ç¶š3æ—¥ä»¥ä¸Šèµ¤ãªã‚‰è¦å› åˆ†æãŒå¿…è¦
#
# ã€å¹³å‡å®¢å˜ä¾¡ã€‘ï¼ˆå³ä¸­ï¼‰
#   ãƒ»ç·šãŒä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ â†’ å®¢å˜ä¾¡å‘ä¸Šæ–½ç­–ãŒåŠ¹æœçš„
#   ãƒ»èµ¤ç‚¹ç·šï¼ˆå¹³å‡ï¼‰ã‚’ä¸‹å›ã‚‹ â†’ ã‚»ãƒƒãƒˆè²©å£²ãƒ»ã¾ã¨ã‚è²·ã„ä¿ƒé€²ãŒå¿…è¦
#   âœ… åˆ¤æ–­åŸºæº–: å¹³å‡Â±10%ã®ç¯„å›²å†…ãªã‚‰æ­£å¸¸
""")

    # éœ€è¦äºˆæ¸¬ã®æ³¨é‡ˆ
    if 'ç‰¹å¾´é‡é‡è¦åº¦' in source_code or 'Feature Importance' in source_code:
        annotations.append("""
# ğŸ“Š ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹ã‚¬ã‚¤ãƒ‰
#
# ã€ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•ã€‘
#   ãƒ»æ£’ãŒé•·ã„é …ç›® â†’ å£²ä¸Šäºˆæ¸¬ã«å¤§ããå½±éŸ¿ã™ã‚‹è¦ç´ 
#   ãƒ»ä¸Šä½3ã¤ã®è¦ç´ ã«æ³¨ç›®ã—ã¦æ–½ç­–ã‚’è€ƒãˆã‚‹
#
#   ä¾‹ï¼‰ã€Œæœ€é«˜æ°—æ¸©ã€ãŒä¸Šä½ â†’ æ°—æ¸©ã«ã‚ˆã‚‹å•†å“å…¥æ›¿ãŒåŠ¹æœçš„
#       ã€Œæ›œæ—¥ã€ãŒä¸Šä½ â†’ æ›œæ—¥åˆ¥ã®å“æƒãˆå¤‰æ›´ãŒé‡è¦
#       ã€Œæ˜¨å¹´åŒæ—¥_å£²ä¸Šã€ãŒä¸Šä½ â†’ å‰å¹´ãƒ‡ãƒ¼ã‚¿ã‚’å‚è€ƒã«ã—ãŸç™ºæ³¨ãŒæœ‰åŠ¹
#
#   âœ… åˆ¤æ–­åŸºæº–: é‡è¦åº¦0.1ä»¥ä¸Šã®è¦ç´ ã«é›†ä¸­ã—ã¦å¯¾ç­–ã‚’æ‰“ã¤
""")

    # å®¢æ•°ãƒ»å®¢å˜ä¾¡åˆ†è§£ã®æ³¨é‡ˆ
    if 'å®¢æ•°æ¨ç§»' in source_code or 'Customer Count Trend' in source_code:
        annotations.append("""
# ğŸ“Š ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹ã‚¬ã‚¤ãƒ‰
#
# ã€å£²ä¸Šã®3è¦ç´ åˆ†è§£ã€‘
#   å£²ä¸Š = å®¢æ•° Ã— å®¢å˜ä¾¡ ã§åˆ†è§£ã—ã¦åŸå› ã‚’ç‰¹å®š
#
# ã€å®¢æ•°æ¨ç§»ã€‘ï¼ˆå·¦ä¸Šï¼‰
#   ãƒ»ä»Šå¹´ï¼ˆé’ï¼‰ãŒæ˜¨å¹´ï¼ˆç´«ç‚¹ç·šï¼‰ã‚’ä¸Šå›ã‚‹ â†’ é›†å®¢å¥½èª¿
#   ãƒ»ä¸‹å›ã‚‹ â†’ ãƒãƒ©ã‚·ãƒ»SNSãƒ»ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã§é›†å®¢å¼·åŒ–
#   âœ… åˆ¤æ–­åŸºæº–: å‰å¹´æ¯”-10%ä»¥ä¸‹ãªã‚‰å³åº§ã«é›†å®¢æ–½ç­–ãŒå¿…è¦
#
# ã€å®¢å˜ä¾¡æ¨ç§»ã€‘ï¼ˆå³ä¸Šï¼‰
#   ãƒ»ä»Šå¹´ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ï¼‰ãŒæ˜¨å¹´ã‚’ä¸Šå›ã‚‹ â†’ ã‚»ãƒƒãƒˆè²©å£²ç­‰ãŒåŠ¹æœçš„
#   ãƒ»ä¸‹å›ã‚‹ â†’ ã¾ã¨ã‚è²·ã„ä¿ƒé€²ãƒ»é–¢é€£å•†å“é™³åˆ—ãŒå¿…è¦
#   âœ… åˆ¤æ–­åŸºæº–: å‰å¹´æ¯”-5%ä»¥ä¸‹ãªã‚‰å•†å“æ§‹æˆã®è¦‹ç›´ã—ãŒå¿…è¦
#
# ã€å‰å¹´æ¯”ã‚°ãƒ©ãƒ•ã€‘ï¼ˆä¸‹æ®µï¼‰
#   ãƒ»ç·‘ â†’ ãƒ—ãƒ©ã‚¹ã€èµ¤ â†’ ãƒã‚¤ãƒŠã‚¹
#   ãƒ»ã©ã¡ã‚‰ãŒä¸»è¦å› ã‹ã‚’è¦‹æ¥µã‚ã¦å¯¾ç­–ã‚’æ‰“ã¤
""")

    # åº—èˆ—é–“æ¯”è¼ƒã®æ³¨é‡ˆ
    if 'å¹³å‡æ—¥å•†æ¯”è¼ƒ' in source_code or 'Daily Sales Comparison' in source_code:
        annotations.append("""
# ğŸ“Š ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹ã‚¬ã‚¤ãƒ‰
#
# ã€åº—èˆ—é–“æ¯”è¼ƒã€‘
#   ãƒ»èµ¤è‰² = ã‚ãªãŸã®åº—èˆ—ï¼ˆâ˜…ãƒãƒ¼ã‚¯ï¼‰
#   ãƒ»æ°´è‰² = ä»–åº—èˆ—
#
# ã€å¹³å‡æ—¥å•†æ¯”è¼ƒã€‘ï¼ˆå·¦ï¼‰
#   ãƒ»ä¸Šä½åº—èˆ—ã¨ã®å·® = æ”¹å–„ä½™åœ°
#   âœ… åˆ¤æ–­åŸºæº–:
#      - ãƒˆãƒƒãƒ—åº—ã®80%ä»¥ä¸Š â†’ å„ªç§€
#      - 60-80% â†’ æ”¹å–„ã®ä½™åœ°ã‚ã‚Š
#      - 60%æœªæº€ â†’ æŠœæœ¬çš„ãªè¦‹ç›´ã—ãŒå¿…è¦
#
# ã€å¹³å‡å®¢å˜ä¾¡æ¯”è¼ƒã€‘ï¼ˆä¸­ï¼‰
#   ãƒ»å®¢å˜ä¾¡ãŒä½ã„ â†’ ã‚»ãƒƒãƒˆè²©å£²ãƒ»é«˜å˜ä¾¡å•†å“ã®æ¨å¥¨è²©å£²
#   âœ… åˆ¤æ–­åŸºæº–: å…¨åº—å¹³å‡ã®90%ä»¥ä¸Šã‚’ç›®æ¨™
#
# ã€ãƒˆãƒƒãƒ—åº—ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ã€‘ï¼ˆå³ï¼‰
#   ãƒ»ã“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ã¨å¾—ã‚‰ã‚Œã‚‹å¢—åé¡
#   ãƒ»å…·ä½“çš„ãªæ”¹å–„æ–½ç­–: ãƒˆãƒƒãƒ—åº—ã®æˆåŠŸäº‹ä¾‹ã‚’çœŸä¼¼ã‚‹
""")

    return '\n'.join(annotations) + '\n\n' if annotations else ''


def translate_to_japanese(source_lines):
    """
    ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®è‹±èªè¡¨ç¾ã‚’æ—¥æœ¬èªã«ç¿»è¨³
    """
    modified = False
    new_lines = []

    for line in source_lines:
        original_line = line

        # ç¿»è¨³ãƒãƒƒãƒ”ãƒ³ã‚°ã«åŸºã¥ã„ã¦ç½®æ›
        for eng, jpn in TRANSLATIONS.items():
            if f"'{eng}'" in line or f'"{eng}"' in line:
                # ã‚¯ã‚©ãƒ¼ãƒˆä»˜ãã®æ–‡å­—åˆ—ã‚’ç½®æ›
                line = line.replace(f"'{eng}'", f"'{jpn}'")
                line = line.replace(f'"{eng}"', f'"{jpn}"')
                modified = True

        new_lines.append(line)

    return new_lines, modified


def process_notebook(notebook_path):
    """
    ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å…¨ä½“ã‚’å‡¦ç†ã—ã¦æ—¥æœ¬èªåŒ–ã¨æ³¨é‡ˆè¿½åŠ 
    """
    print(f"\n{'='*80}")
    print(f"ğŸ”§ å‡¦ç†ä¸­: {notebook_path.name}")
    print(f"{'='*80}")

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = notebook_path.with_suffix(f'.backup_jp_{timestamp}.ipynb')
    shutil.copy2(notebook_path, backup_path)
    print(f"   ğŸ“‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path.name}")

    try:
        # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯èª­ã¿è¾¼ã¿
        with open(notebook_path, 'r', encoding='utf-8') as f:
            nb = json.load(f)

        cells = nb['cells']
        translation_count = 0
        annotation_count = 0

        for cell in cells:
            if cell.get('cell_type') == 'code':
                source_lines = cell.get('source', [])
                source_code = ''.join(source_lines)

                # ã‚°ãƒ©ãƒ•ã‚³ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯
                is_graph_code = any(keyword in source_code for keyword in [
                    'plt.', 'ax.', 'fig.', 'subplot'
                ])

                if is_graph_code:
                    # æ³¨é‡ˆã‚’è¿½åŠ 
                    annotations = add_graph_annotations(source_code)
                    if annotations:
                        # ã‚»ãƒ«ã®å…ˆé ­ã«æ³¨é‡ˆã‚’è¿½åŠ 
                        source_lines = [annotations] + source_lines
                        annotation_count += 1

                    # è‹±èªã‚’æ—¥æœ¬èªã«ç¿»è¨³
                    source_lines, modified = translate_to_japanese(source_lines)
                    if modified:
                        translation_count += 1

                    cell['source'] = source_lines

        # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ä¿å­˜
        with open(notebook_path, 'w', encoding='utf-8') as f:
            json.dump(nb, f, ensure_ascii=False, indent=1)

        print(f"   âœ… ç¿»è¨³å®Œäº†: {translation_count}ã‚»ãƒ«")
        print(f"   âœ… æ³¨é‡ˆè¿½åŠ : {annotation_count}ã‚»ãƒ«")
        print(f"   âœ… å‡¦ç†å®Œäº†")
        return True

    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        shutil.copy2(backup_path, notebook_path)
        print(f"   ğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "="*80)
    print("ğŸŒ ã‚°ãƒ©ãƒ•æ—¥æœ¬èªåŒ– & æ³¨é‡ˆè¿½åŠ ã‚¹ã‚¯ãƒªãƒ—ãƒˆ v1.0")
    print("="*80)
    print("\nğŸ“‹ å®Ÿæ–½å†…å®¹:")
    print("   1. å…¨ã‚°ãƒ©ãƒ•ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ãƒ©ãƒ™ãƒ«ã‚’æ—¥æœ¬èªåŒ–")
    print("   2. å„ã‚°ãƒ©ãƒ•ã«ã€Œè¦‹æ–¹ã‚¬ã‚¤ãƒ‰ã€ã¨ã€Œåˆ¤æ–­åŸºæº–ã€ã‚’è¿½åŠ ")
    print("   3. æ—¥æœ¬äººã«ã‚ã‹ã‚Šã‚„ã™ã„è¡¨ç¾ã«çµ±ä¸€")
    print()

    work_dir = Path.cwd().parent if Path.cwd().name == 'scripts' else Path.cwd()
    print(f"ğŸ“‚ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {work_dir}")

    # Phase 1-4æ¤œç´¢
    notebooks = sorted(work_dir.glob('åº—èˆ—åˆ¥åŒ…æ‹¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰_v5.0_Phase[1-4].ipynb'))
    if not notebooks:
        print("\nâŒ Phase 1-4ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    print(f"\nğŸ” å¯¾è±¡: {len(notebooks)}å€‹")
    for nb in notebooks:
        print(f"   â€¢ {nb.name}")

    # å‡¦ç†å®Ÿè¡Œ
    print("\n" + "="*80)
    print("ğŸš€ å‡¦ç†é–‹å§‹")
    print("="*80)

    success_count = sum(1 for nb in notebooks if process_notebook(nb))

    # å®Œäº†
    print("\n" + "="*80)
    print("âœ… å‡¦ç†å®Œäº†")
    print("="*80)
    print(f"\n   æˆåŠŸ: {success_count}/{len(notebooks)}")
    print(f"\nğŸ“ å¤‰æ›´å†…å®¹:")
    print(f"   â€¢ å…¨ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«ãŒæ—¥æœ¬èªã«")
    print(f"   â€¢ è»¸ãƒ©ãƒ™ãƒ«ãƒ»å‡¡ä¾‹ãŒæ—¥æœ¬èªã«")
    print(f"   â€¢ å„ã‚°ãƒ©ãƒ•ã«åˆ¤æ–­åŸºæº–ã®æ³¨é‡ˆã‚’è¿½åŠ ")
    print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"   1. Jupyter Labã§ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é–‹ã")
    print(f"   2. Kernel â†’ Restart Kernel and Run All Cells")
    print(f"   3. ã‚°ãƒ©ãƒ•ã®æ³¨é‡ˆã¨æ—¥æœ¬èªè¡¨ç¤ºã‚’ç¢ºèª")


if __name__ == "__main__":
    main()
