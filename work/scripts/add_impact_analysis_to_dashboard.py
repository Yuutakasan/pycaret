#!/usr/bin/env python3
"""
åº—èˆ—åˆ¥åŒ…æ‹¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«åŒ…æ‹¬çš„å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æã‚»ãƒ«ã‚’è¿½åŠ 
"""

import json
from pathlib import Path

# åŒ…æ‹¬çš„å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æã‚»ãƒ«
impact_cell_code = """# ========================================
# ğŸ“Š åŒ…æ‹¬çš„å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æï¼ˆå…¨ç‰¹å¾´é‡ï¼‰
# ========================================

print('\\n' + '='*80)
print('ğŸ“Š åŒ…æ‹¬çš„å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æï¼ˆæ ¼ç´ç‡80%ä»¥ä¸Šã®å…¨ç‰¹å¾´é‡ï¼‰')
print('='*80)

# å£²ä¸Šåˆ—ã®ç¢ºèª
sales_col = 'å£²ä¸Šé‡‘é¡' if 'å£²ä¸Šé‡‘é¡' in df.columns else 'å£²ä¸Šæ•°é‡'
print(f'\\nğŸ“Š å£²ä¸ŠæŒ‡æ¨™: {sales_col}')

# ========================================
# ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ
# ========================================

# å„åˆ—ã®æ ¼ç´ç‡è¨ˆç®—
completeness = {}
for col in df.columns:
    non_null_count = df[col].notna().sum()
    completeness[col] = non_null_count / len(df)

# æ ¼ç´ç‡80%ä»¥ä¸Šã®ã‚«ãƒ©ãƒ æŠ½å‡º
high_quality_cols = [col for col, rate in completeness.items() if rate >= 0.8]

print(f'âœ… æ ¼ç´ç‡80%ä»¥ä¸Šã®ã‚«ãƒ©ãƒ : {len(high_quality_cols)}å€‹')

# åˆ†æå¯¾è±¡ã‚«ãƒ©ãƒ ï¼ˆé™¤å¤–åˆ—ã‚’é™¤ãï¼‰
exclude_cols = ['åº—èˆ—', 'å•†å“å', 'æ—¥ä»˜', sales_col, 'date', 'store_id', 'sku_id',
               'category_l', 'category_m', 'category_s',
               'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡']

analysis_cols = [col for col in high_quality_cols if col not in exclude_cols]
print(f'   åˆ†æå¯¾è±¡ã‚«ãƒ©ãƒ : {len(analysis_cols)}å€‹')

# ========================================
# å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè¨ˆç®—
# ========================================

import warnings
warnings.filterwarnings('ignore')

impact_results = []

for col in analysis_cols:
    try:
        col_data = df[col].dropna()

        if len(col_data) < 100:
            continue

        # æ•°å€¤å‹ã®å ´åˆ
        if pd.api.types.is_numeric_dtype(col_data):
            unique_vals = col_data.unique()

            # ãƒã‚¤ãƒŠãƒªãƒ•ãƒ©ã‚°ï¼ˆ0/1ï¼‰
            if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, 0.0, 1.0}):
                flag_on = df[df[col] == 1][sales_col].mean()
                flag_off = df[df[col] == 0][sales_col].mean()

                if flag_off > 0:
                    impact = (flag_on - flag_off) / flag_off
                    impact_abs = flag_on - flag_off

                    impact_results.append({
                        'ç‰¹å¾´é‡': col,
                        'åˆ†æã‚¿ã‚¤ãƒ—': 'ãƒã‚¤ãƒŠãƒªãƒ•ãƒ©ã‚°',
                        'å£²ä¸Š_ON': flag_on,
                        'å£²ä¸Š_OFF': flag_off,
                        'ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡': impact,
                        'ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆçµ¶å¯¾å€¤': impact_abs,
                        'ã‚µãƒ³ãƒ—ãƒ«æ•°_ON': (df[col] == 1).sum(),
                        'ã‚µãƒ³ãƒ—ãƒ«æ•°_OFF': (df[col] == 0).sum()
                    })

            # é€£ç¶šå€¤ï¼ˆç›¸é–¢åˆ†æï¼‰
            elif len(unique_vals) > 10:
                correlation = df[[col, sales_col]].corr().iloc[0, 1]

                if not np.isnan(correlation):
                    q75 = col_data.quantile(0.75)
                    q25 = col_data.quantile(0.25)

                    sales_high = df[df[col] >= q75][sales_col].mean()
                    sales_low = df[df[col] <= q25][sales_col].mean()

                    if sales_low > 0:
                        impact = (sales_high - sales_low) / sales_low
                        impact_abs = sales_high - sales_low

                        impact_results.append({
                            'ç‰¹å¾´é‡': col,
                            'åˆ†æã‚¿ã‚¤ãƒ—': 'é€£ç¶šå€¤ï¼ˆQ75 vs Q25ï¼‰',
                            'å£²ä¸Š_é«˜': sales_high,
                            'å£²ä¸Š_ä½': sales_low,
                            'ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡': impact,
                            'ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆçµ¶å¯¾å€¤': impact_abs,
                            'ç›¸é–¢ä¿‚æ•°': correlation
                        })

            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«æ•°å€¤ï¼ˆ3-10ç¨®é¡ï¼‰
            elif 3 <= len(unique_vals) <= 10:
                category_sales = df.groupby(col)[sales_col].agg(['mean', 'count'])

                if len(category_sales) >= 2:
                    max_sales = category_sales['mean'].max()
                    min_sales = category_sales['mean'].min()

                    if min_sales > 0:
                        impact = (max_sales - min_sales) / min_sales
                        impact_abs = max_sales - min_sales

                        impact_results.append({
                            'ç‰¹å¾´é‡': col,
                            'åˆ†æã‚¿ã‚¤ãƒ—': 'ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«',
                            'å£²ä¸Š_æœ€å¤§': max_sales,
                            'å£²ä¸Š_æœ€å°': min_sales,
                            'ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡': impact,
                            'ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆçµ¶å¯¾å€¤': impact_abs,
                            'ã‚«ãƒ†ã‚´ãƒªæ•°': len(unique_vals)
                        })

    except Exception:
        continue

print(f'\\nâœ… åˆ†æå®Œäº†: {len(impact_results)}å€‹ã®ç‰¹å¾´é‡ã‚’åˆ†æ')

# ========================================
# çµæœé›†è¨ˆ
# ========================================

if len(impact_results) > 0:
    impact_df = pd.DataFrame(impact_results)
    impact_df['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡_çµ¶å¯¾å€¤'] = impact_df['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡'].abs()
    impact_df = impact_df.sort_values('ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡_çµ¶å¯¾å€¤', ascending=False)

    print('\\n' + '='*80)
    print('ğŸ† å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 20')
    print('='*80)

    for idx, row in impact_df.head(20).iterrows():
        impact_sign = '+' if row['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡'] > 0 else ''
        print(f"{row['ç‰¹å¾´é‡']:30s} {impact_sign}{row['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡']:.2%} "\
              f"({impact_sign}{row['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆçµ¶å¯¾å€¤']:,.0f}å††) [{row['åˆ†æã‚¿ã‚¤ãƒ—']}]")

    # æ­£ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆTop 5
    positive_impact = impact_df[impact_df['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡'] > 0].head(5)
    print('\\n' + '='*80)
    print('âœ… å£²ä¸Šå¢—åŠ è¦å›  Top 5')
    print('='*80)
    for idx, row in positive_impact.iterrows():
        print(f"  {row['ç‰¹å¾´é‡']}: {row['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡']:+.2%} ({row['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆçµ¶å¯¾å€¤']:+,.0f}å††)")

    # è² ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆTop 5
    negative_impact = impact_df[impact_df['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡'] < 0].sort_values('ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡').head(5)
    print('\\n' + '='*80)
    print('âš ï¸ å£²ä¸Šæ¸›å°‘è¦å›  Top 5')
    print('='*80)
    for idx, row in negative_impact.iterrows():
        print(f"  {row['ç‰¹å¾´é‡']}: {row['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡']:+.2%} ({row['ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆçµ¶å¯¾å€¤']:+,.0f}å††)")

    print('\\n' + '='*80)
    print('ğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³')
    print('='*80)
    print('''
ã€å£²ä¸Šæœ€å¤§åŒ–æ–½ç­–ã€‘
1. æ­£ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè¦å› ã‚’æœ€å¤§åŒ–
   - è©²å½“æ¡ä»¶ã§ã®åœ¨åº«ç¢ºä¿
   - ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³å¼·åŒ–
   - ä¾¡æ ¼æœ€é©åŒ–

2. è² ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè¦å› ã‚’ç·©å’Œ
   - å£²ä¸Šæ¸›å°‘æ™‚ã®ç‰¹åˆ¥æ–½ç­–
   - ä»£æ›¿å•†å“ã®ææ¡ˆ
   - å‰²å¼•ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³

3. äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¸ã®æ´»ç”¨
   - ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç‡ä¸Šä½ã®ç‰¹å¾´é‡ã‚’é‡ç‚¹ä½¿ç”¨
   - ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§ç›¸äº’ä½œç”¨é …ä½œæˆ
   - ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«é‡è¦ç‰¹å¾´é‡ã‚’é¸å®š
    ''')

else:
    print('\\nâš ï¸ ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ')
"""

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯èª­ã¿è¾¼ã¿
notebook_path = Path('åº—èˆ—åˆ¥åŒ…æ‹¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰_v6.1_ææ¡ˆå¼·åŒ–.ipynb')

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# æ–°è¦ã‚»ãƒ«ä½œæˆ
new_cell = {
    'cell_type': 'code',
    'execution_count': None,
    'id': 'comprehensive_impact_analysis',
    'metadata': {},
    'outputs': [],
    'source': impact_cell_code.split('\n')
}

# å„è¡Œã«æ”¹è¡Œã‚’è¿½åŠ 
new_cell['source'] = [line + '\n' if i < len(new_cell['source'])-1 else line
                     for i, line in enumerate(new_cell['source'])]

# æœ€å¾Œã«è¿½åŠ 
nb['cells'].append(new_cell)

# ä¿å­˜
with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print("âœ… åŒ…æ‹¬çš„å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æã‚»ãƒ«ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
print(f"âœ… ä¿å­˜å®Œäº†: {notebook_path}")
print("\nã‚»ãƒ«å†…å®¹:")
print("  - æ ¼ç´ç‡80%ä»¥ä¸Šã®å…¨ç‰¹å¾´é‡ã‚’åˆ†æ")
print("  - ãƒã‚¤ãƒŠãƒªãƒ•ãƒ©ã‚°ã€é€£ç¶šå€¤ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã®3ç¨®é¡ã®åˆ†æ")
print("  - å£²ä¸Šå¢—åŠ è¦å›  Top 5")
print("  - å£²ä¸Šæ¸›å°‘è¦å›  Top 5")
print("  - æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
