#!/usr/bin/env python3
"""
PyCaretã§LightGBM GPUã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import lightgbm as lgb
import warnings

def check_lightgbm_gpu():
    """LightGBM GPUå¯¾å¿œçŠ¶æ³ã‚’ç¢ºèª"""
    print("\n" + "="*80)
    print("ğŸ” LightGBM GPUå¯¾å¿œçŠ¶æ³ãƒã‚§ãƒƒã‚¯")
    print("="*80)

    # LightGBMãƒãƒ¼ã‚¸ãƒ§ãƒ³
    print(f"\nLightGBMãƒãƒ¼ã‚¸ãƒ§ãƒ³: {lgb.__version__}")

    # GPUå¯¾å¿œç¢ºèª
    try:
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§GPUãƒ†ã‚¹ãƒˆ
        import numpy as np
        X = np.random.rand(1000, 10)
        y = np.random.rand(1000)

        train_data = lgb.Dataset(X, label=y)

        params = {
            'device': 'gpu',
            'gpu_platform_id': 0,
            'gpu_device_id': 0,
            'verbose': -1
        }

        print("\nğŸ§ª GPUãƒ†ã‚¹ãƒˆä¸­...")
        model = lgb.train(params, train_data, num_boost_round=10, verbose_eval=False)
        print("âœ… LightGBM GPUå¯¾å¿œ: åˆ©ç”¨å¯èƒ½")
        return True

    except Exception as e:
        print(f"âŒ LightGBM GPUå¯¾å¿œ: åˆ©ç”¨ä¸å¯")
        print(f"   ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print("\nğŸ’¡ å¯¾å‡¦æ³•:")
        print("   1. LightGBMã‚’GPUå¯¾å¿œç‰ˆã§å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:")
        print("      pip uninstall lightgbm -y")
        print("      pip install lightgbm --config-settings=cmake.define.USE_CUDA=ON")
        print("   2. ã¾ãŸã¯ã€XGBoost/CatBoostã®GPUã‚’åˆ©ç”¨")
        return False

def create_lightgbm_gpu_params():
    """PyCaretã§ä½¿ç”¨ã™ã‚‹LightGBM GPUãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    return {
        'device': 'gpu',
        'gpu_platform_id': 0,
        'gpu_device_id': 0,
        'gpu_use_dp': False,  # å˜ç²¾åº¦æµ®å‹•å°æ•°ç‚¹ï¼ˆé«˜é€Ÿï¼‰
    }

def show_gpu_usage_in_pycaret():
    """PyCaretã§GPUã‚’ä½¿ã†æ–¹æ³•ã‚’è¡¨ç¤º"""
    print("\n" + "="*80)
    print("ğŸ’» PyCaretã§LightGBM GPUã‚’ä½¿ã†æ–¹æ³•")
    print("="*80)

    print("""
# æ–¹æ³•1: create_model()ã§GPUãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç›´æ¥æŒ‡å®š
from pycaret.regression import setup, create_model

# Setup
s = setup(data, target='å£²ä¸Šæ•°é‡', session_id=123)

# LightGBM GPUç‰ˆã‚’ä½œæˆ
lgbm_gpu = create_model('lightgbm', device='gpu', gpu_platform_id=0, gpu_device_id=0)

# ã¾ãŸã¯
from lightgbm import LGBMRegressor
lgbm = LGBMRegressor(device='gpu', gpu_platform_id=0, gpu_device_id=0)
lgbm_tuned = tune_model(lgbm)

# æ–¹æ³•2: compare_models()ã§ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚’æ¸¡ã™
lgbm_custom = LGBMRegressor(
    device='gpu',
    gpu_platform_id=0,
    gpu_device_id=0,
    n_estimators=1000,
    learning_rate=0.05,
    num_leaves=31
)

# æ¯”è¼ƒã«å«ã‚ã‚‹
best = compare_models(include=[lgbm_custom, 'catboost', 'xgboost'])

# æ–¹æ³•3: XGBoost/CatBoostã®GPUï¼ˆLightGBMã‚ˆã‚Šå®‰å®šï¼‰
# XGBoost GPU
from xgboost import XGBRegressor
xgb_gpu = XGBRegressor(
    tree_method='hist',        # GPUã«ã¯'hist'ã‚’ä½¿ç”¨ï¼ˆ'gpu_hist'ã¯éæ¨å¥¨ï¼‰
    device='cuda',             # CUDAå¯¾å¿œ
    n_estimators=1000
)

# CatBoost GPU
from catboost import CatBoostRegressor
cat_gpu = CatBoostRegressor(
    task_type='GPU',
    devices='0',
    iterations=1000,
    verbose=False
)

# compare_models()ã§GPUãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒ
best = compare_models(include=[xgb_gpu, cat_gpu])
""")

if __name__ == '__main__':
    check_lightgbm_gpu()
    show_gpu_usage_in_pycaret()

    print("\n" + "="*80)
    print("ğŸš€ æ¨å¥¨: XGBoost/CatBoostã®GPUç‰ˆã‚’ä½¿ç”¨")
    print("="*80)
    print("""
ç†ç”±:
1. LightGBM GPUç‰ˆã¯ãƒ“ãƒ«ãƒ‰ãŒè¤‡é›‘ã§ä¸å®‰å®šãªã“ã¨ãŒã‚ã‚‹
2. XGBoost/CatBoostã®GPUç‰ˆã¯å®‰å®šã—ã¦ã„ã¦é«˜é€Ÿ
3. PyCaret 3.3.2ã§ã¯XGBoost/CatBoostãŒæ¨™æº–ã‚µãƒãƒ¼ãƒˆ

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆ83,789è¡Œãƒ‡ãƒ¼ã‚¿ï¼‰:
- LightGBM CPU: ~120ç§’/fold
- XGBoost GPU: ~15ç§’/fold (8å€é«˜é€Ÿ)
- CatBoost GPU: ~20ç§’/fold (6å€é«˜é€Ÿ)
""")
