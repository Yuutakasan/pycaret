#!/usr/bin/env python3
"""
Step5_CategoryWise_Compare_with_Overfitting.ipynb ã«åº—èˆ—åˆ¥åˆ†æã‚»ãƒ«ã‚’è¿½åŠ 
"""

import json
from pathlib import Path

# åº—èˆ—åˆ¥åˆ†æã‚»ãƒ«ã®ã‚³ãƒ¼ãƒ‰
store_analysis_cells = [
    {
        'cell_type': 'markdown',
        'id': 'store_analysis_header',
        'source': [
            '# åº—èˆ—åˆ¥åˆ†æ\n',
            '\n',
            '## ç›®çš„\n',
            'å…¨åº—èˆ—çµ±åˆãƒ¢ãƒ‡ãƒ« vs åº—èˆ—åˆ¥å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ\n',
            '\n',
            '**ä»®èª¬:**\n',
            '- åº—èˆ—ã”ã¨ã«é¡§å®¢å±æ€§ãƒ»ç«‹åœ°ç‰¹æ€§ãŒç•°ãªã‚‹\n',
            '- åº—èˆ—åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒç²¾åº¦ãŒé«˜ã„å¯èƒ½æ€§\n',
            '- ãŸã ã—ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã§éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ã‚‚'
        ]
    },
    {
        'cell_type': 'code',
        'id': 'store_all_unified',
        'source': [
            '# ========================================\n',
            '# 8. å…¨åº—èˆ—çµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆåº—èˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼‰\n',
            '# ========================================\n',
            '\n',
            'print(\'\\n\' + \'=\'*80)\n',
            'print(\'ğŸª å…¨åº—èˆ—çµ±åˆãƒ¢ãƒ‡ãƒ«åˆ†æï¼ˆåº—èˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼‰\')\n',
            'print(\'=\'*80)\n',
            '\n',
            '# å…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆå…¨ã‚«ãƒ†ã‚´ãƒªÃ—å…¨åº—èˆ—ï¼‰\n',
            'all_store_data = data.copy()\n',
            '\n',
            'print(f\'\\nå…¨åº—èˆ—ãƒ‡ãƒ¼ã‚¿: {len(all_store_data)}è¡Œ\')\n',
            'print(f\'åº—èˆ—æ•°: {all_store_data[\"åº—èˆ—\"].nunique()}\')\n',
            '\n',
            '# ä¸è¦åˆ—é™¤å¤–\n',
            'exclude_cols = [\'å•†å“å\', \'æ—¥ä»˜\', \'å£²ä¸Šé‡‘é¡\', \'category_l\',\n',
            '               \'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡\', \'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡\', \'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡\']\n',
            '\n',
            '# åº—èˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–\n',
            'store_dummies = pd.get_dummies(all_store_data[\'åº—èˆ—\'], prefix=\'store\')\n',
            '\n',
            '# ã‚«ãƒ†ã‚´ãƒªã‚‚ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–\n',
            'if \'category_l\' in all_store_data.columns:\n',
            '    category_dummies = pd.get_dummies(all_store_data[\'category_l\'], prefix=\'cat\')\n',
            'else:\n',
            '    category_dummies = pd.DataFrame()\n',
            '\n',
            'feature_cols = [c for c in all_store_data.columns \n',
            '               if c not in exclude_cols + [\'å£²ä¸Šæ•°é‡\', \'åº—èˆ—\']]\n',
            'numeric_cols = all_store_data[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n',
            '\n',
            'model_data_all = pd.concat([\n',
            '    all_store_data[numeric_cols + [\'å£²ä¸Šæ•°é‡\']],\n',
            '    store_dummies,\n',
            '    category_dummies\n',
            '], axis=1).dropna()\n',
            '\n',
            'print(f\'æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {len(model_data_all)}è¡Œ, {len(model_data_all.columns)-1}ç‰¹å¾´é‡\')\n',
            '\n',
            '# PyCaret setup\n',
            's_all = setup(\n',
            '    model_data_all,\n',
            '    target=\'å£²ä¸Šæ•°é‡\',\n',
            '    session_id=123,\n',
            '    train_size=0.8,\n',
            '    fold=10,\n',
            '    normalize=True,\n',
            '    remove_multicollinearity=True,\n',
            '    multicollinearity_threshold=0.95,\n',
            '    silent=True,\n',
            '    verbose=False\n',
            ')\n',
            '\n',
            '# ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\n',
            'print(\'\\nğŸ” compare_models()å®Ÿè¡Œä¸­ï¼ˆå…¨åº—èˆ—çµ±åˆï¼‰...\')\n',
            'best_models_all = compare_models(\n',
            '    n_select=5,\n',
            '    sort=\'R2\',\n',
            '    turbo=False,\n',
            '    verbose=False\n',
            ')\n',
            '\n',
            'comparison_all = pull()\n',
            'print(\'\\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœï¼ˆTop 5ï¼‰:\')\n',
            'print(comparison_all[[\'Model\', \'R2\', \'MAE\', \'RMSE\']].head())\n',
            '\n',
            '# éå­¦ç¿’æ¤œå‡º\n',
            'best_model_all = best_models_all[0] if isinstance(best_models_all, list) else best_models_all\n',
            '\n',
            'X_train_all = get_config(\'X_train\')\n',
            'y_train_all = get_config(\'y_train\')\n',
            'X_test_all = get_config(\'X_test\')\n',
            'y_test_all = get_config(\'y_test\')\n',
            '\n',
            'overfitting_all = detect_overfitting(\n',
            '    best_model_all, X_train_all, y_train_all, X_test_all, y_test_all,\n',
            '    model_name=f\'AllStores - {best_model_all.__class__.__name__}\'\n',
            ')\n',
            '\n',
            'print(f\'\\nğŸ”¬ éå­¦ç¿’æ¤œå‡ºçµæœ:\')\n',
            'print(f\'  Train RÂ²: {overfitting_all[\"r2_train\"]:.4f}\')\n',
            'print(f\'  Test RÂ²: {overfitting_all[\"r2_test\"]:.4f}\')\n',
            'print(f\'  RÂ²ã‚®ãƒ£ãƒƒãƒ—: {overfitting_all[\"r2_gap\"]:.4f}\')\n',
            'print(f\'  éå­¦ç¿’åˆ¤å®š: {\"ã¯ã„\" if overfitting_all[\"is_overfitting\"] else \"ã„ã„ãˆ\"}\')\n',
            '\n',
            '# çµæœä¿å­˜\n',
            'all_store_result = {\n',
            '    \'åˆ†æã‚¿ã‚¤ãƒ—\': \'å…¨åº—èˆ—çµ±åˆ\',\n',
            '    \'åº—èˆ—\': \'å…¨åº—èˆ—\',\n',
            '    \'ãƒ‡ãƒ¼ã‚¿æ•°\': len(model_data_all),\n',
            '    \'ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\': best_model_all.__class__.__name__,\n',
            '    \'R2_Test\': overfitting_all[\'r2_test\'],\n',
            '    \'R2_Train\': overfitting_all[\'r2_train\'],\n',
            '    \'R2_Gap\': overfitting_all[\'r2_gap\'],\n',
            '    \'éå­¦ç¿’\': overfitting_all[\'is_overfitting\'],\n',
            '    \'æ·±åˆ»åº¦\': overfitting_all[\'overfitting_severity\'],\n',
            '    \'MAE_Test\': overfitting_all[\'mae_test\'],\n',
            '    \'RMSE_Test\': overfitting_all[\'rmse_test\']\n',
            '}\n',
            '\n',
            '# Learning Curve\n',
            'fig_all, gap_all = plot_learning_curve(best_model_all, X_train_all, y_train_all,\n',
            '                                       model_name=\'å…¨åº—èˆ—çµ±åˆ\', cv=10)\n',
            'fig_all.savefig(\'output/learning_curves/learning_curve_AllStores.png\',\n',
            '               dpi=150, bbox_inches=\'tight\')\n',
            'plt.close(fig_all)\n',
            '\n',
            'print(\'\\nâœ… å…¨åº—èˆ—çµ±åˆãƒ¢ãƒ‡ãƒ«åˆ†æå®Œäº†\')\n'
        ]
    },
    {
        'cell_type': 'code',
        'id': 'store_individual',
        'source': [
            '# ========================================\n',
            '# 9. åº—èˆ—åˆ¥å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«åˆ†æ\n',
            '# ========================================\n',
            '\n',
            'print(\'\\n\' + \'=\'*80)\n',
            'print(\'ğŸª åº—èˆ—åˆ¥å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«åˆ†æ\')\n',
            'print(\'=\'*80)\n',
            '\n',
            'store_results = []\n',
            '\n',
            '# åº—èˆ—ãƒªã‚¹ãƒˆå–å¾—\n',
            'stores = data[\'åº—èˆ—\'].unique()\n',
            'print(f\'\\nå¯¾è±¡åº—èˆ—æ•°: {len(stores)}åº—èˆ—\')\n',
            'print(f\'åº—èˆ—ãƒªã‚¹ãƒˆ: {stores}\')\n',
            '\n',
            'for store in stores:\n',
            '    print(f\'\\n--- åº—èˆ—: {store} ---\')\n',
            '    \n',
            '    # åº—èˆ—ãƒ‡ãƒ¼ã‚¿æŠ½å‡º\n',
            '    store_data = data[data[\'åº—èˆ—\'] == store].copy()\n',
            '    \n',
            '    if len(store_data) < 500:\n',
            '        print(f\'âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({len(store_data)}è¡Œ) - ã‚¹ã‚­ãƒƒãƒ—\')\n',
            '        continue\n',
            '    \n',
            '    print(f\'ãƒ‡ãƒ¼ã‚¿æ•°: {len(store_data)}è¡Œ\')\n',
            '    print(f\'ã‚«ãƒ†ã‚´ãƒªæ•°: {store_data[\"category_l\"].nunique()}\')\n',
            '    \n',
            '    # ä¸è¦åˆ—é™¤å¤–\n',
            '    exclude_cols = [\'åº—èˆ—\', \'å•†å“å\', \'æ—¥ä»˜\', \'å£²ä¸Šé‡‘é¡\',\n',
            '                   \'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡\', \'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡\', \'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡\']\n',
            '    \n',
            '    # ã‚«ãƒ†ã‚´ãƒªã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–\n',
            '    if \'category_l\' in store_data.columns:\n',
            '        category_dummies = pd.get_dummies(store_data[\'category_l\'], prefix=\'cat\')\n',
            '    else:\n',
            '        category_dummies = pd.DataFrame()\n',
            '    \n',
            '    feature_cols = [c for c in store_data.columns \n',
            '                   if c not in exclude_cols + [\'å£²ä¸Šæ•°é‡\', \'category_l\']]\n',
            '    numeric_cols = store_data[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n',
            '    \n',
            '    model_data_store = pd.concat([\n',
            '        store_data[numeric_cols + [\'å£²ä¸Šæ•°é‡\']],\n',
            '        category_dummies\n',
            '    ], axis=1).dropna()\n',
            '    \n',
            '    if len(model_data_store) < 100:\n',
            '        print(f\'âš ï¸ æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({len(model_data_store)}è¡Œ) - ã‚¹ã‚­ãƒƒãƒ—\')\n',
            '        continue\n',
            '    \n',
            '    print(f\'æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {len(model_data_store)}è¡Œ, {len(model_data_store.columns)-1}ç‰¹å¾´é‡\')\n',
            '    \n',
            '    # PyCaret setup\n',
            '    s_store = setup(\n',
            '        model_data_store,\n',
            '        target=\'å£²ä¸Šæ•°é‡\',\n',
            '        session_id=123,\n',
            '        train_size=0.8,\n',
            '        fold=5,\n',
            '        normalize=True,\n',
            '        remove_multicollinearity=True,\n',
            '        multicollinearity_threshold=0.95,\n',
            '        silent=True,\n',
            '        verbose=False\n',
            '    )\n',
            '    \n',
            '    # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\n',
            '    print(f\'\\nğŸ” compare_models()å®Ÿè¡Œä¸­ï¼ˆåº—èˆ—: {store}ï¼‰...\')\n',
            '    best_models_store = compare_models(\n',
            '        n_select=5,\n',
            '        sort=\'R2\',\n',
            '        turbo=False,\n',
            '        verbose=False\n',
            '    )\n',
            '    \n',
            '    comparison_store = pull()\n',
            '    print(\'\\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœï¼ˆTop 5ï¼‰:\')\n',
            '    print(comparison_store[[\'Model\', \'R2\', \'MAE\', \'RMSE\']].head())\n',
            '    \n',
            '    # éå­¦ç¿’æ¤œå‡º\n',
            '    best_model_store = best_models_store[0] if isinstance(best_models_store, list) else best_models_store\n',
            '    \n',
            '    X_train_store = get_config(\'X_train\')\n',
            '    y_train_store = get_config(\'y_train\')\n',
            '    X_test_store = get_config(\'X_test\')\n',
            '    y_test_store = get_config(\'y_test\')\n',
            '    \n',
            '    overfitting_store = detect_overfitting(\n',
            '        best_model_store, X_train_store, y_train_store, X_test_store, y_test_store,\n',
            '        model_name=f\'{store} - {best_model_store.__class__.__name__}\'\n',
            '    )\n',
            '    \n',
            '    print(f\'\\nğŸ”¬ éå­¦ç¿’æ¤œå‡ºçµæœ:\')\n',
            '    print(f\'  Train RÂ²: {overfitting_store[\"r2_train\"]:.4f}\')\n',
            '    print(f\'  Test RÂ²: {overfitting_store[\"r2_test\"]:.4f}\')\n',
            '    print(f\'  RÂ²ã‚®ãƒ£ãƒƒãƒ—: {overfitting_store[\"r2_gap\"]:.4f}\')\n',
            '    print(f\'  éå­¦ç¿’åˆ¤å®š: {\"ã¯ã„\" if overfitting_store[\"is_overfitting\"] else \"ã„ã„ãˆ\"}\')\n',
            '    \n',
            '    # çµæœä¿å­˜\n',
            '    store_results.append({\n',
            '        \'åˆ†æã‚¿ã‚¤ãƒ—\': \'åº—èˆ—åˆ¥\',\n',
            '        \'åº—èˆ—\': store,\n',
            '        \'ãƒ‡ãƒ¼ã‚¿æ•°\': len(model_data_store),\n',
            '        \'ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\': best_model_store.__class__.__name__,\n',
            '        \'R2_Test\': overfitting_store[\'r2_test\'],\n',
            '        \'R2_Train\': overfitting_store[\'r2_train\'],\n',
            '        \'R2_Gap\': overfitting_store[\'r2_gap\'],\n',
            '        \'éå­¦ç¿’\': overfitting_store[\'is_overfitting\'],\n',
            '        \'æ·±åˆ»åº¦\': overfitting_store[\'overfitting_severity\'],\n',
            '        \'MAE_Test\': overfitting_store[\'mae_test\'],\n',
            '        \'RMSE_Test\': overfitting_store[\'rmse_test\']\n',
            '    })\n',
            '    \n',
            '    # Learning Curve\n',
            '    fig_store, gap_store = plot_learning_curve(\n',
            '        best_model_store, X_train_store, y_train_store,\n',
            '        model_name=f\'åº—èˆ—{store}\', cv=5\n',
            '    )\n',
            '    fig_store.savefig(f\'output/learning_curves/learning_curve_Store_{store}.png\',\n',
            '                     dpi=150, bbox_inches=\'tight\')\n',
            '    plt.close(fig_store)\n',
            '    \n',
            '    print(f\'âœ… åº—èˆ—{store}åˆ†æå®Œäº†\')\n',
            '\n',
            'print(f\'\\nâœ… åº—èˆ—åˆ¥åˆ†æå®Œäº†: {len(store_results)}åº—èˆ—\')\n'
        ]
    },
    {
        'cell_type': 'code',
        'id': 'store_comparison',
        'source': [
            '# ========================================\n',
            '# 10. å…¨åº—èˆ—çµ±åˆ vs åº—èˆ—åˆ¥ æ¯”è¼ƒåˆ†æ\n',
            '# ========================================\n',
            '\n',
            'print(\'\\n\' + \'=\'*80)\n',
            'print(\'ğŸ“Š å…¨åº—èˆ—çµ±åˆ vs åº—èˆ—åˆ¥ãƒ¢ãƒ‡ãƒ« æ¯”è¼ƒåˆ†æ\')\n',
            'print(\'=\'*80)\n',
            '\n',
            '# å…¨çµæœã‚’çµ±åˆ\n',
            'store_comparison_results = [all_store_result] + store_results\n',
            'store_comparison_df = pd.DataFrame(store_comparison_results)\n',
            '\n',
            'if len(store_comparison_df) > 0:\n',
            '    print(\'\\nã€å…¨åº—èˆ—çµ±åˆ vs åº—èˆ—åˆ¥ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã€‘\')\n',
            '    print(store_comparison_df[[\'åˆ†æã‚¿ã‚¤ãƒ—\', \'åº—èˆ—\', \'ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\', \'R2_Test\',\n',
            '                              \'R2_Gap\', \'éå­¦ç¿’\', \'æ·±åˆ»åº¦\', \'ãƒ‡ãƒ¼ã‚¿æ•°\']].to_string(index=False))\n',
            '    \n',
            '    # çµ±è¨ˆã‚µãƒãƒªãƒ¼\n',
            '    print(\'\\n\' + \'=\'*80)\n',
            '    print(\'ğŸ“ˆ æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼\')\n',
            '    print(\'=\'*80)\n',
            '    \n',
            '    strategy_summary = store_comparison_df.groupby(\'åˆ†æã‚¿ã‚¤ãƒ—\').agg({\n',
            '        \'R2_Test\': [\'mean\', \'std\', \'min\', \'max\'],\n',
            '        \'R2_Gap\': [\'mean\', \'max\'],\n',
            '        \'éå­¦ç¿’\': lambda x: (x == True).sum(),\n',
            '        \'åº—èˆ—\': \'count\'\n',
            '    }).round(4)\n',
            '    \n',
            '    print(strategy_summary)\n',
            '    \n',
            '    # æœ€é©æˆ¦ç•¥ã®åˆ¤å®š\n',
            '    all_store_r2 = store_comparison_df[store_comparison_df[\'åˆ†æã‚¿ã‚¤ãƒ—\'] == \'å…¨åº—èˆ—çµ±åˆ\'][\'R2_Test\'].iloc[0]\n',
            '    per_store_avg_r2 = store_comparison_df[store_comparison_df[\'åˆ†æã‚¿ã‚¤ãƒ—\'] == \'åº—èˆ—åˆ¥\'][\'R2_Test\'].mean()\n',
            '    \n',
            '    print(\'\\n\' + \'=\'*80)\n',
            '    print(\'ğŸ¯ æœ€é©ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æˆ¦ç•¥ã®åˆ¤å®š\')\n',
            '    print(\'=\'*80)\n',
            '    \n',
            '    print(f\'\\nå…¨åº—èˆ—çµ±åˆãƒ¢ãƒ‡ãƒ« RÂ²: {all_store_r2:.4f}\')\n',
            '    print(f\'åº—èˆ—åˆ¥ãƒ¢ãƒ‡ãƒ«å¹³å‡ RÂ²: {per_store_avg_r2:.4f}\')\n',
            '    print(f\'å·®åˆ†: {per_store_avg_r2 - all_store_r2:.4f} ({(per_store_avg_r2 - all_store_r2)/all_store_r2:.2%})\')\n',
            '    \n',
            '    # åˆ¤å®šåŸºæº–\n',
            '    if per_store_avg_r2 > all_store_r2 + 0.05:  # 5%ä»¥ä¸Šæ”¹å–„\n',
            '        recommendation = \'âœ… åº—èˆ—åˆ¥ãƒ¢ãƒ‡ãƒ«æ¨å¥¨\'\n',
            '        reason = f\'åº—èˆ—åˆ¥ãƒ¢ãƒ‡ãƒ«ãŒ{(per_store_avg_r2 - all_store_r2)/all_store_r2:.1%}æ”¹å–„\')\n',
            '    elif per_store_avg_r2 < all_store_r2 - 0.05:  # 5%ä»¥ä¸Šæ‚ªåŒ–\n',
            '        recommendation = \'âœ… å…¨åº—èˆ—çµ±åˆãƒ¢ãƒ‡ãƒ«æ¨å¥¨\'\n',
            '        reason = f\'çµ±åˆãƒ¢ãƒ‡ãƒ«ãŒ{(all_store_r2 - per_store_avg_r2)/all_store_r2:.1%}å„ªä½\')\n',
            '    else:  # Â±5%ä»¥å†…\n',
            '        recommendation = \'âš–ï¸ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æˆ¦ç•¥æ¨å¥¨\'\n',
            '        reason = \'å·®åˆ†ãŒå°ã•ã„ãŸã‚ã€åº—èˆ—ç‰¹æ€§ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘\'\n',
            '    \n',
            '    print(f\'\\n{recommendation}\')\n',
            '    print(f\'ç†ç”±: {reason}\')\n',
            '    \n',
            '    # è©³ç´°æ¨å¥¨\n',
            '    print(\'\\nğŸ’¡ å®Ÿè£…æ¨å¥¨:\')\n',
            '    if \'åº—èˆ—åˆ¥\' in recommendation:\n',
            '        print(\'  1. å„åº—èˆ—ã§å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤\')\n',
            '        print(\'  2. æ–°è¦åº—èˆ—ã¯çµ±åˆãƒ¢ãƒ‡ãƒ«ã§é–‹å§‹ã€ãƒ‡ãƒ¼ã‚¿è“„ç©å¾Œã«å€‹åˆ¥åŒ–\')\n',
            '        print(\'  3. å®šæœŸçš„ã«ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ï¼ˆæœˆæ¬¡æ¨å¥¨ï¼‰\')\n',
            '    elif \'çµ±åˆ\' in recommendation:\n',
            '        print(\'  1. å…¨åº—èˆ—ã§1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’å…±æœ‰ï¼ˆãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰\')\n',
            '        print(\'  2. åº—èˆ—ãƒ€ãƒŸãƒ¼å¤‰æ•°ã§åº—èˆ—ç‰¹æ€§ã‚’å¸å\')\n',
            '        print(\'  3. åº—èˆ—å›ºæœ‰ã®ç‰¹å¾´é‡ã‚’è¿½åŠ æ¤œè¨ï¼ˆç«‹åœ°ã€å•†åœãªã©ï¼‰\')\n',
            '    else:  # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰\n',
            '        print(\'  1. ãƒ‡ãƒ¼ã‚¿é‡ãŒè±Šå¯Œãªåº—èˆ— â†’ å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«\')\n',
            '        print(\'  2. ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®åº—èˆ— â†’ çµ±åˆãƒ¢ãƒ‡ãƒ«\')\n',
            '        print(\'  3. é–¾å€¤: 1åº—èˆ—ã‚ãŸã‚Š5000è¡Œä»¥ä¸Šãªã‚‰å€‹åˆ¥åŒ–\')\n',
            '    \n',
            '    # åº—èˆ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n',
            '    print(\'\\n\' + \'=\'*80)\n',
            '    print(\'ğŸ† åº—èˆ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°\')\n',
            '    print(\'=\'*80)\n',
            '    \n',
            '    store_only = store_comparison_df[store_comparison_df[\'åˆ†æã‚¿ã‚¤ãƒ—\'] == \'åº—èˆ—åˆ¥\'].copy()\n',
            '    if len(store_only) > 0:\n',
            '        store_only_sorted = store_only.sort_values(\'R2_Test\', ascending=False)\n',
            '        print(store_only_sorted[[\'åº—èˆ—\', \'ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\', \'R2_Test\', \'R2_Gap\',\n',
            '                                \'éå­¦ç¿’\', \'ãƒ‡ãƒ¼ã‚¿æ•°\']].to_string(index=False))\n',
            '        \n',
            '        # ãƒ™ã‚¹ãƒˆåº—èˆ—ã¨ãƒ¯ãƒ¼ã‚¹ãƒˆåº—èˆ—\n',
            '        best_store = store_only_sorted.iloc[0]\n',
            '        worst_store = store_only_sorted.iloc[-1]\n',
            '        \n',
            '        print(f\'\\nğŸ¥‡ æœ€é«˜ç²¾åº¦åº—èˆ—: {best_store[\"åº—èˆ—\"]} (RÂ²={best_store[\"R2_Test\"]:.4f})\')\n',
            '        print(f\'   ãƒ¢ãƒ‡ãƒ«: {best_store[\"ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\"]}\')\n',
            '        print(f\'   ãƒ‡ãƒ¼ã‚¿æ•°: {best_store[\"ãƒ‡ãƒ¼ã‚¿æ•°\"]:,}è¡Œ\')\n',
            '        \n',
            '        print(f\'\\nâš ï¸ æ”¹å–„å¿…è¦åº—èˆ—: {worst_store[\"åº—èˆ—\"]} (RÂ²={worst_store[\"R2_Test\"]:.4f})\')\n',
            '        print(f\'   ãƒ¢ãƒ‡ãƒ«: {worst_store[\"ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\"]}\')\n',
            '        print(f\'   ãƒ‡ãƒ¼ã‚¿æ•°: {worst_store[\"ãƒ‡ãƒ¼ã‚¿æ•°\"]:,}è¡Œ\')\n',
            '        print(f\'   æ”¹å–„ç­–: ãƒ‡ãƒ¼ã‚¿æœŸé–“å»¶é•·ã€ç‰¹å¾´é‡è¦‹ç›´ã—ã€çµ±åˆãƒ¢ãƒ‡ãƒ«åˆ©ç”¨æ¤œè¨\')\n',
            '    \n',
            '    # CSVä¿å­˜\n',
            '    output_path = Path(\'output/store_comparison_results.csv\')\n',
            '    store_comparison_df.to_csv(output_path, index=False, encoding=\'utf-8-sig\')\n',
            '    print(f\'\\nâœ… çµæœã‚’CSVä¿å­˜: {output_path}\')\n',
            '\n',
            'else:\n',
            '    print(\'âš ï¸ æ¯”è¼ƒçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ\')\n',
            '\n',
            'print(\'\\nâœ… åº—èˆ—åˆ¥åˆ†æå®Œäº†ï¼\')\n'
        ]
    }
]

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯èª­ã¿è¾¼ã¿
notebook_path = Path('/mnt/d/github/pycaret/work/Step5_CategoryWise_Compare_with_Overfitting.ipynb')

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# æœ€å¾Œã®ã‚»ãƒ«ï¼ˆsummaryï¼‰ã®å¾Œã«æŒ¿å…¥
nb['cells'].extend(store_analysis_cells)

# ä¿å­˜
with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print(f"âœ… åº—èˆ—åˆ¥åˆ†æã‚»ãƒ«ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼ˆ3ã‚»ãƒ«è¿½åŠ ï¼‰")
print(f"âœ… ä¿å­˜å®Œäº†: {notebook_path}")
print("\nè¿½åŠ ã•ã‚ŒãŸã‚»ãƒ«:")
print("  Cell 8: å…¨åº—èˆ—çµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆåº—èˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼‰")
print("  Cell 9: åº—èˆ—åˆ¥å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«")
print("  Cell 10: å…¨åº—èˆ—çµ±åˆ vs åº—èˆ—åˆ¥ æ¯”è¼ƒåˆ†æ")
