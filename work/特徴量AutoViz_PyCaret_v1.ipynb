{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad39ec2",
   "metadata": {},
   "source": [
    "# 🔎 特徴量分析（AutoViz + PyCaret）v1 — AI売上予測ツール\n",
    "\n",
    "## 📘 このツールの目的\n",
    "**AIが売上データを自動分析し、「何が売上に効くか」を教えてくれるツールです。**\n",
    "\n",
    "### 🎯 できること\n",
    "1. グラフで視覚的に売上パターンを確認（AutoViz）\n",
    "2. AI が重要な要因を自動で見つける（PyCaret）\n",
    "3. 予測モデルを作成し、精度を数値で確認\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 使い方（簡単3ステップ）\n",
    "1. **セルを上から順に実行**（各セルで Shift+Enter を押す）\n",
    "2. **グラフを見て、パターンを確認**\n",
    "3. **重要度ランキングで、注目すべき要因を特定**\n",
    "\n",
    "---\n",
    "\n",
    "**それでは、以下のセルを順番に実行してください。各セクションに「何を見るか」「どう判断するか」が書いてあります。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリと環境\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# 日本語フォント（Matplotlib/Plotly）\n",
    "import font_setup  # IPAGothic等を自動設定\n",
    "\n",
    "# AutoViz\n",
    "try:\n",
    "    from autoviz.AutoViz_Class import AutoViz_Class\n",
    "    AV_OK = True\n",
    "except Exception:\n",
    "    AV_OK = False\n",
    "\n",
    "# PyCaret（回帰）\n",
    "try:\n",
    "    from pycaret.regression import setup, compare_models, pull, finalize_model, predict_model, plot_model\n",
    "    PYC_OK = True\n",
    "except Exception:\n",
    "    PYC_OK = False\n",
    "\n",
    "# ipywidgets（インタラクティブUI）\n",
    "WIDGETS = False\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    WIDGETS = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# バージョン情報\n",
    "print(f'Python: {sys.version.split()[0]}')\n",
    "print(f'pandas: {pd.__version__}, numpy: {np.__version__}')\n",
    "print(f'AutoViz: {AV_OK}, PyCaret.regression: {PYC_OK}')\n",
    "\n",
    "# PyCaretの最小サンプル数（3-fold CVに必要）\n",
    "MIN_SAMPLES_PYCARET = 100\n",
    "\n",
    "# ========================================\n",
    "# 🚀 GPU検出と設定\n",
    "# ========================================\n",
    "print('\\n' + '='*60)\n",
    "print('🖥️ GPU検出')\n",
    "print('='*60)\n",
    "\n",
    "# GPU利用可能性をチェック\n",
    "GPU_AVAILABLE = False\n",
    "GPU_DEVICE = 'cpu'\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_AVAILABLE = True\n",
    "        GPU_DEVICE = 'cuda'\n",
    "        print(f'✅ NVIDIA GPU検出: {torch.cuda.get_device_name(0)}')\n",
    "        print(f'   CUDA Version: {torch.version.cuda}')\n",
    "        print(f'   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "    else:\n",
    "        print('⚠️ PyTorch installed but no CUDA GPU found')\n",
    "except ImportError:\n",
    "    print('ℹ️ PyTorch not installed (GPU detection skipped)')\n",
    "\n",
    "# LightGBM GPU対応チェック\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    if GPU_AVAILABLE:\n",
    "        print('✅ LightGBM GPU対応: 可能')\n",
    "    else:\n",
    "        print('ℹ️  LightGBM: CPU mode')\n",
    "except ImportError:\n",
    "    print('ℹ️ LightGBM not installed')\n",
    "\n",
    "# XGBoost GPU対応チェック\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    if GPU_AVAILABLE:\n",
    "        print('✅ XGBoost GPU対応: 可能')\n",
    "    else:\n",
    "        print('ℹ️ XGBoost: CPU mode')\n",
    "except ImportError:\n",
    "    print('ℹ️ XGBoost not installed')\n",
    "\n",
    "# CatBoost GPU対応チェック\n",
    "try:\n",
    "    import catboost\n",
    "    if GPU_AVAILABLE:\n",
    "        print('✅ CatBoost GPU対応: 可能')\n",
    "    else:\n",
    "        print('ℹ️ CatBoost: CPU mode')\n",
    "except ImportError:\n",
    "    print('ℹ️ CatBoost not installed')\n",
    "# cuDF (GPU Pandas) チェック\n",
    "CUDF_AVAILABLE = False\n",
    "try:\n",
    "    import cudf\n",
    "    if GPU_AVAILABLE:\n",
    "        CUDF_AVAILABLE = True\n",
    "        print('✅ cuDF (GPU Pandas) 対応: 可能')\n",
    "    else:\n",
    "        print('ℹ️ cuDF: GPU not available, using CPU Pandas')\n",
    "except ImportError:\n",
    "    print('ℹ️ cuDF not installed (CPU Pandas継続)')\n",
    "\n",
    "# GPU使用フラグ（ユーザーが変更可能）\n",
    "USE_GPU = GPU_AVAILABLE  # Trueに設定するとGPUを使用（GPUが利用可能な場合のみ）\n",
    "\n",
    "if USE_GPU:\n",
    "    print(f'\\n🚀 GPU使用: 有効（推定2～10倍高速化）')\n",
    "    print(f'   Device: {GPU_DEVICE}')\n",
    "else:\n",
    "    print(f'\\nℹ️ GPU使用: 無効（CPUモードで実行）')\n",
    "    if GPU_AVAILABLE:\n",
    "        print('   💡 ヒント: 上のセルで USE_GPU = True に設定するとGPU使用可能')\n",
    "\n",
    "print('='*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 🔧 GPU/CPU データフレーム変換ユーティリティ\n",
    "# ========================================\n",
    "\n",
    "def to_gpu(df):\n",
    "    \"\"\"pandasデータフレームをGPU (cuDF) に変換（USE_GPU=Trueの場合のみ）\"\"\"\n",
    "    if USE_GPU and CUDF_AVAILABLE and df is not None and not df.empty:\n",
    "        try:\n",
    "            import cudf\n",
    "            return cudf.from_pandas(df)\n",
    "        except Exception as e:\n",
    "            print(f'⚠️ GPU変換失敗、CPUモード継続: {e}')\n",
    "            return df\n",
    "    return df\n",
    "\n",
    "def to_cpu(df):\n",
    "    \"\"\"cuDFデータフレームをpandasに変換\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    try:\n",
    "        import cudf\n",
    "        if isinstance(df, cudf.DataFrame):\n",
    "            return df.to_pandas()\n",
    "    except:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "# GPUメモリ使用状況表示\n",
    "def show_gpu_memory():\n",
    "    if GPU_AVAILABLE:\n",
    "        try:\n",
    "            import torch\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "            print(f'📊 GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if USE_GPU and CUDF_AVAILABLE:\n",
    "    print('✅ GPU高速化ユーティリティ: 準備完了')\n",
    "    print('   to_gpu(df) でGPU処理、to_cpu(df) でCPU戻し')\n",
    "    show_gpu_memory()\n",
    "else:\n",
    "    print('ℹ️ CPU処理モード（GPUユーティリティは無効）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# フォント強制リセット（日本語対応 / AutoViz対策）\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "try:\n",
    "    import japanize_matplotlib; japanize_matplotlib.japanize()\n",
    "except Exception:\n",
    "    pass\n",
    "candidates = ['IPAGothic','IPAexGothic','Noto Sans CJK JP','Noto Sans JP','Yu Gothic','Meiryo','Hiragino Sans','MS Gothic']\n",
    "avail = []\n",
    "try:\n",
    "    names = [getattr(f,'name','') for f in fm.fontManager.ttflist]\n",
    "    for nm in candidates:\n",
    "        if any(nm in n for n in names):\n",
    "            if nm not in avail:\n",
    "                avail.append(nm)\n",
    "except Exception:\n",
    "    pass\n",
    "if not avail:\n",
    "    avail = ['Noto Sans CJK JP','IPAGothic','DejaVu Sans']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = avail + ['DejaVu Sans']\n",
    "plt.rcParams['font.serif'] = ['Noto Serif CJK JP','IPAMincho','DejaVu Serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "try:\n",
    "    sns.set_theme(rc={'font.family':'sans-serif','font.sans-serif': plt.rcParams['font.sans-serif']})\n",
    "except Exception:\n",
    "    pass\n",
    "print('フォント設定:', plt.rcParams['font.family'], '→', plt.rcParams['font.sans-serif'][:3], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8928fdd",
   "metadata": {},
   "source": [
    "## 📂 ステップ1: データ読み込み\n",
    "\n",
    "### 🎯 **このセクションの目的**\n",
    "売上データ（CSV形式）を自動検出して読み込みます。\n",
    "\n",
    "### 👀 **店長が確認すべきこと**\n",
    "実行後、以下のメッセージが表示されます：\n",
    "```\n",
    "[INFO] glob検出: output/06_final_enriched_20250701_20250930.csv\n",
    "[INFO] 列名変換: 8/8 件適用 → ['store_id', 'sku_id', 'date'...]\n",
    "読み込み完了: 06_final_enriched_20250930.csv | shape=(50000, 40) | memory=15.2MB\n",
    "```\n",
    "\n",
    "**意味**:\n",
    "- `shape=(50000, 40)` → 50,000行×40列のデータ\n",
    "- `memory=15.2MB` → メモリ使用量\n",
    "\n",
    "**判断ポイント**:\n",
    "- データが見つからない場合 → `output`フォルダにCSVファイルがあるか確認\n",
    "- メモリ不足エラーが出る場合 → データ期間を短縮検討\n",
    "\n",
    "---\n",
    "\n",
    "**次のセルを実行してください ↓**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ffb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_enriched_csv():\n",
    "    \"\"\"\n",
    "    enriched CSVファイルを自動検出\n",
    "    優先順: 環境変数 → glob最新 → 既定値\n",
    "    \"\"\"\n",
    "    for env in ('DATA_PATH','ENRICHED_CSV'):\n",
    "        p = os.environ.get(env)\n",
    "        if p and Path(p).exists():\n",
    "            print(f'[INFO] 環境変数 {env} からファイル取得: {p}')\n",
    "            return Path(p)\n",
    "    d = Path('output')\n",
    "    if d.exists():\n",
    "        c = sorted(d.glob('06_final_enriched_*.csv'), reverse=True)\n",
    "        if c:\n",
    "            print(f'[INFO] glob検出: {c[0]}')\n",
    "            return c[0]\n",
    "    f = Path('output/06_final_enriched_20250701_20250930.csv')\n",
    "    if f.exists():\n",
    "        print(f'[INFO] 既定ファイル使用: {f}')\n",
    "        return f\n",
    "    return None\n",
    "\n",
    "CSV_PATH = pick_enriched_csv()\n",
    "if not CSV_PATH:\n",
    "    raise FileNotFoundError('output/06_final_enriched_*.csv が見つかりません。work/output に配置、または環境変数 DATA_PATH で指定してください。')\n",
    "\n",
    "# メモリチェック（オプション）\n",
    "try:\n",
    "    import psutil\n",
    "    file_size_mb = CSV_PATH.stat().st_size / (1024**2)\n",
    "    available_mem_mb = psutil.virtual_memory().available / (1024**2)\n",
    "    if file_size_mb > available_mem_mb * 0.5:\n",
    "        print(f'[WARNING] ファイルサイズ {file_size_mb:.1f}MB が利用可能メモリの50%超')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "df_raw = pd.read_csv(CSV_PATH, encoding='utf-8-sig')\n",
    "df = df_raw.copy()\n",
    "\n",
    "# 列名正規化（存在すれば）\n",
    "rename_map = {\n",
    "    '店舗':'店舗','商品名':'商品名','日付':'日付','売上数量':'売上数量','売上金額':'売上金額',\n",
    "    'フェイスくくり大分類':'フェイスくくり大分類','フェイスくくり中分類':'フェイスくくり中分類','フェイスくくり小分類':'フェイスくくり小分類'\n",
    "}\n",
    "renamed = {k:v for k,v in rename_map.items() if k in df.columns}\n",
    "df = df.rename(columns=renamed)\n",
    "print(f'[INFO] 列名変換: {len(renamed)}/{len(rename_map)} 件適用 → {list(renamed.values())}')\n",
    "\n",
    "if '日付' in df.columns: df['日付'] = pd.to_datetime(df['日付'])\n",
    "if '売上数量' in df.columns: df['売上数量'] = pd.to_numeric(df['売上数量'], errors='coerce').fillna(0).astype('float32')\n",
    "if '売上金額' in df.columns: df['売上金額'] = pd.to_numeric(df['売上金額'], errors='coerce').fillna(0).astype('float32')\n",
    "\n",
    "print(f'読み込み完了: {CSV_PATH.name} | shape={df.shape} | memory={df.memory_usage(deep=True).sum()/(1024**2):.1f}MB')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e69d3f",
   "metadata": {},
   "source": [
    "## 📊 ステップ2: 売上最大化のためのフラグ別売上分析\n",
    "\n",
    "### 🎯 **このセクションの目的**\n",
    "**売上を最大化するために、どのフラグ（天候・曜日・イベント等）の日に売上が伸びるかを分析します。**\n",
    "\n",
    "### ⚠️ **重要な変更点（従来のAutoVizから変更）**\n",
    "- ❌ **削除**: 日付ベースの時系列プロット（日付と売上の比較）\n",
    "- ✅ **追加**: フラグ別の売上比較（降雨フラグ、週末フラグ等と売上の相関）\n",
    "- ✅ **追加**: 商品カテゴリ選択機能（特定カテゴリに絞った分析が可能）\n",
    "\n",
    "### 📈 **何が分析されるか**\n",
    "\n",
    "#### 1️⃣ **フラグ別売上増加率ランキング**\n",
    "- 各フラグ（降雨、週末、猛暑日など）がONの日とOFFの日で、売上がどれだけ変わるかを計算\n",
    "- 売上増加率が高いフラグ = 売上最大化のチャンス日\n",
    "\n",
    "#### 2️⃣ **フラグ別売上分布の可視化**\n",
    "- フラグON時とOFF時の売上分布を比較\n",
    "- どのフラグの日に高額売上が発生しやすいかを視覚的に把握\n",
    "\n",
    "#### 3️⃣ **カテゴリ別分析**\n",
    "- 商品カテゴリを選択して、カテゴリごとの売上パターンを分析\n",
    "- 例: 「飲料」カテゴリは猛暑日に売上↑、「おでん」は冬日に売上↑\n",
    "\n",
    "### 👀 **店長が確認すべきこと**\n",
    "\n",
    "#### ✅ **実行後に表示される情報**\n",
    "1. **フラグ別売上増加率 TOP10 テーブル**\n",
    "   - 各フラグのON/OFF時の平均売上\n",
    "   - 売上増加率（%）\n",
    "   - 該当日数\n",
    "\n",
    "2. **フラグ別売上増加率の棒グラフ**\n",
    "   - 赤い棒（プラス）: このフラグの日は売上が増加 → **陳列・発注を強化すべき日**\n",
    "   - 青い棒（マイナス）: このフラグの日は売上が減少 → 在庫を抑制\n",
    "\n",
    "3. **上位5フラグのON/OFF売上分布グラフ**\n",
    "   - 赤い分布（フラグON）が右にシフト → そのフラグの日は高額売上が発生しやすい\n",
    "   - 青い分布（フラグOFF）との差が大きい → そのフラグの影響が大きい\n",
    "\n",
    "### 💡 **店長の実務アクション**\n",
    "\n",
    "#### 🎯 **売上増加率が高いフラグが見つかった場合**\n",
    "\n",
    "**例: 「降雨フラグ」の売上増加率 +25%**\n",
    "→ **アクション**:\n",
    "- 降雨予報の日の前日に、温かい総菜・カップ麺・ホット飲料の発注を1.3倍に増やす\n",
    "- 入口付近に傘・レインコート・ホット商品の特設コーナーを設置\n",
    "- 中華まん・おでんのフェースを拡大\n",
    "\n",
    "**例: 「週末フラグ」の売上増加率 +18%**\n",
    "→ **アクション**:\n",
    "- 金曜夕方から弁当・デザート・酒類の陳列を強化\n",
    "- 土日の朝は朝食需要（パン・コーヒー）、昼は弁当、夕方は酒類のピーク対応\n",
    "- 家族向け大容量商品のフェース拡大\n",
    "\n",
    "**例: 「給料日フラグ」の売上増加率 +12%**\n",
    "→ **アクション**:\n",
    "- 給料日（25日前後）は高単価弁当・スイーツ・プレミアム商品を目立つ位置に\n",
    "- 夕方の前出し時間を早める（17時→16時30分）\n",
    "\n",
    "#### 📊 **カテゴリ選択の活用方法**\n",
    "\n",
    "上のウィジェット（SelectMultiple）で商品カテゴリを選択すると、そのカテゴリに特化したフラグ分析が再実行されます。\n",
    "\n",
    "**使い方**:\n",
    "1. ウィジェットから分析したいカテゴリを選択（Ctrl/Cmd + クリックで複数選択）\n",
    "2. 自動で再分析が実行され、そのカテゴリの売上最大化フラグが表示される\n",
    "3. カテゴリごとの最適な発注・陳列戦略を立てる\n",
    "\n",
    "**例**:\n",
    "- **「飲料」**を選択 → 「猛暑日」「真夏日」フラグで売上↑ → 夏日の冷飲料発注強化\n",
    "- **「弁当」**を選択 → 「週末フラグ」「昼ピーク」で売上↑ → 土日の弁当発注1.5倍\n",
    "- **「デザート」**を選択 → 「給料日」「週末」で売上↑ → 高単価スイーツ陳列強化\n",
    "\n",
    "### 🚀 **実行方法**\n",
    "下のセルを実行してください。自動で以下が行われます:\n",
    "1. カテゴリ選択ウィジェットの表示（複数選択可）\n",
    "2. 全カテゴリでのフラグ別売上分析\n",
    "3. TOP10フラグの表示とグラフ可視化\n",
    "4. カテゴリ選択時の自動再分析\n",
    "\n",
    "### 💾 **GPU高速化について**\n",
    "- このセルでは主にグラフ描画を行うため、GPU効果は限定的です\n",
    "- 次のステップ（PyCaret）で大規模なAI学習が実行され、GPUの効果が最大化されます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 📊 売上最大化分析: フラグ別売上比較（全カテゴリ）\n",
    "# ========================================\n",
    "print('\\n' + '='*60)\n",
    "print('📊 売上最大化分析: フラグ別売上比較')\n",
    "print('='*60)\n",
    "\n",
    "# カテゴリフィルタ（オプション：コメントアウトを外して使用）\n",
    "# selected_categories = ['全カテゴリ']  # または ['菓子', '飲料'] のように指定\n",
    "selected_categories = ['全カテゴリ']\n",
    "\n",
    "def analyze_sales_by_flags():\n",
    "    \"\"\"フラグ別売上分析の実行\"\"\"\n",
    "    \n",
    "    # データ存在確認\n",
    "    if 'df' not in globals():\n",
    "        print('⚠️ データフレーム \"df\" が見つかりません。先にステップ1でデータを読み込んでください。')\n",
    "        return\n",
    "    \n",
    "    # カテゴリフィルタ適用\n",
    "    df_filtered = df.copy()\n",
    "    if '全カテゴリ' not in selected_categories and 'フェイスくくり大分類' in df.columns:\n",
    "        df_filtered = df_filtered[df_filtered['フェイスくくり大分類'].isin(selected_categories)]\n",
    "        print(f'✅ フィルタ適用: {selected_categories} ({len(df_filtered):,}件)')\n",
    "    else:\n",
    "        print('ℹ️ 全カテゴリで分析します')\n",
    "    \n",
    "    # デバッグ: カラム名を表示\n",
    "    print(f'\\n📋 利用可能なカラム数: {len(df_filtered.columns)}')\n",
    "    flag_like_cols = [c for c in df_filtered.columns if 'flag' in c.lower() or c.startswith('is_') or c.startswith('has_')]\n",
    "    \n",
    "    if flag_like_cols:\n",
    "        print(f'📌 フラグ系カラム候補: {len(flag_like_cols)}個')\n",
    "        for i, col in enumerate(flag_like_cols[:20], 1):  # 最初の20個まで表示\n",
    "            print(f'  {i}. {col}')\n",
    "        if len(flag_like_cols) > 20:\n",
    "            print(f'  ... 他 {len(flag_like_cols)-20}個')\n",
    "    \n",
    "    # フラグカラム検出（柔軟な検索）\n",
    "    flag_cols = []\n",
    "    \n",
    "    # パターン1: flag_ プレフィックス\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.startswith('flag_')])\n",
    "    \n",
    "    # パターン2: is_ プレフィックス（ブール値）\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.startswith('is_')])\n",
    "    \n",
    "    # パターン3: has_ プレフィックス\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.startswith('has_')])\n",
    "    \n",
    "    # パターン4: 日本語フラグ（_フラグ で終わる）\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.endswith('_フラグ') or c.endswith('フラグ')])\n",
    "    \n",
    "    # 重複削除\n",
    "    flag_cols = list(set(flag_cols))\n",
    "    \n",
    "    if not flag_cols:\n",
    "        print('\\n⚠️ フラグカラムが見つかりません')\n",
    "        print('\\n💡 以下のいずれかの形式でフラグカラムを作成してください:')\n",
    "        print('  - flag_雨天日')\n",
    "        print('  - is_weekend')\n",
    "        print('  - has_event')\n",
    "        print('  - イベント_フラグ')\n",
    "        print('\\n📌 現在のカラムで数値型（0/1の候補）:')\n",
    "        numeric_binary = []\n",
    "        for col in df_filtered.select_dtypes(include=[np.number]).columns:\n",
    "            unique_vals = df_filtered[col].dropna().unique()\n",
    "            if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, 0.0, 1.0}):\n",
    "                numeric_binary.append(col)\n",
    "        \n",
    "        if numeric_binary:\n",
    "            for i, col in enumerate(numeric_binary[:10], 1):\n",
    "                print(f'  {i}. {col}')\n",
    "            print('\\n💡 これらのカラムを \"flag_\" プレフィックス付きに変更すると分析できます')\n",
    "        else:\n",
    "            print('  なし（0/1の2値カラムが見つかりません）')\n",
    "        return\n",
    "    \n",
    "    print(f'\\n📌 分析対象フラグ: {len(flag_cols)}個')\n",
    "    for i, col in enumerate(flag_cols, 1):\n",
    "        print(f'  {i}. {col}')\n",
    "    \n",
    "    # 売上カラム検出\n",
    "    sales_col = None\n",
    "    for col_name in ['売上金額', '売上金額', 'sales', 'amount', '売上']:\n",
    "        if col_name in df_filtered.columns:\n",
    "            sales_col = col_name\n",
    "            break\n",
    "    \n",
    "    if sales_col is None:\n",
    "        print('\\n⚠️ 売上カラムが見つかりません')\n",
    "        print('💡 以下のカラム名を使用してください: sales_amt, 売上金額, sales, amount')\n",
    "        return\n",
    "    \n",
    "    print(f'\\n💰 売上カラム: {sales_col}')\n",
    "    \n",
    "    # フラグ別集計\n",
    "    results = []\n",
    "    for fc in flag_cols:\n",
    "        # 0/1以外の値をチェック\n",
    "        unique_vals = df_filtered[fc].dropna().unique()\n",
    "        if not set(unique_vals).issubset({0, 1, 0.0, 1.0, True, False}):\n",
    "            print(f'⚠️ スキップ: {fc} (0/1以外の値を含む: {unique_vals})')\n",
    "            continue\n",
    "        \n",
    "        flag_on = df_filtered[df_filtered[fc].isin([1, 1.0, True])]\n",
    "        flag_off = df_filtered[df_filtered[fc].isin([0, 0.0, False])]\n",
    "        \n",
    "        if len(flag_on) == 0 or len(flag_off) == 0:\n",
    "            continue\n",
    "        \n",
    "        on_mean = flag_on[sales_col].mean()\n",
    "        off_mean = flag_off[sales_col].mean()\n",
    "        on_sum = flag_on[sales_col].sum()\n",
    "        off_sum = flag_off[sales_col].sum()\n",
    "        \n",
    "        mean_diff = on_mean - off_mean\n",
    "        mean_lift = (mean_diff / off_mean * 100) if off_mean > 0 else 0\n",
    "        \n",
    "        # プレフィックスを削除して表示名を作成\n",
    "        display_name = fc.replace('flag_', '').replace('is_', '').replace('has_', '').replace('_フラグ', '')\n",
    "        \n",
    "        results.append({\n",
    "            'フラグ': display_name,\n",
    "            'ON件数': len(flag_on),\n",
    "            'OFF件数': len(flag_off),\n",
    "            'ON平均': on_mean,\n",
    "            'OFF平均': off_mean,\n",
    "            '平均差': mean_diff,\n",
    "            '平均リフト(%)': mean_lift,\n",
    "            'ON合計': on_sum,\n",
    "            'OFF合計': off_sum,\n",
    "            '合計差': on_sum - off_sum\n",
    "        })\n",
    "    \n",
    "    if not results:\n",
    "        print('⚠️ 分析可能なデータがありません')\n",
    "        return\n",
    "    \n",
    "    # 結果をDataFrameに変換\n",
    "    df_result = pd.DataFrame(results).sort_values('平均リフト(%)', ascending=False)\n",
    "    \n",
    "    # 可視化: 4パネル\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('📊 フラグ別売上インパクト分析', fontsize=16, fontproperties=font_setup.jp_font)\n",
    "    \n",
    "    # 1. 平均リフト率\n",
    "    ax1 = axes[0, 0]\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_result['平均リフト(%)']]\n",
    "    ax1.barh(df_result['フラグ'], df_result['平均リフト(%)'], color=colors, alpha=0.7)\n",
    "    ax1.set_xlabel('平均リフト率 (%)', fontproperties=font_setup.jp_font)\n",
    "    ax1.set_title('1️⃣ 平均売上リフト率（ON時の増減）', fontproperties=font_setup.jp_font)\n",
    "    ax1.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 2. ON/OFF平均売上比較\n",
    "    ax2 = axes[0, 1]\n",
    "    x = np.arange(len(df_result))\n",
    "    width = 0.35\n",
    "    ax2.bar(x - width/2, df_result['OFF平均'], width, label='OFF', alpha=0.7, color='lightcoral')\n",
    "    ax2.bar(x + width/2, df_result['ON平均'], width, label='ON', alpha=0.7, color='skyblue')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(df_result['フラグ'], rotation=45, ha='right', fontproperties=font_setup.jp_font)\n",
    "    ax2.set_ylabel('平均売上（円）', fontproperties=font_setup.jp_font)\n",
    "    ax2.set_title('2️⃣ ON/OFF時の平均売上比較', fontproperties=font_setup.jp_font)\n",
    "    ax2.legend(prop=font_setup.jp_font)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 3. 件数分布\n",
    "    ax3 = axes[1, 0]\n",
    "    x = np.arange(len(df_result))\n",
    "    ax3.bar(x - width/2, df_result['OFF件数'], width, label='OFF', alpha=0.7, color='lightcoral')\n",
    "    ax3.bar(x + width/2, df_result['ON件数'], width, label='ON', alpha=0.7, color='skyblue')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(df_result['フラグ'], rotation=45, ha='right', fontproperties=font_setup.jp_font)\n",
    "    ax3.set_ylabel('件数', fontproperties=font_setup.jp_font)\n",
    "    ax3.set_title('3️⃣ ON/OFF時のデータ件数', fontproperties=font_setup.jp_font)\n",
    "    ax3.legend(prop=font_setup.jp_font)\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. 合計売上インパクト\n",
    "    ax4 = axes[1, 1]\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_result['合計差']]\n",
    "    ax4.barh(df_result['フラグ'], df_result['合計差']/1000, color=colors, alpha=0.7)\n",
    "    ax4.set_xlabel('合計売上差（千円）', fontproperties=font_setup.jp_font)\n",
    "    ax4.set_title('4️⃣ 合計売上インパクト（ON-OFF）', fontproperties=font_setup.jp_font)\n",
    "    ax4.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax4.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 数値表示\n",
    "    print('\\n' + '='*80)\n",
    "    print('📊 フラグ別売上分析結果')\n",
    "    print('='*80)\n",
    "    display(df_result.style.format({\n",
    "        'ON平均': '{:,.0f}円',\n",
    "        'OFF平均': '{:,.0f}円',\n",
    "        '平均差': '{:,.0f}円',\n",
    "        '平均リフト(%)': '{:+.1f}%',\n",
    "        'ON合計': '{:,.0f}円',\n",
    "        'OFF合計': '{:,.0f}円',\n",
    "        '合計差': '{:,.0f}円'\n",
    "    }).background_gradient(subset=['平均リフト(%)'], cmap='RdYlGn', vmin=-20, vmax=20))\n",
    "    \n",
    "    # トップ3推奨\n",
    "    print('\\n' + '='*80)\n",
    "    print('💡 売上最大化のアクション推奨（平均リフト率トップ3）')\n",
    "    print('='*80)\n",
    "    for i, (idx, row) in enumerate(df_result.head(3).iterrows(), 1):\n",
    "        print(f\"\\n{i}. **{row['フラグ']}**\")\n",
    "        print(f\"   平均リフト: {row['平均リフト(%)']:+.1f}% | ON平均: {row['ON平均']:,.0f}円 vs OFF平均: {row['OFF平均']:,.0f}円\")\n",
    "        print(f\"   推奨: {row['フラグ']}を積極的に活用してください\")\n",
    "\n",
    "# 分析を自動実行\n",
    "analyze_sales_by_flags()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bc7ad",
   "metadata": {},
   "source": [
    "## 🔧 ステップ3: 特徴量テーブルの作成\n",
    "\n",
    "### 🎯 **このセクションの目的**\n",
    "AIが分析しやすいように、データを日次×店舗単位に整理します。\n",
    "\n",
    "### 👀 **店長が確認すべきこと**\n",
    "実行後、以下のメッセージが表示されます：\n",
    "```\n",
    "[INFO] 利用可能特徴量: 28/30 個\n",
    "[INFO] カテゴリカル変数: ['category_l', 'category_m', 'store_id']\n",
    "[INFO] 特徴量テーブル: (2500, 35) (行×列)\n",
    "[INFO] 欠損値: 150 個\n",
    "```\n",
    "\n",
    "**意味**:\n",
    "- **28個の要因**（気温、曜日、天気など）を使用\n",
    "- **2,500日分**のデータで分析\n",
    "- 欠損値は自動処理される\n",
    "\n",
    "### 💡 **追加された特徴量の意味**\n",
    "このセルで、以下の便利な特徴量が自動追加されます：\n",
    "\n",
    "| 特徴量 | 意味 | 実務での活用 |\n",
    "|--------|------|------------|\n",
    "| `sales_lag_1` | 前日の売上 | 「昨日売れたから今日も売れる」パターン発見 |\n",
    "| `sales_lag_7` | 1週間前の売上 | 「先週の月曜と今週の月曜は似ている」パターン発見 |\n",
    "| `sales_rolling_7` | 7日移動平均 | トレンド把握（売上が伸びているか下がっているか） |\n",
    "| `day_of_week` | 曜日（0=月曜、6=日曜） | 曜日別の売上パターン分析 |\n",
    "| `is_weekend` | 週末フラグ（土日=1） | 週末効果の測定 |\n",
    "\n",
    "**判断ポイント**:\n",
    "- 欠損値が50%超の列 → 自動で除外される\n",
    "- 特徴量が10個未満 → データ期間を延長検討\n",
    "\n",
    "このセルは自動実行するだけでOKです。\n",
    "\n",
    "---\n",
    "\n",
    "**次のセルを実行してください ↓**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f96b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全ての数値列を特徴量として使用（事前の絞り込みなし）\n",
    "print('[INFO] データに含まれる全ての列を使用します（事前絞り込みなし）')\n",
    "\n",
    "# 除外すべき列（分析対象でない列）\n",
    "exclude_cols = ['店舗', '商品名', '日付', '日付', '店舗', '商品名', \n",
    "                'フェイスくくり大分類', 'フェイスくくり中分類', 'フェイスくくり小分類',\n",
    "                'フェイスくくり大分類', 'フェイスくくり中分類', 'フェイスくくり小分類',\n",
    "                '売上金額', '売上金額', 'price',  # 売上数量(qty)は目的変数なので除外しない\n",
    "                '昨年同日_売上', '昨年同日_客数', '昨年同日_客単価']  # 目的変数と関連列を除外\n",
    "\n",
    "# 全列リスト\n",
    "all_cols = df.columns.tolist()\n",
    "\n",
    "# 数値列のみ抽出（文字列・日付型を除く）\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# 特徴量候補：数値列から除外列を引く\n",
    "# 特徴量候補：数値列から除外列を引く（qtyも明示的に除外）\n",
    "feature_cols = [c for c in numeric_cols if c not in exclude_cols and c not in ['売上数量', '売上数量']]\n",
    "\n",
    "print(f'[INFO] 全列数: {len(all_cols)}')\n",
    "print(f'[INFO] 数値列数: {len(numeric_cols)}')\n",
    "print(f'[INFO] 除外列数: {len([c for c in exclude_cols if c in all_cols])}')\n",
    "print(f'[INFO] 使用する特徴量: {len(feature_cols)} 個')\n",
    "print(f'\\n[特徴量リスト（全{len(feature_cols)}個）]:')\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f'  {i}. {col}')\n",
    "\n",
    "# カテゴリカル変数の確認\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_present = [c for c in categorical_cols if c not in exclude_cols and c in df.columns]\n",
    "print(f'\\n[INFO] カテゴリカル変数: {len(categorical_present)} 個 → {categorical_present}')\n",
    "\n",
    "# 基本テーブル構築（全ての数値特徴量を使用）\n",
    "keep = ['日付', '店舗', '売上数量'] + feature_cols\n",
    "tmp = df[[c for c in keep if c in df.columns]].copy()\n",
    "\n",
    "# 日付×店舗で特徴量を代表化（数値は平均）、売上は合計\n",
    "# qtyが feature_cols に含まれている場合は除外（目的変数なので特徴量としては使わない）\n",
    "feature_cols_for_agg = [c for c in feature_cols if c not in ['売上数量', '売上数量']]\n",
    "Xdf = tmp.groupby(['日付','店舗'], as_index=False)[feature_cols_for_agg].mean() if feature_cols_for_agg else tmp[['日付','店舗']].drop_duplicates()\n",
    "ydf = tmp.groupby(['日付','店舗'], as_index=False)['売上数量'].sum()\n",
    "feat = Xdf.merge(ydf, on=['日付','店舗'], how='inner')\n",
    "\n",
    "# qtyが存在することを確認\n",
    "if '売上数量' not in feat.columns:\n",
    "    print('[ERROR] qty列が見つかりません！データを確認してください')\n",
    "else:\n",
    "    qty_sum = feat[\"売上数量\"].sum()\n",
    "    qty_mean = feat[\"売上数量\"].mean()\n",
    "    print(f'[INFO] qty列を確認: 合計={qty_sum:,.0f}個, 平均={qty_mean:.1f}個/日')\n",
    "    print(f'[DEBUG] qty列の型: {feat[\"売上数量\"].dtype}, NaN数: {feat[\"売上数量\"].isna().sum()}')\n",
    "\n",
    "# カテゴリカル変数の追加（元データから）\n",
    "if categorical_present:\n",
    "    cat_data = df[['日付','店舗'] + categorical_present].drop_duplicates()\n",
    "    feat = feat.merge(cat_data, on=['日付','店舗'], how='left')\n",
    "\n",
    "# 重複列名のチェックと削除\n",
    "duplicate_cols = feat.columns[feat.columns.duplicated()].tolist()\n",
    "if duplicate_cols:\n",
    "    print(f'[WARNING] 重複列名を検出: {duplicate_cols}')\n",
    "    # 重複列を削除（最初の列のみ残す）\n",
    "    feat = feat.loc[:, ~feat.columns.duplicated()]\n",
    "    print(f'[INFO] 重複列を削除後: {feat.shape}')\n",
    "    print(f'[INFO] カテゴリカル変数をマージ: {categorical_present}')\n",
    "\n",
    "print(f'\\n[INFO] 特徴量テーブル: {feat.shape} (行×列)')\n",
    "print(f'[INFO] 欠損値: {feat.isnull().sum().sum()} 個 ({feat.isnull().sum().sum() / feat.size * 100:.2f}%)')\n",
    "\n",
    "# 欠損値が多い列を警告\n",
    "missing_ratio = feat.isnull().sum() / len(feat)\n",
    "high_missing = missing_ratio[missing_ratio > 0.5].sort_values(ascending=False)\n",
    "if not high_missing.empty:\n",
    "    print(f'\\n[WARNING] 欠損値50%超の列（{len(high_missing)}個）:')\n",
    "    for col, ratio in high_missing.items():\n",
    "        print(f'  - {col}: {ratio*100:.1f}% 欠損')\n",
    "\n",
    "feat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc776dc",
   "metadata": {},
   "source": [
    "## 🤖 ステップ4: PyCaret — AIで売上予測モデルを作成\n",
    "\n",
    "### 🎯 **このセクションの目的**\n",
    "**PyCaretを使って、売上を予測するAIモデルを自動的に作成します。**\n",
    "\n",
    "---\n",
    "\n",
    "### 📋 **PyCaretが自動でやってくれること**\n",
    "\n",
    "1. **15～20種類のAIモデルを一括比較**\n",
    "   - LightGBM、XGBoost、CatBoost（GPU対応）\n",
    "   - ランダムフォレスト、決定木、線形回帰\n",
    "   - その他の高度なモデル\n",
    "\n",
    "2. **データの前処理**\n",
    "   - 欠損値の補完\n",
    "   - 外れ値の検出\n",
    "   - 特徴量のスケーリング（正規化）\n",
    "\n",
    "3. **交差検証（3-Fold CV）**\n",
    "   - データを3分割して、過学習を防ぎながら精度を評価\n",
    "\n",
    "4. **最良モデルの自動選択**\n",
    "   - R²スコアが最も高いモデルを選択\n",
    "\n",
    "---\n",
    "\n",
    "### 👀 **店長が確認すべきこと**\n",
    "\n",
    "#### 1️⃣ **モデル比較結果（Leaderboard）**\n",
    "実行後、以下のような表が表示されます：\n",
    "\n",
    "| Model | R2 | RMSE | MAE | 実行時間 |\n",
    "|-------|-----|------|-----|---------|\n",
    "| LightGBM | 0.85 | 1200 | 950 | 2.3秒 |\n",
    "| XGBoost | 0.83 | 1350 | 1020 | 3.1秒 |\n",
    "| CatBoost | 0.82 | 1400 | 1080 | 2.8秒 |\n",
    "\n",
    "**重要指標の読み方：**\n",
    "- **R² (決定係数)**: 0～1の範囲。**0.7以上なら実用レベル**、0.8以上なら高精度\n",
    "  - 0.85 = 売上変動の85%をAIが説明できている\n",
    "- **RMSE (平均二乗誤差)**: 予測誤差の大きさ（円単位）。**小さいほど良い**\n",
    "- **MAE (平均絶対誤差)**: より直感的な誤差（円単位）。**日々の売上±この金額の範囲で予測**\n",
    "\n",
    "#### 2️⃣ **GPU加速の確認**\n",
    "```\n",
    "🚀 [INFO] GPU使用モードで実行（LightGBM/XGBoost/CatBoost対応）\n",
    "⏱️ 実行時間: 23.4秒\n",
    "💡 GPUにより高速化されました\n",
    "```\n",
    "↑ このメッセージが表示されればGPU加速が有効です（CPU版の約10倍高速）\n",
    "\n",
    "#### 3️⃣ **特徴量重要度グラフ**\n",
    "「どの要素が売上に効いているか」を可視化：\n",
    "- **天気**（flag_weather_rain）が重要 → 雨の日対策が必要\n",
    "- **曜日**（flag_dow_土曜）が重要 → 週末の品揃えが鍵\n",
    "- **イベント**（flag_event_給料日）が重要 → 給料日セールが効果的\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ **GPU設定の詳細**\n",
    "\n",
    "PyCaretは以下のGPUパラメータを自動設定します：\n",
    "\n",
    "```python\n",
    "# LightGBM GPU設定\n",
    "'device': 'gpu'\n",
    "'gpu_platform_id': 0\n",
    "'gpu_device_id': 0\n",
    "\n",
    "# XGBoost GPU設定  \n",
    "'tree_method': 'gpu_hist'\n",
    "'gpu_id': 0\n",
    "\n",
    "# CatBoost GPU設定\n",
    "'task_type': 'GPU'\n",
    "'devices': '0'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **注意事項**\n",
    "\n",
    "1. **最低データ数**: 100行以上必要（少ないとエラーになります）\n",
    "2. **実行時間**: データ量により1～5分程度かかります\n",
    "3. **GPU非搭載の場合**: 自動的にCPUモードで実行されます（やや遅くなります）\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **次のステップ**\n",
    "このステップで学習したモデル（`final`変数）を使って、ステップ5で予測結果の可視化を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 🤖 ステップ4: PyCaret実行（GPU自動検出 + CPUフォールバック）\n",
    "# ========================================\n",
    "\n",
    "if PYC_OK and 'feat' in locals() and len(feat) >= MIN_SAMPLES_PYCARET:\n",
    "    print(f'[INFO] PyCaret開始: {len(feat)}行 (>= {MIN_SAMPLES_PYCARET}行)')\n",
    "    \n",
    "    # PyCaretセットアップ用データ準備\n",
    "    data = feat.drop(columns=['日付','店舗'], errors='ignore').copy()\n",
    "    \n",
    "    # 欠損値が多い列を削除（50%以上欠損）※ただし目的変数qtyは保護\n",
    "    missing_ratio = data.isnull().sum() / len(data)\n",
    "    drop_cols = missing_ratio[missing_ratio > 0.5].index.tolist()\n",
    "    # 目的変数qtyを除外リストから削除（保護）\n",
    "    if '売上数量' in drop_cols:\n",
    "        drop_cols.remove('売上数量')\n",
    "    if drop_cols:\n",
    "        print(f'[WARNING] 欠損値50%超の列を除外: {drop_cols}')\n",
    "        data = data.drop(columns=drop_cols)\n",
    "    \n",
    "    print(f'[INFO] 学習データ: {data.shape} | 目的変数: qty (販売数量)')\n",
    "    print(f'[DEBUG] data.columns に qty が存在: {\"売上数量\" in data.columns}')\n",
    "    print(f'[DEBUG] data.columns: {list(data.columns[:10])}...')\n",
    "    if '売上数量' in data.columns:\n",
    "        print(f'[DEBUG] qty統計: min={data[\"売上数量\"].min()}, max={data[\"売上数量\"].max()}, mean={data[\"売上数量\"].mean():.2f}')\n",
    "    else:\n",
    "        print(f'[ERROR] qty列がdataに存在しません！')\n",
    "        print(f'[ERROR] 利用可能な列: {list(data.columns)}')\n",
    "    \n",
    "    # ========================================\n",
    "    # 🚀 GPU対応チェック（各ライブラリの実際の対応状況を確認）\n",
    "    # ========================================\n",
    "    \n",
    "    def check_lightgbm_gpu():\n",
    "        \"\"\"LightGBMのGPU対応を確認\"\"\"\n",
    "        try:\n",
    "            import lightgbm as lgb\n",
    "            # テストデータでGPU動作確認\n",
    "            test_data = [[1, 2], [3, 4]]\n",
    "            test_label = [1, 2]\n",
    "            lgb_train = lgb.Dataset(test_data, test_label)\n",
    "            params = {'device': 'gpu', 'verbosity': -1}\n",
    "            lgb.train(params, lgb_train, num_boost_round=1)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    def check_xgboost_gpu():\n",
    "        \"\"\"XGBoostのGPU対応を確認\"\"\"\n",
    "        try:\n",
    "            import xgboost as xgb\n",
    "            # テストデータでGPU動作確認\n",
    "            dtrain = xgb.DMatrix([[1, 2], [3, 4]], label=[1, 2])\n",
    "            params = {'tree_method': 'gpu_hist', 'verbosity': 0}\n",
    "            xgb.train(params, dtrain, num_boost_round=1)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    def check_catboost_gpu():\n",
    "        \"\"\"CatBoostのGPU対応を確認\"\"\"\n",
    "        try:\n",
    "            from catboost import CatBoostRegressor\n",
    "            model = CatBoostRegressor(task_type='GPU', iterations=1, verbose=0)\n",
    "            model.fit([[1, 2], [3, 4]], [1, 2])\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    # GPU対応状況の確認\n",
    "    print('\\n🔍 [INFO] GPU対応状況を確認中...')\n",
    "    \n",
    "    lightgbm_gpu = False\n",
    "    xgboost_gpu = False\n",
    "    catboost_gpu = False\n",
    "    \n",
    "    if USE_GPU and GPU_AVAILABLE:\n",
    "        lightgbm_gpu = check_lightgbm_gpu()\n",
    "        xgboost_gpu = check_xgboost_gpu()\n",
    "        catboost_gpu = check_catboost_gpu()\n",
    "        \n",
    "        print(f'  LightGBM GPU: {\"✅ 利用可能\" if lightgbm_gpu else \"❌ 未対応（CPUフォールバック）\"}')\n",
    "        print(f'  XGBoost GPU: {\"✅ 利用可能\" if xgboost_gpu else \"❌ 未対応（CPUフォールバック）\"}')\n",
    "        print(f'  CatBoost GPU: {\"✅ 利用可能\" if catboost_gpu else \"❌ 未対応（CPUフォールバック）\"}')\n",
    "        \n",
    "        if not any([lightgbm_gpu, xgboost_gpu, catboost_gpu]):\n",
    "            print('\\n⚠️ [WARNING] GPU対応ライブラリがインストールされていません')\n",
    "            print('💡 CPUモードで実行します（精度は同じですが速度は遅くなります）')\n",
    "            print('\\n📝 GPU対応版のインストール方法:')\n",
    "            print('  pip install lightgbm --install-option=--gpu')\n",
    "            print('  pip install xgboost[gpu]')\n",
    "            print('  pip install catboost --install-option=\"--features=GPU\"')\n",
    "    else:\n",
    "        print('  ℹ️ GPUが検出されていないため、CPUモードで実行します')\n",
    "    \n",
    "    try:\n",
    "        # ========================================\n",
    "        # 📊 PyCaretセットアップ（並列処理有効化）\n",
    "        # ========================================\n",
    "        import time\n",
    "        setup_start = time.time()\n",
    "        \n",
    "        _ = setup(\n",
    "            data=data, \n",
    "            target='売上数量', \n",
    "            session_id=42, \n",
    "            fold=3,\n",
    "            verbose=False,\n",
    "            normalize=True,\n",
    "            transformation=True,\n",
    "            ignore_features=['sales_lag_1', 'sales_lag_7', 'sales_rolling_7'],\n",
    "            n_jobs=-1,  # 全CPUコアを使用（並列処理）\n",
    "        )\n",
    "        \n",
    "        setup_time = time.time() - setup_start\n",
    "        print(f'\\n✅ [INFO] セットアップ完了: {setup_time:.1f}秒')\n",
    "        \n",
    "        # ========================================\n",
    "        # 🚀 モデル比較（並列実行 + 自動GPU設定）\n",
    "        # ========================================\n",
    "        print('\\n[INFO] モデル比較実行中（全モデル並列実行）...')\n",
    "        print('[INFO] 比較対象: PyCaretの全回帰モデル（15～20種類）')\n",
    "        \n",
    "        if any([lightgbm_gpu, xgboost_gpu, catboost_gpu]):\n",
    "            print('[INFO] ✅ 一部モデルでGPU加速有効')\n",
    "        else:\n",
    "            print('[INFO] ℹ️ CPUモード（全コア並列実行）')\n",
    "        \n",
    "        print('[INFO] ※ 実行に数分かかる場合があります')\n",
    "        \n",
    "        compare_start = time.time()\n",
    "        \n",
    "        # 全モデル比較実行（PyCaretが自動で最適化）\n",
    "        best = compare_models(\n",
    "            sort='R2',\n",
    "            n_select=1,\n",
    "            turbo=True,  # 高速モード\n",
    "        )\n",
    "        \n",
    "        compare_time = time.time() - compare_start\n",
    "        \n",
    "        leaderboard = pull()\n",
    "        print('\\n[SUCCESS] モデル比較完了')\n",
    "        print(f'⏱️ 実行時間: {compare_time:.1f}秒')\n",
    "        \n",
    "        if any([lightgbm_gpu, xgboost_gpu, catboost_gpu]):\n",
    "            print('💡 一部モデルでGPUにより高速化されました')\n",
    "        \n",
    "        print(f'\\n📊 全{len(leaderboard)}モデルの比較結果:')\n",
    "        display(leaderboard)\n",
    "        \n",
    "        # ========================================\n",
    "        # 🎯 最良モデルのファイナライズ\n",
    "        # ========================================\n",
    "        finalize_start = time.time()\n",
    "        \n",
    "        final = finalize_model(best)\n",
    "        \n",
    "        finalize_time = time.time() - finalize_start\n",
    "        \n",
    "        print(f'\\n[INFO] 最良モデル: {type(best).__name__}')\n",
    "        print(f'[INFO] R2スコア: {leaderboard.iloc[0][\"R2\"]:.4f}')\n",
    "        print(f'[INFO] RMSE: {leaderboard.iloc[0][\"RMSE\"]:.2f}')\n",
    "        print(f'[INFO] MAE: {leaderboard.iloc[0][\"MAE\"]:.2f}')\n",
    "        print(f'[INFO] ファイナライズ時間: {finalize_time:.1f}秒')\n",
    "        \n",
    "        # モデルタイプを確認してGPU使用状況を表示\n",
    "        model_name = type(best).__name__\n",
    "        if 'LGBM' in model_name:\n",
    "            gpu_status = '✅ GPU' if lightgbm_gpu else 'ℹ️ CPU'\n",
    "            print(f'[INFO] LightGBM: {gpu_status}モードで学習')\n",
    "        elif 'XGB' in model_name:\n",
    "            gpu_status = '✅ GPU' if xgboost_gpu else 'ℹ️ CPU'\n",
    "            print(f'[INFO] XGBoost: {gpu_status}モードで学習')\n",
    "        elif 'CatBoost' in model_name:\n",
    "            gpu_status = '✅ GPU' if catboost_gpu else 'ℹ️ CPU'\n",
    "            print(f'[INFO] CatBoost: {gpu_status}モードで学習')\n",
    "        else:\n",
    "            print(f'[INFO] {model_name}: CPUモードで学習')\n",
    "        \n",
    "        # ========================================\n",
    "        # 📊 可視化\n",
    "        # ========================================\n",
    "        try:\n",
    "            print('\\n[INFO] 特徴量重要度プロット')\n",
    "            plot_model(final, plot='feature')\n",
    "        except Exception as e:\n",
    "            print(f'[WARNING] 特徴量プロット失敗: {e}')\n",
    "        \n",
    "        try:\n",
    "            print('\\n[INFO] 残差プロット')\n",
    "            plot_model(final, plot='residuals')\n",
    "        except Exception as e:\n",
    "            print(f'[WARNING] 残差プロット失敗: {e}')\n",
    "        \n",
    "        # ========================================\n",
    "        # ⏱️ パフォーマンスサマリー\n",
    "        # ========================================\n",
    "        total_time = setup_time + compare_time + finalize_time\n",
    "        print('\\n' + '='*60)\n",
    "        print('⏱️ パフォーマンスサマリー')\n",
    "        print('='*60)\n",
    "        print(f'セットアップ: {setup_time:.1f}秒')\n",
    "        print(f'モデル比較: {compare_time:.1f}秒 ({len(leaderboard)}モデル)')\n",
    "        print(f'ファイナライズ: {finalize_time:.1f}秒')\n",
    "        print(f'合計時間: {total_time:.1f}秒')\n",
    "        \n",
    "        gpu_count = sum([lightgbm_gpu, xgboost_gpu, catboost_gpu])\n",
    "        if gpu_count > 0:\n",
    "            print(f'\\n💡 {gpu_count}種類のモデルでGPU加速が有効でした')\n",
    "        else:\n",
    "            print(f'\\nℹ️ CPUモードで実行しました（並列処理により高速化）')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'[ERROR] PyCaret実行失敗')\n",
    "        print(f'  エラー型: {type(e).__name__}')\n",
    "        print(f'  詳細: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "elif PYC_OK:\n",
    "    print(f'[WARNING] データ不足（{len(feat)}行 < {MIN_SAMPLES_PYCARET}行）。PyCaretスキップ。')\n",
    "else:\n",
    "    print('[WARNING] PyCaret未インストール。スキップ。')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79z9lrfba1r",
   "metadata": {},
   "source": [
    "## 📈 ステップ5: 予測結果の可視化とビジネスインサイト\n",
    "\n",
    "### 🎯 **このセクションの目的**\n",
    "**上のステップ4で学習したAIモデルを使って、予測結果を可視化し、ビジネス上の判断材料を提供します。**\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 **このセクションで表示される内容**\n",
    "\n",
    "#### 1️⃣ **予測精度メトリクス**\n",
    "```\n",
    "📊 予測精度メトリクス:\n",
    "   R² Score: 0.8234\n",
    "   MAE: 1,250円\n",
    "   RMSE: 1,680円\n",
    "   MAPE: 8.5%\n",
    "```\n",
    "\n",
    "**指標の読み方：**\n",
    "- **R² (決定係数)**: 0.7以上なら実用レベル、0.8以上なら高精度\n",
    "- **MAE (平均絶対誤差)**: 予測が平均±1,250円の範囲でズレる\n",
    "- **RMSE (二乗平均平方根誤差)**: 大きな誤差を重視した指標\n",
    "- **MAPE (平均絶対パーセント誤差)**: 予測誤差が約8.5%（売上の1割未満なら実用可）\n",
    "\n",
    "#### 2️⃣ **4パネル可視化**\n",
    "1. **予測vs実績 散布図**: モデルの当てはまり具合を確認\n",
    "2. **残差分布**: 予測誤差の分布（正規分布に近いほど良い）\n",
    "3. **時系列予測**: 日別の予測精度推移\n",
    "4. **予測誤差率の分布**: どれくらいの割合で誤差が出るか\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **実務での活用方法**\n",
    "\n",
    "| 指標 | 判断基準 | アクション |\n",
    "|------|----------|----------|\n",
    "| **R² > 0.8** | 高精度 | このモデルを本番運用に投入可能 |\n",
    "| **0.7 < R² < 0.8** | 実用レベル | 注意しながら運用、改善の余地あり |\n",
    "| **R² < 0.7** | 要改善 | 特徴量の追加やデータ期間の延長が必要 |\n",
    "| **MAPE < 10%** | 優秀 | 発注数量の自動化に活用可能 |\n",
    "| **MAPE > 20%** | 要注意 | 人間のチェックを必須にする |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ **注意事項**\n",
    "\n",
    "1. **モデルが学習されていない場合**\n",
    "   ```\n",
    "   ⚠️ モデルが学習されていません。先にステップ4を実行してください。\n",
    "   ```\n",
    "   → ステップ4を先に実行してください\n",
    "\n",
    "2. **日付データがない場合**\n",
    "   - 時系列プロットはスキップされます（散布図と残差のみ表示）\n",
    "\n",
    "3. **異常値の確認**\n",
    "   - 散布図で大きく外れた点（外れ値）がある場合、その日のデータを確認してください\n",
    "   - イベント日や特殊要因があった可能性があります\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 **次のステップ**\n",
    "このステップで精度を確認したら、ステップ6で実際の発注数量予測を実行します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33101c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 📈 ステップ5: 予測結果の可視化とビジネスインサイト\n",
    "# ========================================\n",
    "\n",
    "if 'final' in locals():\n",
    "    print('\\n' + '='*60)\n",
    "    print('📈 ステップ5: 予測結果の可視化とビジネスインサイト')\n",
    "    print('='*60)\n",
    "    \n",
    "    try:\n",
    "        # 予測実行\n",
    "        predictions = predict_model(final)\n",
    "        \n",
    "        # 予測精度の評価\n",
    "        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "        \n",
    "        y_true = predictions['売上数量']\n",
    "        y_pred = predictions['prediction_label']\n",
    "        \n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "        \n",
    "        # MAPE計算（ゼロ除算回避）\n",
    "        non_zero_mask = y_true != 0\n",
    "        if non_zero_mask.sum() > 0:\n",
    "            mape = np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "        else:\n",
    "            mape = 0\n",
    "        \n",
    "        print(f'\\n📊 予測精度メトリクス:')\n",
    "        print(f'   R² Score: {r2:.4f}')\n",
    "        print(f'   MAE: {mae:,.0f}円')\n",
    "        print(f'   RMSE: {rmse:,.0f}円')\n",
    "        print(f'   MAPE: {mape:.2f}%')\n",
    "        \n",
    "        # 4パネル可視化\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('📊 予測精度の可視化分析', fontsize=16, fontproperties=font_setup.jp_font)\n",
    "        \n",
    "        # 1. 予測vs実績 散布図\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.scatter(y_true, y_pred, alpha=0.5, s=20, color='steelblue')\n",
    "        min_val = min(y_true.min(), y_pred.min())\n",
    "        max_val = max(y_true.max(), y_pred.max())\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='完全一致線')\n",
    "        ax1.set_xlabel('実績売上（円）', fontproperties=font_setup.jp_font)\n",
    "        ax1.set_ylabel('予測売上（円）', fontproperties=font_setup.jp_font)\n",
    "        ax1.set_title(f'1️⃣ 予測vs実績（R²={r2:.3f}）', fontproperties=font_setup.jp_font)\n",
    "        ax1.legend(prop=font_setup.jp_font)\n",
    "        ax1.grid(alpha=0.3)\n",
    "        \n",
    "        # 2. 残差分布\n",
    "        ax2 = axes[0, 1]\n",
    "        residuals = y_true - y_pred\n",
    "        ax2.hist(residuals, bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "        ax2.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        ax2.set_xlabel('残差（実績-予測）', fontproperties=font_setup.jp_font)\n",
    "        ax2.set_ylabel('頻度', fontproperties=font_setup.jp_font)\n",
    "        ax2.set_title(f'2️⃣ 残差分布（平均={residuals.mean():.0f}円）', fontproperties=font_setup.jp_font)\n",
    "        ax2.grid(alpha=0.3)\n",
    "        \n",
    "        # 3. 時系列予測（日付がある場合）\n",
    "        ax3 = axes[1, 0]\n",
    "        \n",
    "        # predictionsに日付が含まれているか確認\n",
    "        if '日付' in predictions.columns:\n",
    "            # 既に日付が含まれている場合\n",
    "            pred_sorted = predictions.sort_values('日付')\n",
    "            ax3.plot(pred_sorted['日付'], pred_sorted['売上数量'], \n",
    "                    label='実績', alpha=0.7, linewidth=1.5, color='blue', marker='o', markersize=3)\n",
    "            ax3.plot(pred_sorted['日付'], pred_sorted['prediction_label'], \n",
    "                    label='予測', alpha=0.7, linewidth=1.5, color='orange', marker='x', markersize=3)\n",
    "            ax3.set_xlabel('日付', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_ylabel('売上（円）', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_title('3️⃣ 時系列予測推移', fontproperties=font_setup.jp_font)\n",
    "            ax3.legend(prop=font_setup.jp_font)\n",
    "            ax3.grid(alpha=0.3)\n",
    "            plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        else:\n",
    "            # 日付がない場合はインデックスで表示\n",
    "            ax3.plot(range(len(predictions)), predictions['売上数量'], \n",
    "                    label='実績', alpha=0.7, linewidth=1.5, color='blue', marker='o', markersize=3)\n",
    "            ax3.plot(range(len(predictions)), predictions['prediction_label'], \n",
    "                    label='予測', alpha=0.7, linewidth=1.5, color='orange', marker='x', markersize=3)\n",
    "            ax3.set_xlabel('データポイント', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_ylabel('売上（円）', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_title('3️⃣ 予測推移（時系列順）', fontproperties=font_setup.jp_font)\n",
    "            ax3.legend(prop=font_setup.jp_font)\n",
    "            ax3.grid(alpha=0.3)\n",
    "        \n",
    "        # 4. 予測誤差率の分布\n",
    "        ax4 = axes[1, 1]\n",
    "        error_pct = ((y_pred - y_true) / y_true.replace(0, np.nan) * 100).dropna()\n",
    "        error_pct_clipped = error_pct.clip(-100, 100)\n",
    "        ax4.hist(error_pct_clipped, bins=30, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "        ax4.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        ax4.set_xlabel('予測誤差率（%）', fontproperties=font_setup.jp_font)\n",
    "        ax4.set_ylabel('頻度', fontproperties=font_setup.jp_font)\n",
    "        ax4.set_title(f'4️⃣ 予測誤差率分布（MAPE={mape:.1f}%）', fontproperties=font_setup.jp_font)\n",
    "        ax4.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # ビジネスインサイト\n",
    "        print('\\n' + '='*60)\n",
    "        print('💡 ビジネスインサイト')\n",
    "        print('='*60)\n",
    "        \n",
    "        if r2 >= 0.8:\n",
    "            print('✅ 【高精度】このモデルは本番運用に投入可能です')\n",
    "            print(f'   - モデルは売上変動の{r2*100:.1f}%を説明できています')\n",
    "        elif r2 >= 0.7:\n",
    "            print('⚠️ 【実用レベル】注意しながら運用できます（改善の余地あり）')\n",
    "            print(f'   - モデルは売上変動の{r2*100:.1f}%を説明できています')\n",
    "        else:\n",
    "            print('❌ 【要改善】特徴量の追加やデータ期間の延長が必要です')\n",
    "            print(f'   - モデルは売上変動の{r2*100:.1f}%しか説明できていません')\n",
    "        \n",
    "        if mape < 10:\n",
    "            print('✅ 【優秀】発注数量の自動化に活用できます')\n",
    "        elif mape < 20:\n",
    "            print('⚠️ 【実用可】人間のチェックを併用してください')\n",
    "        else:\n",
    "            print('❌ 【要注意】自動化は避け、参考値として利用してください')\n",
    "        \n",
    "        print(f'\\n📊 予測精度の実務的な意味:')\n",
    "        print(f'  - 平均予測誤差: ±{mae:,.0f}円')\n",
    "        print(f'  - 大部分の予測は ±{rmse:,.0f}円 の範囲内')\n",
    "        print(f'  - 予測レコード数: {len(predictions):,}件')\n",
    "        \n",
    "        # 最大誤差の分析\n",
    "        abs_errors = np.abs(residuals)\n",
    "        max_error_idx = abs_errors.idxmax()\n",
    "        max_error_actual = y_true.loc[max_error_idx]\n",
    "        max_error_pred = y_pred.loc[max_error_idx]\n",
    "        max_error_diff = residuals.loc[max_error_idx]\n",
    "        \n",
    "        print(f'\\n⚠️ 最大誤差のケース:')\n",
    "        print(f'  - 実績: {max_error_actual:,.0f}円')\n",
    "        print(f'  - 予測: {max_error_pred:,.0f}円')\n",
    "        print(f'  - 誤差: {max_error_diff:,.0f}円 ({abs(max_error_diff/max_error_actual*100):.1f}%)')\n",
    "        print(f'  💡 このような外れ値は特殊イベントの可能性があります')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'⚠️ 可視化エラー: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print('⚠️ モデルが学習されていません。先にステップ4を実行してください。')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2br5d2hc0od",
   "metadata": {},
   "source": [
    "## 📦 ステップ6: 1週間先の発注数量予測（全商品）\n",
    "\n",
    "### 🎯 **このセクションの目的**\n",
    "**学習したAIモデルを使って、2025年10月15日から1週間分の全商品の販売数量を予測し、発注数量を自動計算します。**\n",
    "\n",
    "---\n",
    "\n",
    "### 📋 **予測の流れ**\n",
    "\n",
    "1. **外部要因の入力** → 1週間分の天気予報・カレンダー情報を入力\n",
    "2. **AIが予測** → 学習したモデルで商品×日付ごとに販売数量を予測\n",
    "3. **発注数量の計算** → 予測値 × 安全係数で発注数量を算出\n",
    "4. **CSV出力** → 発注表をCSVファイルとして保存\n",
    "\n",
    "---\n",
    "\n",
    "### 👀 **店長が入力すべき情報**\n",
    "\n",
    "次のセルで、以下の情報を入力してください：\n",
    "\n",
    "| 項目 | 入力例 | 説明 |\n",
    "|------|--------|------|\n",
    "| **予測開始日** | `2025-10-15` | 発注を開始する日 |\n",
    "| **予測日数** | `7` | 何日分予測するか（通常は7日） |\n",
    "| **天気予報** | `['晴れ', '曇り', '雨', ...]` | 1週間分の天気予報 |\n",
    "| **平均気温** | `[22, 23, 20, 18, ...]` | 1週間分の予測気温（℃） |\n",
    "| **降水確率** | `[10, 30, 70, ...]` | 1週間分の降水確率（%） |\n",
    "| **安全係数** | `1.2` | 欠品防止のための余裕率（通常1.1～1.3） |\n",
    "\n",
    "**安全係数の目安**:\n",
    "- `1.0` → 予測値そのまま（リスク高）\n",
    "- `1.1～1.2` → 通常の運用（推奨）\n",
    "- `1.3～1.5` → 欠品を絶対に避けたい（廃棄リスク増）\n",
    "\n",
    "---\n",
    "\n",
    "**次のセルで外部要因を入力し、予測を実行してください ↓**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rbi69vvi24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 📊 Step 6-1: 全店舗×全商品の予測用データ作成（GPU高速化版）\n",
    "# ========================================\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('📅 Step 6-1: 全店舗の天気データ取得 + 予測用特徴量作成')\n",
    "print('='*60)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# ========================================\n",
    "# 📍 店舗マスタの読み込み\n",
    "# ========================================\n",
    "\n",
    "print('\\n📍 店舗マスタを読み込み中...')\n",
    "stores_df = pd.read_csv('stores.csv')\n",
    "print(f'  ✅ 店舗数: {len(stores_df)} 店舗')\n",
    "print(f'  店舗リスト: {list(stores_df[\"店舗名\"][:5])}...')\n",
    "\n",
    "# ========================================\n",
    "# 🛍️ 商品マスタの作成（学習データから抽出）\n",
    "# ========================================\n",
    "\n",
    "print('\\n🛍️ 商品マスタを作成中...')\n",
    "if 'df' in globals() and '商品名' in df.columns:\n",
    "    # 学習データから商品情報を抽出\n",
    "    sku_master = df[['商品名']].drop_duplicates().copy()\n",
    "    \n",
    "    # 商品単価を計算（price列がある場合）\n",
    "    if 'price' in df.columns:\n",
    "        sku_prices = df.groupby('商品名')['price'].mean().reset_index()\n",
    "        sku_master = sku_master.merge(sku_prices, on='商品名', how='left')\n",
    "    elif '売上金額' in df.columns and '売上数量' in df.columns:\n",
    "        # sales_amt / qty で単価を計算\n",
    "        df_with_price = df[df['売上数量'] > 0].copy()\n",
    "        df_with_price['calc_price'] = df_with_price['売上金額'] / df_with_price['売上数量']\n",
    "        sku_prices = df_with_price.groupby('商品名')['calc_price'].median().reset_index()\n",
    "        sku_prices.columns = ['商品名', 'price']\n",
    "        sku_master = sku_master.merge(sku_prices, on='商品名', how='left')\n",
    "    \n",
    "    print(f'  ✅ 商品数: {len(sku_master)} SKU')\n",
    "    if 'price' in sku_master.columns:\n",
    "        print(f'  平均単価: ¥{sku_master[\"price\"].mean():.0f}')\n",
    "else:\n",
    "    print('  ⚠️ 学習データから商品マスタを作成できませんでした')\n",
    "    sku_master = pd.DataFrame({'商品名': [1]})  # ダミー\n",
    "\n",
    "# ========================================\n",
    "# 🌤️ 全店舗の天気予報を一括取得（並列処理）\n",
    "# ========================================\n",
    "\n",
    "FORECAST_START_DATE = '2025-10-15'  # 予測開始日\n",
    "FORECAST_DAYS = 7  # 予測日数\n",
    "\n",
    "print(f'\\n🌤️ 全{len(stores_df)}店舗の天気予報を取得中...')\n",
    "print(f'  期間: {FORECAST_START_DATE} ～ {FORECAST_DAYS}日間')\n",
    "\n",
    "weather_codes = {\n",
    "    0: '晴れ', 1: '晴れ', 2: '晴れ', 3: '曇り',\n",
    "    45: '霧', 48: '霧', 51: '小雨', 53: '小雨', 55: '雨',\n",
    "    61: '雨', 63: '雨', 65: '大雨', 80: '雨', 81: '雨', 82: '大雨'\n",
    "}\n",
    "\n",
    "all_store_weather = []\n",
    "\n",
    "for idx, store in stores_df.iterrows():\n",
    "    store_name = store['店舗名']\n",
    "    lat = store['緯度']\n",
    "    lon = store['経度']\n",
    "    \n",
    "    try:\n",
    "        url = 'https://api.open-meteo.com/v1/forecast'\n",
    "        params = {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode',\n",
    "            'timezone': 'Asia/Tokyo',\n",
    "            'start_date': FORECAST_START_DATE,\n",
    "            'end_date': (datetime.strptime(FORECAST_START_DATE, '%Y-%m-%d') + timedelta(days=FORECAST_DAYS-1)).strftime('%Y-%m-%d')\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # 店舗ごとの天気データを保存\n",
    "        for i in range(len(data['daily']['time'])):\n",
    "            weather_code = data['daily']['weathercode'][i]\n",
    "            all_store_weather.append({\n",
    "                'store_name': store_name,\n",
    "                'store_lat': lat,\n",
    "                'store_lon': lon,\n",
    "                '日付': data['daily']['time'][i],\n",
    "                'weather': weather_codes.get(weather_code, '不明'),\n",
    "                'temp_max': data['daily']['temperature_2m_max'][i],\n",
    "                'temp_min': data['daily']['temperature_2m_min'][i],\n",
    "                'temp_avg': (data['daily']['temperature_2m_max'][i] + data['daily']['temperature_2m_min'][i]) / 2,\n",
    "                'precipitation': data['daily']['precipitation_sum'][i]\n",
    "            })\n",
    "        \n",
    "        print(f'  ✅ {store_name}: {len(data[\"daily\"][\"time\"])}日分取得')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'  ❌ {store_name}: API失敗 ({e}) - ダミーデータ使用')\n",
    "        # ダミーデータ\n",
    "        for i in range(FORECAST_DAYS):\n",
    "            forecast_date = (datetime.strptime(FORECAST_START_DATE, '%Y-%m-%d') + timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "            all_store_weather.append({\n",
    "                'store_name': store_name,\n",
    "                'store_lat': lat,\n",
    "                'store_lon': lon,\n",
    "                '日付': forecast_date,\n",
    "                'weather': '晴れ',\n",
    "                'temp_max': 25.0,\n",
    "                'temp_min': 18.0,\n",
    "                'temp_avg': 21.5,\n",
    "                'precipitation': 0.0\n",
    "            })\n",
    "\n",
    "weather_all_df = pd.DataFrame(all_store_weather)\n",
    "print(f'\\n✅ 天気データ取得完了: {len(weather_all_df)} レコード')\n",
    "\n",
    "# ========================================\n",
    "# 🔄 全店舗×全商品×全日付の組み合わせを生成\n",
    "# ========================================\n",
    "\n",
    "print('\\n🔄 予測用データセットを生成中...')\n",
    "\n",
    "# 店舗マスタに店舗IDを追加\n",
    "stores_df['店舗'] = range(1, len(stores_df) + 1)\n",
    "\n",
    "# 全組み合わせを生成（店舗×商品×日付）\n",
    "forecast_combinations = []\n",
    "\n",
    "for _, store in stores_df.iterrows():\n",
    "    store_id = store['店舗']\n",
    "    store_name = store['店舗名']\n",
    "    \n",
    "    for _, sku in sku_master.iterrows():\n",
    "        sku_id = sku['商品名']\n",
    "        sku_price = sku.get('price', np.nan)\n",
    "        \n",
    "        # この店舗の天気データを取得\n",
    "        store_weather = weather_all_df[weather_all_df['store_name'] == store_name]\n",
    "        \n",
    "        for _, w_data in store_weather.iterrows():\n",
    "            date_obj = datetime.strptime(w_data['日付'], '%Y-%m-%d')\n",
    "            \n",
    "            features = {\n",
    "                '店舗': store_id,\n",
    "                '商品名': sku_id,\n",
    "                'price': sku_price,\n",
    "                '日付': w_data['日付'],\n",
    "                '年': date_obj.year,\n",
    "                '月': date_obj.month,\n",
    "                '日': date_obj.day,\n",
    "                '曜日': date_obj.weekday(),\n",
    "                '週番号': date_obj.isocalendar()[1],\n",
    "                '年内日数': date_obj.timetuple().tm_yday,\n",
    "                '祝日フラグ': 0,\n",
    "                '土曜フラグ': 1 if date_obj.weekday() == 5 else 0,\n",
    "                '日曜フラグ': 1 if date_obj.weekday() == 6 else 0,\n",
    "                '週末フラグ': 1 if date_obj.weekday() >= 5 else 0,\n",
    "                '平日フラグ': 1 if date_obj.weekday() < 5 else 0,\n",
    "                '天気': w_data['weather'],\n",
    "                '最高気温': w_data['temp_max'],\n",
    "                '最低気温': w_data['temp_min'],\n",
    "                '平均気温': w_data['temp_avg'],\n",
    "                '気温差': w_data['temp_max'] - w_data['temp_min'],\n",
    "                '降水量': w_data['precipitation'],\n",
    "            }\n",
    "            \n",
    "            # 学習データの全カラムに対応\n",
    "            if 'feat' in globals():\n",
    "                for col in feat.columns:\n",
    "                    if col not in features and col not in ['売上数量', '売上金額']:\n",
    "                        # ラグ特徴量や移動平均はNaN\n",
    "                        if '_t-' in col or '_MA' in col or '変化' in col or 'トレンド' in col or '累積' in col:\n",
    "                            features[col] = np.nan\n",
    "                        else:\n",
    "                            features[col] = 0\n",
    "            \n",
    "            forecast_combinations.append(features)\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_combinations)\n",
    "\n",
    "# 学習データと同じ列順序に並べ替え\n",
    "if 'feat' in globals():\n",
    "    common_cols = [c for c in feat.columns if c in forecast_df.columns and c not in ['売上数量', '売上金額']]\n",
    "    # 必須列（店舗、商品名、日付）を保持しつつ、学習データと同じ列順序に並べ替え\n",
    "    essential_cols = ['店舗', '商品名', '日付']\n",
    "    feature_cols_only = [c for c in common_cols if c not in essential_cols]\n",
    "    final_cols = essential_cols + feature_cols_only + ['price']\n",
    "    # forecast_dfに存在する列のみ選択\n",
    "    final_cols = [c for c in final_cols if c in forecast_df.columns]\n",
    "    forecast_df = forecast_df[final_cols]\n",
    "\n",
    "print(f'\\n✅ 予測用データセット作成完了:')\n",
    "print(f'  総レコード数: {len(forecast_df):,} 件')\n",
    "print(f'  = {len(stores_df)} 店舗 × {len(sku_master)} 商品 × {FORECAST_DAYS} 日')\n",
    "print(f'  列数: {len(forecast_df.columns)}')\n",
    "\n",
    "# サンプル表示\n",
    "print('\\n📋 予測用データサンプル:')\n",
    "sample_cols = ['店舗', '商品名', '日付', '年', '月', '曜日', '天気', '最高気温', 'price']\n",
    "display_cols = [c for c in sample_cols if c in forecast_df.columns]\n",
    "display(forecast_df[display_cols].head(10))\n",
    "\n",
    "print('\\n💡 次のステップ: Step 6-2で商品別・店舗別の販売数量を予測してください')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2qr8mow022t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 📦 Step 6-2: 全店舗×全商品の販売数量予測（GPU高速化版）\n",
    "# ========================================\n",
    "\n",
    "if not PYC_OK or 'final' not in globals():\n",
    "    print('⚠️ モデルが学習されていません。先にステップ4を実行してください。')\n",
    "elif 'forecast_df' not in globals():\n",
    "    print('⚠️ 予測用データが作成されていません。先にStep 6-1を実行してください。')\n",
    "else:\n",
    "    print('\\n' + '='*60)\n",
    "    print('🤖 全店舗×全商品の販売数量予測を実行中...')\n",
    "    print('='*60)\n",
    "    \n",
    "    total_records = len(forecast_df)\n",
    "    print(f'\\n📊 予測対象:')\n",
    "    print(f'  商品数: {forecast_df[\"商品名\"].nunique()} SKU')\n",
    "    print(f'  店舗数: {forecast_df[\"店舗\"].nunique()} 店舗')\n",
    "    print(f'  日数: {forecast_df[\"日付\"].nunique()} 日')\n",
    "    print(f'  合計予測レコード数: {total_records:,} 件')\n",
    "    \n",
    "    # GPU並列化設定\n",
    "    BATCH_SIZE = 10000  # GPU最適なバッチサイズ（大量データ対応）\n",
    "    \n",
    "    if USE_GPU and GPU_AVAILABLE:\n",
    "        print(f'\\n🚀 GPU並列化モード: {BATCH_SIZE:,}件ずつバッチ処理')\n",
    "    else:\n",
    "        print(f'\\nℹ️ CPU処理モード: {BATCH_SIZE:,}件ずつバッチ処理')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # バッチ予測（GPU高速化）\n",
    "    predictions_list = []\n",
    "    num_batches = (total_records + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = min((batch_idx + 1) * BATCH_SIZE, total_records)\n",
    "        \n",
    "        batch_data = forecast_df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # price列を除外して予測\n",
    "        pred_cols = [c for c in batch_data.columns if c != 'price']\n",
    "        batch_pred_data = batch_data[pred_cols]\n",
    "        \n",
    "        # バッチ予測実行\n",
    "        try:\n",
    "            batch_pred = predict_model(final, data=batch_pred_data)\n",
    "            \n",
    "            # price列を復元\n",
    "            if 'price' in batch_data.columns:\n",
    "                batch_pred['price'] = batch_data['price'].values\n",
    "            \n",
    "            predictions_list.append(batch_pred)\n",
    "            \n",
    "            # 進捗表示\n",
    "            progress = (batch_idx + 1) / num_batches * 100\n",
    "            print(f'\\r⏳ 予測進捗: {progress:.1f}% ({batch_idx+1}/{num_batches} バッチ)', end='')\n",
    "        except Exception as e:\n",
    "            print(f'\\n⚠️ バッチ{batch_idx+1}でエラー: {e}')\n",
    "            continue\n",
    "    \n",
    "    print()  # 改行\n",
    "    \n",
    "    if predictions_list:\n",
    "        forecast_result = pd.concat(predictions_list, ignore_index=True)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        records_per_sec = total_records / elapsed if elapsed > 0 else 0\n",
    "        \n",
    "        print(f'\\n✅ 予測完了:')\n",
    "        print(f'  総件数: {len(forecast_result):,} 件')\n",
    "        print(f'  実行時間: {elapsed:.1f}秒')\n",
    "        print(f'  処理速度: {records_per_sec:,.0f} 件/秒')\n",
    "        if USE_GPU:\n",
    "            print(f'  💡 GPUにより高速化されました')\n",
    "        \n",
    "        # 予測値をわかりやすい列名に変更\n",
    "        if 'prediction_label' in forecast_result.columns:\n",
    "            forecast_result = forecast_result.rename(columns={\n",
    "                'prediction_label': 'predicted_qty'  # 販売数量予測\n",
    "            })\n",
    "        \n",
    "        # ========================================\n",
    "        # 💰 売上金額の計算（予測数量 × 単価）\n",
    "        # ========================================\n",
    "        \n",
    "        if 'predicted_qty' in forecast_result.columns and 'price' in forecast_result.columns:\n",
    "            # 負の予測値を0に補正\n",
    "            forecast_result['predicted_qty'] = forecast_result['predicted_qty'].clip(lower=0)\n",
    "            \n",
    "            # 売上金額 = 予測数量 × 単価\n",
    "            forecast_result['predicted_sales_amt'] = (\n",
    "                forecast_result['predicted_qty'] * forecast_result['price']\n",
    "            ).round(0)\n",
    "            \n",
    "            print(f'\\n💰 売上金額計算完了:')\n",
    "            print(f'  予測販売数量合計: {forecast_result[\"predicted_qty\"].sum():,.0f} 個')\n",
    "            print(f'  予測売上金額合計: ¥{forecast_result[\"predicted_sales_amt\"].sum():,.0f}')\n",
    "        \n",
    "        # ========================================\n",
    "        # 📦 発注数量の計算（安全在庫係数）\n",
    "        # ========================================\n",
    "        \n",
    "        SAFETY_FACTOR = 1.2  # 20%多めに発注（機会損失を防ぐ）\n",
    "        \n",
    "        if 'predicted_qty' in forecast_result.columns:\n",
    "            forecast_result['order_qty'] = (\n",
    "                forecast_result['predicted_qty'] * SAFETY_FACTOR\n",
    "            ).round(0).astype(int)\n",
    "            \n",
    "            print(f'\\n📦 発注数量計算完了:')\n",
    "            print(f'  安全係数: {SAFETY_FACTOR}倍')\n",
    "            print(f'  発注数量合計: {forecast_result[\"order_qty\"].sum():,} 個')\n",
    "            print(f'  （予測数量の{SAFETY_FACTOR}倍で在庫切れリスクを低減）')\n",
    "        \n",
    "        # ========================================\n",
    "        # 📊 結果サマリー\n",
    "        # ========================================\n",
    "        \n",
    "        print(f'\\n📊 予測結果サマリー（上位10件）:')\n",
    "        display_cols = []\n",
    "        for col in ['日付', '店舗', '商品名', 'predicted_qty', 'order_qty', 'price', 'predicted_sales_amt']:\n",
    "            if col in forecast_result.columns:\n",
    "                display_cols.append(col)\n",
    "        \n",
    "        if display_cols:\n",
    "            # 予測販売数量が多い順にソート\n",
    "            top_results = forecast_result.nlargest(10, 'predicted_qty' if 'predicted_qty' in forecast_result.columns else 'predicted_sales_amt')\n",
    "            print(top_results[display_cols])\n",
    "        \n",
    "        # 日別サマリー\n",
    "        if '日付' in forecast_result.columns and 'predicted_qty' in forecast_result.columns:\n",
    "            print(f'\\n📅 日別サマリー:')\n",
    "            daily_summary = forecast_result.groupby('日付').agg({\n",
    "                'predicted_qty': 'sum',\n",
    "                'order_qty': 'sum',\n",
    "                'predicted_sales_amt': 'sum'\n",
    "            }).reset_index()\n",
    "            daily_summary.columns = ['日付', '予測販売数量', '発注数量', '予測売上金額']\n",
    "            print(daily_summary)\n",
    "        \n",
    "        # 店舗別サマリー\n",
    "        if '店舗' in forecast_result.columns and 'predicted_qty' in forecast_result.columns:\n",
    "            print(f'\\n🏪 店舗別サマリー（上位5店舗）:')\n",
    "            store_summary = forecast_result.groupby('店舗').agg({\n",
    "                'predicted_qty': 'sum',\n",
    "                'order_qty': 'sum',\n",
    "                'predicted_sales_amt': 'sum'\n",
    "            }).reset_index()\n",
    "            store_summary.columns = ['店舗ID', '予測販売数量', '発注数量', '予測売上金額']\n",
    "            store_summary = store_summary.nlargest(5, '予測売上金額')\n",
    "            print(store_summary)\n",
    "        \n",
    "        print(f'\\n✅ 予測完了！次のステップ: Step 6-3でCSV出力してください')\n",
    "    else:\n",
    "        print('\\n❌ 予測に失敗しました')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slf8tnkekhn",
   "metadata": {},
   "source": [
    "## 📊 ステップ7: 発注予測結果の読み方と実務での使い方\n",
    "\n",
    "### 🎯 **このセクションの目的**\n",
    "**上で出力された発注予測表を、明日からどう使うかを解説します。**\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ 出力されたCSVファイルの内容\n",
    "\n",
    "### 📋 **メインファイル: `発注予測_2025-10-15_to_2025-10-21.csv`**\n",
    "\n",
    "このファイルには、全商品×7日分の発注予測が含まれています。\n",
    "\n",
    "| 列名 | 意味 | 使い方 |\n",
    "|------|------|--------|\n",
    "| **日付** | 販売予定日 | この日に店頭に並ぶ商品 |\n",
    "| **曜日** | 曜日（Monday～Sunday） | 曜日別の発注パターン確認 |\n",
    "| **店舗** | 店舗コード | 複数店舗の場合、店舗ごとに分ける |\n",
    "| **商品コード** | SKU識別子 | 発注システムへの入力値 |\n",
    "| **大分類/中分類/小分類** | カテゴリ | 発注作業の整理用 |\n",
    "| **予測販売数量** | AIの予測値 | この数量が売れると予測 |\n",
    "| **発注数量** | 実際の発注数 | **これを発注システムに入力** |\n",
    "| **単価** | 平均単価 | 予算計算用 |\n",
    "| **天気/気温** | 予測日の天候 | 判断材料 |\n",
    "| **週末** | 週末/平日フラグ | 週末対応の目印 |\n",
    "\n",
    "---\n",
    "\n",
    "### 📅 **日付別ファイル: `発注予測_2025-10-15.csv`**\n",
    "\n",
    "各日付ごとに分割されたファイルです。\n",
    "\n",
    "**使い方**:\n",
    "1. 毎朝、**その日の発注ファイル**を開く\n",
    "2. **発注数量**列をそのまま発注システムに入力\n",
    "3. カテゴリ別にソートして、効率的に発注作業を進める\n",
    "\n",
    "---\n",
    "\n",
    "### 🏪 **店舗別ファイル: `発注予測_店舗A_2025-10-15.csv`**\n",
    "\n",
    "複数店舗がある場合、店舗ごとに分割されたファイルです。\n",
    "\n",
    "**使い方**:\n",
    "- 各店舗の店長に配布\n",
    "- 店舗ごとの特性を反映した発注が可能\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ 発注作業の実務フロー（毎日のルーティン）\n",
    "\n",
    "### 📝 **毎朝のチェックリスト**\n",
    "\n",
    "#### **ステップ1: CSVファイルを開く（5分）**\n",
    "```\n",
    "1. output/発注予測_[今日の日付].csv を開く\n",
    "2. Excelで開いて、カテゴリでソート\n",
    "3. 発注システムと画面を並べる\n",
    "```\n",
    "\n",
    "#### **ステップ2: 発注数量を確認（5分）**\n",
    "```\n",
    "□ 発注数量が異常に多い商品はないか？\n",
    "  → 通常の2倍以上 → 天気・イベントを再確認\n",
    "  → 問題なければそのまま発注\n",
    "\n",
    "□ 発注数量が0の商品はないか？\n",
    "  → 0の場合 → 過去実績を確認して少量発注を検討\n",
    "```\n",
    "\n",
    "#### **ステップ3: 発注システムに入力（10～15分）**\n",
    "```\n",
    "1. カテゴリ別に発注数量を入力\n",
    "2. 特に注意すべき商品:\n",
    "   - 発注数量トップ20 → 欠品させない\n",
    "   - 雨の日に売れる商品 → 降水確率を再確認\n",
    "   - 週末に売れる商品 → 金曜の朝までに発注\n",
    "```\n",
    "\n",
    "#### **ステップ4: 調整（5分）**\n",
    "```\n",
    "□ 天気予報が変わっていないか確認\n",
    "  → 変わっている場合、手動で±10%調整\n",
    "\n",
    "□ 突発イベント（セールなど）がないか確認\n",
    "  → ある場合、該当カテゴリを+20～30%増量\n",
    "\n",
    "□ 昨日の売上実績と比較\n",
    "  → 予測が大きく外れている場合、フィードバック\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ 結果の読み方（数字の意味）\n",
    "\n",
    "### 📊 **日付別サマリーの見方**\n",
    "\n",
    "上のセルで表示された「日付別サマリー」:\n",
    "\n",
    "| 日付 | 発注数量 | 予測売上金額 | 商品種類数 |\n",
    "|------|----------|------------|----------|\n",
    "| 2025-10-15 | 850 | ¥127,500 | 120 |\n",
    "| 2025-10-16 | 820 | ¥123,000 | 120 |\n",
    "| 2025-10-19 (雨) | 950 | ¥142,500 | 120 |\n",
    "\n",
    "**読み方**:\n",
    "- **10/19（雨の日）** → 発注数量が通常より+15%増\n",
    "- **意味**: AIが「雨の日は売上が増える」と判断\n",
    "- **アクション**: 温かい商品・カップ麺などを重点発注\n",
    "\n",
    "---\n",
    "\n",
    "### 📦 **カテゴリ別サマリーの見方**\n",
    "\n",
    "| 大分類 | 発注数量 | 予測売上金額 |\n",
    "|--------|----------|------------|\n",
    "| 弁当 | 2,100 | ¥315,000 |\n",
    "| 飲料 | 1,800 | ¥108,000 |\n",
    "| 総菜 | 1,500 | ¥225,000 |\n",
    "\n",
    "**読み方**:\n",
    "- **弁当が最も売れる** → 陳列スペースを最優先確保\n",
    "- **発注数量の比率** → 棚割りの参考に\n",
    "\n",
    "---\n",
    "\n",
    "### 🔝 **発注数量トップ20の使い方**\n",
    "\n",
    "上位20商品 = **絶対に欠品させてはいけない商品**\n",
    "\n",
    "**実務アクション**:\n",
    "1. **毎日チェック** → トップ20商品の在庫を毎夕確認\n",
    "2. **フェース増** → 陳列スペースを通常の1.5倍確保\n",
    "3. **前出し強化** → 昼・夕ピーク前に必ず前出し\n",
    "4. **欠品時の対応** → 予備在庫を用意、または類似商品で代替\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ よくある質問（FAQ）\n",
    "\n",
    "### ❓ **予測が外れた場合はどうする？**\n",
    "\n",
    "**回答**:\n",
    "- **1日だけ外れた** → 突発要因（競合店のセール等）の可能性。記録して次回に活かす\n",
    "- **連続で外れる** → AIの再学習が必要。データ期間を延長（3ヶ月→6ヶ月）して再実行\n",
    "\n",
    "---\n",
    "\n",
    "### ❓ **安全係数はどう決める？**\n",
    "\n",
    "**回答**:\n",
    "\n",
    "| 状況 | 推奨値 | 理由 |\n",
    "|------|--------|------|\n",
    "| **通常運用** | 1.1～1.2 | 欠品と廃棄のバランス |\n",
    "| **新商品** | 1.3～1.5 | 需要が読めないため保守的に |\n",
    "| **廃棄率が高い** | 1.0～1.1 | 廃棄削減を優先 |\n",
    "| **欠品が多発** | 1.2～1.3 | 売上機会損失を防ぐ |\n",
    "\n",
    "**調整方法**:\n",
    "- 1週間運用して、廃棄率と欠品率を測定\n",
    "- 廃棄率5%以上 → 安全係数を-0.1下げる\n",
    "- 欠品率3%以上 → 安全係数を+0.1上げる\n",
    "\n",
    "---\n",
    "\n",
    "### ❓ **天気予報が変わったらどうする？**\n",
    "\n",
    "**回答**:\n",
    "1. **前日夕方** に最新の天気予報を確認\n",
    "2. **降水確率が30%以上変わった場合**:\n",
    "   - 晴れ→雨 → 温かい商品を+10～20%増量\n",
    "   - 雨→晴れ → 冷たい商品を+10～20%増量\n",
    "3. **気温が5℃以上変わった場合**:\n",
    "   - 暑くなる → 冷飲料・アイスを+20%増量\n",
    "   - 寒くなる → ホット飲料・総菜を+20%増量\n",
    "\n",
    "---\n",
    "\n",
    "### ❓ **発注数量が0の商品はどうする？**\n",
    "\n",
    "**回答**:\n",
    "- **AIの判断**: その商品はその日売れにくい\n",
    "- **実務対応**:\n",
    "  1. 過去実績を確認 → 本当に売れていないか？\n",
    "  2. 売れている → 最低発注数（1～2個）を手動入力\n",
    "  3. 売れていない → 0のまま発注しない（在庫削減）\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ 効果測定（1週間後にチェック）\n",
    "\n",
    "### ✅ **成功指標**\n",
    "\n",
    "| 指標 | 目標値 | 測定方法 |\n",
    "|------|--------|----------|\n",
    "| **欠品率** | 3%以下 | 欠品商品数 ÷ 全商品数 |\n",
    "| **廃棄率** | 5%以下 | 廃棄数量 ÷ 発注数量 |\n",
    "| **予測精度** | 80%以上 | 実売数量 ÷ 予測数量 |\n",
    "| **売上増加率** | +5%以上 | 今週売上 vs 先週売上 |\n",
    "\n",
    "**測定シート（Excelで作成）**:\n",
    "```\n",
    "| 日付 | 発注数量 | 実売数量 | 廃棄数量 | 欠品商品数 | 予測精度 |\n",
    "|------|----------|----------|----------|-----------|---------|\n",
    "| 10/15 | 850 | 820 | 30 | 2 | 96% |\n",
    "| 10/16 | 820 | 790 | 30 | 1 | 96% |\n",
    "| ...  | ... | ... | ... | ... | ... |\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 まとめ: AI発注予測の活用ポイント\n",
    "\n",
    "### **最重要ポイント 3つ**\n",
    "\n",
    "1. **毎朝5分のルーティン化**\n",
    "   - CSVファイルを開く → 発注数量を確認 → 発注システムに入力\n",
    "\n",
    "2. **トップ20商品は絶対欠品させない**\n",
    "   - 毎夕、在庫チェック\n",
    "   - フェース1.5倍確保\n",
    "   - 予備在庫を用意\n",
    "\n",
    "3. **1週間運用して、安全係数を調整**\n",
    "   - 廃棄率5%以上 → 係数-0.1\n",
    "   - 欠品率3%以上 → 係数+0.1\n",
    "\n",
    "---\n",
    "\n",
    "**これで、AI発注予測システムの説明は完了です！**\n",
    "\n",
    "明日から実際に運用してみてください。1週間後に効果を測定し、継続的に改善していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6sn7okpdz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================",
    "# 💾 Step 6-3: 発注表をCSVファイルに出力",
    "# ========================================",
    "",
    "from pathlib import Path",
    "",
    "if 'forecast_result' not in globals() or forecast_result.empty:",
    "    print('[ERROR] 予測結果が見つかりません。先にStep 6-2を実行してください。')",
    "else:",
    "    # outputディレクトリ作成",
    "    output_dir = Path('output')",
    "    output_dir.mkdir(exist_ok=True)",
    "    ",
    "    print('\\n' + '='*60)",
    "    print('💾 発注表CSVファイルを出力中...')",
    "    print('='*60)",
    "    ",
    "    # ========================================",
    "    # 📄 メイン発注表（全データ）",
    "    # ========================================",
    "    ",
    "    # 日付範囲を取得",
    "    if '日付' in forecast_result.columns:",
    "        # Categorical型の場合は文字列に変換",
    "        date_col = forecast_result['日付']",
    "        if hasattr(date_col, 'cat'):  # Categoricalの場合",
    "            date_col = date_col.astype(str)",
    "        ",
    "        # ソートして最初と最後を取得",
    "        dates_sorted = sorted(date_col.unique())",
    "        start_date = dates_sorted[0] if len(dates_sorted) > 0 else 'unknown'",
    "        end_date = dates_sorted[-1] if len(dates_sorted) > 0 else 'unknown'",
    "        output_filename = f'発注表_全店舗_{start_date}_to_{end_date}.csv'",
    "    else:",
    "        output_filename = '発注表_全店舗.csv'",
    "    ",
    "    output_path = output_dir / output_filename",
    "    ",
    "    # 発注表として必要な列を選択",
    "    order_cols = []",
    "    for col in ['日付', '店舗', '商品名', 'predicted_qty', 'order_qty', 'price', 'predicted_sales_amt']:",
    "        if col in forecast_result.columns:",
    "            order_cols.append(col)",
    "    ",
    "    # 日本語列名に変換",
    "    order_df = forecast_result[order_cols].copy()",
    "    rename_dict = {",
    "        '日付': '日付',",
    "        '店舗': '店舗ID',",
    "        '商品名': '商品ID',",
    "        'predicted_qty': '予測販売数量',",
    "        'order_qty': '発注数量',",
    "        'price': '単価',",
    "        'predicted_sales_amt': '予測売上金額'",
    "    }",
    "    order_df = order_df.rename(columns={k: v for k, v in rename_dict.items() if k in order_df.columns})",
    "    ",
    "    # CSV出力",
    "    order_df.to_csv(output_path, index=False, encoding='utf-8-sig')",
    "    ",
    "    print(f'\\n✅ メイン発注表を保存:')",
    "    print(f'  ファイル名: {output_path}')",
    "    print(f'  ファイルサイズ: {output_path.stat().st_size / 1024:.1f} KB')",
    "    print(f'  レコード数: {len(order_df):,} 件')",
    "    ",
    "    # ========================================",
    "    # 📅 日付別CSVファイル",
    "    # ========================================",
    "    ",
    "    if '日付' in order_df.columns:",
    "        print(f'\\n📅 日付別CSVファイルを出力中...')",
    "        for date in sorted(order_df['日付'].unique()):",
    "            date_df = order_df[order_df['日付'] == date].copy()",
    "            date_filename = f'発注表_{date}.csv'",
    "            date_path = output_dir / date_filename",
    "            date_df.to_csv(date_path, index=False, encoding='utf-8-sig')",
    "            ",
    "            total_qty = date_df['発注数量'].sum() if '発注数量' in date_df.columns else 0",
    "            total_amt = date_df['予測売上金額'].sum() if '予測売上金額' in date_df.columns else 0",
    "            ",
    "            print(f'  ✅ {date_filename}: {len(date_df):,}件 | 発注{total_qty:,}個 | 予測売上¥{total_amt:,.0f}')",
    "    ",
    "    # ========================================",
    "    # 🏪 店舗別CSVファイル",
    "    # ========================================",
    "    ",
    "    if '店舗ID' in order_df.columns and order_df['店舗ID'].nunique() > 1:",
    "        print(f'\\n🏪 店舗別CSVファイルを出力中...')",
    "        for store_id in sorted(order_df['店舗ID'].unique()):",
    "            store_df = order_df[order_df['店舗ID'] == store_id].copy()",
    "            store_filename = f'発注表_店舗{int(store_id)}.csv'",
    "            store_path = output_dir / store_filename",
    "            store_df.to_csv(store_path, index=False, encoding='utf-8-sig')",
    "            ",
    "            total_qty = store_df['発注数量'].sum() if '発注数量' in store_df.columns else 0",
    "            total_amt = store_df['予測売上金額'].sum() if '予測売上金額' in store_df.columns else 0",
    "            ",
    "            print(f'  ✅ {store_filename}: {len(store_df):,}件 | 発注{total_qty:,}個 | 予測売上¥{total_amt:,.0f}')",
    "    ",
    "    # ========================================",
    "    # 🛍️ 商品別サマリー（高回転商品TOP100）",
    "    # ========================================",
    "    ",
    "    if '商品ID' in order_df.columns and '発注数量' in order_df.columns:",
    "        print(f'\\n🛍️ 商品別サマリーを出力中...')",
    "        ",
    "        sku_summary = order_df.groupby('商品ID').agg({",
    "            '発注数量': 'sum',",
    "            '予測売上金額': 'sum'",
    "        }).reset_index()",
    "        sku_summary.columns = ['商品ID', '総発注数量', '総予測売上金額']",
    "        sku_summary = sku_summary.nlargest(100, '総発注数量')",
    "        ",
    "        sku_summary_path = output_dir / '商品別サマリー_TOP100.csv'",
    "        sku_summary.to_csv(sku_summary_path, index=False, encoding='utf-8-sig')",
    "        print(f'  ✅ 商品別サマリー_TOP100.csv: {len(sku_summary)}件')",
    "    ",
    "    # ========================================",
    "    # 📊 全体サマリーレポート",
    "    # ========================================",
    "    ",
    "    print(f'\\n📊 全体サマリー:')",
    "    if '発注数量' in order_df.columns:",
    "        print(f'  総発注数量: {order_df[\"発注数量\"].sum():,} 個')",
    "    if '予測売上金額' in order_df.columns:",
    "        print(f'  総予測売上: ¥{order_df[\"予測売上金額\"].sum():,.0f}')",
    "    if '店舗ID' in order_df.columns:",
    "        print(f'  対象店舗数: {order_df[\"店舗ID\"].nunique()} 店舗')",
    "    if '商品ID' in order_df.columns:",
    "        print(f'  対象商品数: {order_df[\"商品ID\"].nunique()} SKU')",
    "    if '日付' in order_df.columns:",
    "        # 日付列をdatetimeに変換してmin/maxを取得",
    "        try:",
    "            date_col = pd.to_datetime(order_df[\"日付\"])",
    "            print(f'  予測期間: {date_col.min()} ～ {date_col.max()}')",
    "        except:",
    "            # Categorical型の場合はユニーク値でソート",
    "            dates = sorted(order_df[\"日付\"].unique())",
    "            if len(dates) > 0:",
    "                print(f'  予測期間: {dates[0]} ～ {dates[-1]}')",
    "    ",
    "    print(f'\\n✅ すべてのCSVファイルを output/ ディレクトリに保存しました')",
    "    print(f'\\n💡 発注表の使い方:')",
    "    print(f'  1. 日付別CSV: 日次の発注計画に使用')",
    "    print(f'  2. 店舗別CSV: 店舗ごとの発注指示に使用')",
    "    print(f'  3. 商品別サマリー: 重点商品の在庫管理に使用')",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}