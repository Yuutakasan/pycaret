{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad39ec2",
   "metadata": {},
   "source": [
    "# ğŸ” ç‰¹å¾´é‡åˆ†æï¼ˆAutoViz + PyCaretï¼‰v1 â€” AIå£²ä¸Šäºˆæ¸¬ãƒ„ãƒ¼ãƒ«\n",
    "\n",
    "## ğŸ“˜ ã“ã®ãƒ„ãƒ¼ãƒ«ã®ç›®çš„\n",
    "**AIãŒå£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•åˆ†æã—ã€ã€Œä½•ãŒå£²ä¸Šã«åŠ¹ãã‹ã€ã‚’æ•™ãˆã¦ãã‚Œã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚**\n",
    "\n",
    "### ğŸ¯ ã§ãã‚‹ã“ã¨\n",
    "1. ã‚°ãƒ©ãƒ•ã§è¦–è¦šçš„ã«å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèªï¼ˆAutoVizï¼‰\n",
    "2. AI ãŒé‡è¦ãªè¦å› ã‚’è‡ªå‹•ã§è¦‹ã¤ã‘ã‚‹ï¼ˆPyCaretï¼‰\n",
    "3. äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã€ç²¾åº¦ã‚’æ•°å€¤ã§ç¢ºèª\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ä½¿ã„æ–¹ï¼ˆç°¡å˜3ã‚¹ãƒ†ãƒƒãƒ—ï¼‰\n",
    "1. **ã‚»ãƒ«ã‚’ä¸Šã‹ã‚‰é †ã«å®Ÿè¡Œ**ï¼ˆå„ã‚»ãƒ«ã§ Shift+Enter ã‚’æŠ¼ã™ï¼‰\n",
    "2. **ã‚°ãƒ©ãƒ•ã‚’è¦‹ã¦ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª**\n",
    "3. **é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã§ã€æ³¨ç›®ã™ã¹ãè¦å› ã‚’ç‰¹å®š**\n",
    "\n",
    "---\n",
    "\n",
    "**ãã‚Œã§ã¯ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ã€Œä½•ã‚’è¦‹ã‚‹ã‹ã€ã€Œã©ã†åˆ¤æ–­ã™ã‚‹ã‹ã€ãŒæ›¸ã„ã¦ã‚ã‚Šã¾ã™ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ç’°å¢ƒ\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆMatplotlib/Plotlyï¼‰\n",
    "import font_setup  # IPAGothicç­‰ã‚’è‡ªå‹•è¨­å®š\n",
    "\n",
    "# AutoViz\n",
    "try:\n",
    "    from autoviz.AutoViz_Class import AutoViz_Class\n",
    "    AV_OK = True\n",
    "except Exception:\n",
    "    AV_OK = False\n",
    "\n",
    "# PyCaretï¼ˆå›å¸°ï¼‰\n",
    "try:\n",
    "    from pycaret.regression import setup, compare_models, pull, finalize_model, predict_model, plot_model\n",
    "    PYC_OK = True\n",
    "except Exception:\n",
    "    PYC_OK = False\n",
    "\n",
    "# ipywidgetsï¼ˆã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–UIï¼‰\n",
    "WIDGETS = False\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    WIDGETS = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±\n",
    "print(f'Python: {sys.version.split()[0]}')\n",
    "print(f'pandas: {pd.__version__}, numpy: {np.__version__}')\n",
    "print(f'AutoViz: {AV_OK}, PyCaret.regression: {PYC_OK}')\n",
    "\n",
    "# PyCaretã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆ3-fold CVã«å¿…è¦ï¼‰\n",
    "MIN_SAMPLES_PYCARET = 100\n",
    "\n",
    "# ========================================\n",
    "# ğŸš€ GPUæ¤œå‡ºã¨è¨­å®š\n",
    "# ========================================\n",
    "print('\\n' + '='*60)\n",
    "print('ğŸ–¥ï¸ GPUæ¤œå‡º')\n",
    "print('='*60)\n",
    "\n",
    "# GPUåˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "GPU_AVAILABLE = False\n",
    "GPU_DEVICE = 'cpu'\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_AVAILABLE = True\n",
    "        GPU_DEVICE = 'cuda'\n",
    "        print(f'âœ… NVIDIA GPUæ¤œå‡º: {torch.cuda.get_device_name(0)}')\n",
    "        print(f'   CUDA Version: {torch.version.cuda}')\n",
    "        print(f'   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "    else:\n",
    "        print('âš ï¸ PyTorch installed but no CUDA GPU found')\n",
    "except ImportError:\n",
    "    print('â„¹ï¸ PyTorch not installed (GPU detection skipped)')\n",
    "\n",
    "# LightGBM GPUå¯¾å¿œãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    if GPU_AVAILABLE:\n",
    "        print('âœ… LightGBM GPUå¯¾å¿œ: å¯èƒ½')\n",
    "    else:\n",
    "        print('â„¹ï¸  LightGBM: CPU mode')\n",
    "except ImportError:\n",
    "    print('â„¹ï¸ LightGBM not installed')\n",
    "\n",
    "# XGBoost GPUå¯¾å¿œãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    if GPU_AVAILABLE:\n",
    "        print('âœ… XGBoost GPUå¯¾å¿œ: å¯èƒ½')\n",
    "    else:\n",
    "        print('â„¹ï¸ XGBoost: CPU mode')\n",
    "except ImportError:\n",
    "    print('â„¹ï¸ XGBoost not installed')\n",
    "\n",
    "# CatBoost GPUå¯¾å¿œãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import catboost\n",
    "    if GPU_AVAILABLE:\n",
    "        print('âœ… CatBoost GPUå¯¾å¿œ: å¯èƒ½')\n",
    "    else:\n",
    "        print('â„¹ï¸ CatBoost: CPU mode')\n",
    "except ImportError:\n",
    "    print('â„¹ï¸ CatBoost not installed')\n",
    "# cuDF (GPU Pandas) ãƒã‚§ãƒƒã‚¯\n",
    "CUDF_AVAILABLE = False\n",
    "try:\n",
    "    import cudf\n",
    "    if GPU_AVAILABLE:\n",
    "        CUDF_AVAILABLE = True\n",
    "        print('âœ… cuDF (GPU Pandas) å¯¾å¿œ: å¯èƒ½')\n",
    "    else:\n",
    "        print('â„¹ï¸ cuDF: GPU not available, using CPU Pandas')\n",
    "except ImportError:\n",
    "    print('â„¹ï¸ cuDF not installed (CPU Pandasç¶™ç¶š)')\n",
    "\n",
    "# GPUä½¿ç”¨ãƒ•ãƒ©ã‚°ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¤‰æ›´å¯èƒ½ï¼‰\n",
    "USE_GPU = GPU_AVAILABLE  # Trueã«è¨­å®šã™ã‚‹ã¨GPUã‚’ä½¿ç”¨ï¼ˆGPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰\n",
    "\n",
    "if USE_GPU:\n",
    "    print(f'\\nğŸš€ GPUä½¿ç”¨: æœ‰åŠ¹ï¼ˆæ¨å®š2ï½10å€é«˜é€ŸåŒ–ï¼‰')\n",
    "    print(f'   Device: {GPU_DEVICE}')\n",
    "else:\n",
    "    print(f'\\nâ„¹ï¸ GPUä½¿ç”¨: ç„¡åŠ¹ï¼ˆCPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼‰')\n",
    "    if GPU_AVAILABLE:\n",
    "        print('   ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ä¸Šã®ã‚»ãƒ«ã§ USE_GPU = True ã«è¨­å®šã™ã‚‹ã¨GPUä½¿ç”¨å¯èƒ½')\n",
    "\n",
    "print('='*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ”§ GPU/CPU ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "# ========================================\n",
    "\n",
    "def to_gpu(df):\n",
    "    \"\"\"pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’GPU (cuDF) ã«å¤‰æ›ï¼ˆUSE_GPU=Trueã®å ´åˆã®ã¿ï¼‰\"\"\"\n",
    "    if USE_GPU and CUDF_AVAILABLE and df is not None and not df.empty:\n",
    "        try:\n",
    "            import cudf\n",
    "            return cudf.from_pandas(df)\n",
    "        except Exception as e:\n",
    "            print(f'âš ï¸ GPUå¤‰æ›å¤±æ•—ã€CPUãƒ¢ãƒ¼ãƒ‰ç¶™ç¶š: {e}')\n",
    "            return df\n",
    "    return df\n",
    "\n",
    "def to_cpu(df):\n",
    "    \"\"\"cuDFãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’pandasã«å¤‰æ›\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    try:\n",
    "        import cudf\n",
    "        if isinstance(df, cudf.DataFrame):\n",
    "            return df.to_pandas()\n",
    "    except:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "# GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³è¡¨ç¤º\n",
    "def show_gpu_memory():\n",
    "    if GPU_AVAILABLE:\n",
    "        try:\n",
    "            import torch\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "            print(f'ğŸ“Š GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if USE_GPU and CUDF_AVAILABLE:\n",
    "    print('âœ… GPUé«˜é€ŸåŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£: æº–å‚™å®Œäº†')\n",
    "    print('   to_gpu(df) ã§GPUå‡¦ç†ã€to_cpu(df) ã§CPUæˆ»ã—')\n",
    "    show_gpu_memory()\n",
    "else:\n",
    "    print('â„¹ï¸ CPUå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆGPUãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¯ç„¡åŠ¹ï¼‰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ãƒ•ã‚©ãƒ³ãƒˆå¼·åˆ¶ãƒªã‚»ãƒƒãƒˆï¼ˆæ—¥æœ¬èªå¯¾å¿œ / AutoVizå¯¾ç­–ï¼‰\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "try:\n",
    "    import japanize_matplotlib; japanize_matplotlib.japanize()\n",
    "except Exception:\n",
    "    pass\n",
    "candidates = ['IPAGothic','IPAexGothic','Noto Sans CJK JP','Noto Sans JP','Yu Gothic','Meiryo','Hiragino Sans','MS Gothic']\n",
    "avail = []\n",
    "try:\n",
    "    names = [getattr(f,'name','') for f in fm.fontManager.ttflist]\n",
    "    for nm in candidates:\n",
    "        if any(nm in n for n in names):\n",
    "            if nm not in avail:\n",
    "                avail.append(nm)\n",
    "except Exception:\n",
    "    pass\n",
    "if not avail:\n",
    "    avail = ['Noto Sans CJK JP','IPAGothic','DejaVu Sans']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = avail + ['DejaVu Sans']\n",
    "plt.rcParams['font.serif'] = ['Noto Serif CJK JP','IPAMincho','DejaVu Serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "try:\n",
    "    sns.set_theme(rc={'font.family':'sans-serif','font.sans-serif': plt.rcParams['font.sans-serif']})\n",
    "except Exception:\n",
    "    pass\n",
    "print('ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š:', plt.rcParams['font.family'], 'â†’', plt.rcParams['font.sans-serif'][:3], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8928fdd",
   "metadata": {},
   "source": [
    "## ğŸ“‚ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "\n",
    "### ğŸ¯ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„**\n",
    "å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆCSVå½¢å¼ï¼‰ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "\n",
    "### ğŸ‘€ **åº—é•·ãŒç¢ºèªã™ã¹ãã“ã¨**\n",
    "å®Ÿè¡Œå¾Œã€ä»¥ä¸‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼š\n",
    "```\n",
    "[INFO] globæ¤œå‡º: output/06_final_enriched_20250701_20250930.csv\n",
    "[INFO] åˆ—åå¤‰æ›: 8/8 ä»¶é©ç”¨ â†’ ['store_id', 'sku_id', 'date'...]\n",
    "èª­ã¿è¾¼ã¿å®Œäº†: 06_final_enriched_20250930.csv | shape=(50000, 40) | memory=15.2MB\n",
    "```\n",
    "\n",
    "**æ„å‘³**:\n",
    "- `shape=(50000, 40)` â†’ 50,000è¡ŒÃ—40åˆ—ã®ãƒ‡ãƒ¼ã‚¿\n",
    "- `memory=15.2MB` â†’ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡\n",
    "\n",
    "**åˆ¤æ–­ãƒã‚¤ãƒ³ãƒˆ**:\n",
    "- ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ â†’ `output`ãƒ•ã‚©ãƒ«ãƒ€ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª\n",
    "- ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆ â†’ ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚’çŸ­ç¸®æ¤œè¨\n",
    "\n",
    "---\n",
    "\n",
    "**æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ â†“**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ffb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_enriched_csv():\n",
    "    \"\"\"\n",
    "    enriched CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡º\n",
    "    å„ªå…ˆé †: ç’°å¢ƒå¤‰æ•° â†’ globæœ€æ–° â†’ æ—¢å®šå€¤\n",
    "    \"\"\"\n",
    "    for env in ('DATA_PATH','ENRICHED_CSV'):\n",
    "        p = os.environ.get(env)\n",
    "        if p and Path(p).exists():\n",
    "            print(f'[INFO] ç’°å¢ƒå¤‰æ•° {env} ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—: {p}')\n",
    "            return Path(p)\n",
    "    d = Path('output')\n",
    "    if d.exists():\n",
    "        c = sorted(d.glob('06_final_enriched_*.csv'), reverse=True)\n",
    "        if c:\n",
    "            print(f'[INFO] globæ¤œå‡º: {c[0]}')\n",
    "            return c[0]\n",
    "    f = Path('output/06_final_enriched_20250701_20250930.csv')\n",
    "    if f.exists():\n",
    "        print(f'[INFO] æ—¢å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {f}')\n",
    "        return f\n",
    "    return None\n",
    "\n",
    "CSV_PATH = pick_enriched_csv()\n",
    "if not CSV_PATH:\n",
    "    raise FileNotFoundError('output/06_final_enriched_*.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚work/output ã«é…ç½®ã€ã¾ãŸã¯ç’°å¢ƒå¤‰æ•° DATA_PATH ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚')\n",
    "\n",
    "# ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "try:\n",
    "    import psutil\n",
    "    file_size_mb = CSV_PATH.stat().st_size / (1024**2)\n",
    "    available_mem_mb = psutil.virtual_memory().available / (1024**2)\n",
    "    if file_size_mb > available_mem_mb * 0.5:\n",
    "        print(f'[WARNING] ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º {file_size_mb:.1f}MB ãŒåˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®50%è¶…')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "df_raw = pd.read_csv(CSV_PATH, encoding='utf-8-sig')\n",
    "df = df_raw.copy()\n",
    "\n",
    "# åˆ—åæ­£è¦åŒ–ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰\n",
    "rename_map = {\n",
    "    'åº—èˆ—':'åº—èˆ—','å•†å“å':'å•†å“å','æ—¥ä»˜':'æ—¥ä»˜','å£²ä¸Šæ•°é‡':'å£²ä¸Šæ•°é‡','å£²ä¸Šé‡‘é¡':'å£²ä¸Šé‡‘é¡',\n",
    "    'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡':'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡','ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡':'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡','ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡':'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡'\n",
    "}\n",
    "renamed = {k:v for k,v in rename_map.items() if k in df.columns}\n",
    "df = df.rename(columns=renamed)\n",
    "print(f'[INFO] åˆ—åå¤‰æ›: {len(renamed)}/{len(rename_map)} ä»¶é©ç”¨ â†’ {list(renamed.values())}')\n",
    "\n",
    "if 'æ—¥ä»˜' in df.columns: df['æ—¥ä»˜'] = pd.to_datetime(df['æ—¥ä»˜'])\n",
    "if 'å£²ä¸Šæ•°é‡' in df.columns: df['å£²ä¸Šæ•°é‡'] = pd.to_numeric(df['å£²ä¸Šæ•°é‡'], errors='coerce').fillna(0).astype('float32')\n",
    "if 'å£²ä¸Šé‡‘é¡' in df.columns: df['å£²ä¸Šé‡‘é¡'] = pd.to_numeric(df['å£²ä¸Šé‡‘é¡'], errors='coerce').fillna(0).astype('float32')\n",
    "\n",
    "print(f'èª­ã¿è¾¼ã¿å®Œäº†: {CSV_PATH.name} | shape={df.shape} | memory={df.memory_usage(deep=True).sum()/(1024**2):.1f}MB')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e69d3f",
   "metadata": {},
   "source": [
    "## ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—2: å£²ä¸Šæœ€å¤§åŒ–ã®ãŸã‚ã®ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šåˆ†æ\n",
    "\n",
    "### ğŸ¯ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„**\n",
    "**å£²ä¸Šã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã€ã©ã®ãƒ•ãƒ©ã‚°ï¼ˆå¤©å€™ãƒ»æ›œæ—¥ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰ã®æ—¥ã«å£²ä¸ŠãŒä¼¸ã³ã‚‹ã‹ã‚’åˆ†æã—ã¾ã™ã€‚**\n",
    "\n",
    "### âš ï¸ **é‡è¦ãªå¤‰æ›´ç‚¹ï¼ˆå¾“æ¥ã®AutoVizã‹ã‚‰å¤‰æ›´ï¼‰**\n",
    "- âŒ **å‰Šé™¤**: æ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã®æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ—¥ä»˜ã¨å£²ä¸Šã®æ¯”è¼ƒï¼‰\n",
    "- âœ… **è¿½åŠ **: ãƒ•ãƒ©ã‚°åˆ¥ã®å£²ä¸Šæ¯”è¼ƒï¼ˆé™é›¨ãƒ•ãƒ©ã‚°ã€é€±æœ«ãƒ•ãƒ©ã‚°ç­‰ã¨å£²ä¸Šã®ç›¸é–¢ï¼‰\n",
    "- âœ… **è¿½åŠ **: å•†å“ã‚«ãƒ†ã‚´ãƒªé¸æŠæ©Ÿèƒ½ï¼ˆç‰¹å®šã‚«ãƒ†ã‚´ãƒªã«çµã£ãŸåˆ†æãŒå¯èƒ½ï¼‰\n",
    "\n",
    "### ğŸ“ˆ **ä½•ãŒåˆ†æã•ã‚Œã‚‹ã‹**\n",
    "\n",
    "#### 1ï¸âƒ£ **ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šå¢—åŠ ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°**\n",
    "- å„ãƒ•ãƒ©ã‚°ï¼ˆé™é›¨ã€é€±æœ«ã€çŒ›æš‘æ—¥ãªã©ï¼‰ãŒONã®æ—¥ã¨OFFã®æ—¥ã§ã€å£²ä¸ŠãŒã©ã‚Œã ã‘å¤‰ã‚ã‚‹ã‹ã‚’è¨ˆç®—\n",
    "- å£²ä¸Šå¢—åŠ ç‡ãŒé«˜ã„ãƒ•ãƒ©ã‚° = å£²ä¸Šæœ€å¤§åŒ–ã®ãƒãƒ£ãƒ³ã‚¹æ—¥\n",
    "\n",
    "#### 2ï¸âƒ£ **ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šåˆ†å¸ƒã®å¯è¦–åŒ–**\n",
    "- ãƒ•ãƒ©ã‚°ONæ™‚ã¨OFFæ™‚ã®å£²ä¸Šåˆ†å¸ƒã‚’æ¯”è¼ƒ\n",
    "- ã©ã®ãƒ•ãƒ©ã‚°ã®æ—¥ã«é«˜é¡å£²ä¸ŠãŒç™ºç”Ÿã—ã‚„ã™ã„ã‹ã‚’è¦–è¦šçš„ã«æŠŠæ¡\n",
    "\n",
    "#### 3ï¸âƒ£ **ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ**\n",
    "- å•†å“ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ã€ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ\n",
    "- ä¾‹: ã€Œé£²æ–™ã€ã‚«ãƒ†ã‚´ãƒªã¯çŒ›æš‘æ—¥ã«å£²ä¸Šâ†‘ã€ã€ŒãŠã§ã‚“ã€ã¯å†¬æ—¥ã«å£²ä¸Šâ†‘\n",
    "\n",
    "### ğŸ‘€ **åº—é•·ãŒç¢ºèªã™ã¹ãã“ã¨**\n",
    "\n",
    "#### âœ… **å®Ÿè¡Œå¾Œã«è¡¨ç¤ºã•ã‚Œã‚‹æƒ…å ±**\n",
    "1. **ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šå¢—åŠ ç‡ TOP10 ãƒ†ãƒ¼ãƒ–ãƒ«**\n",
    "   - å„ãƒ•ãƒ©ã‚°ã®ON/OFFæ™‚ã®å¹³å‡å£²ä¸Š\n",
    "   - å£²ä¸Šå¢—åŠ ç‡ï¼ˆ%ï¼‰\n",
    "   - è©²å½“æ—¥æ•°\n",
    "\n",
    "2. **ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šå¢—åŠ ç‡ã®æ£’ã‚°ãƒ©ãƒ•**\n",
    "   - èµ¤ã„æ£’ï¼ˆãƒ—ãƒ©ã‚¹ï¼‰: ã“ã®ãƒ•ãƒ©ã‚°ã®æ—¥ã¯å£²ä¸ŠãŒå¢—åŠ  â†’ **é™³åˆ—ãƒ»ç™ºæ³¨ã‚’å¼·åŒ–ã™ã¹ãæ—¥**\n",
    "   - é’ã„æ£’ï¼ˆãƒã‚¤ãƒŠã‚¹ï¼‰: ã“ã®ãƒ•ãƒ©ã‚°ã®æ—¥ã¯å£²ä¸ŠãŒæ¸›å°‘ â†’ åœ¨åº«ã‚’æŠ‘åˆ¶\n",
    "\n",
    "3. **ä¸Šä½5ãƒ•ãƒ©ã‚°ã®ON/OFFå£²ä¸Šåˆ†å¸ƒã‚°ãƒ©ãƒ•**\n",
    "   - èµ¤ã„åˆ†å¸ƒï¼ˆãƒ•ãƒ©ã‚°ONï¼‰ãŒå³ã«ã‚·ãƒ•ãƒˆ â†’ ãã®ãƒ•ãƒ©ã‚°ã®æ—¥ã¯é«˜é¡å£²ä¸ŠãŒç™ºç”Ÿã—ã‚„ã™ã„\n",
    "   - é’ã„åˆ†å¸ƒï¼ˆãƒ•ãƒ©ã‚°OFFï¼‰ã¨ã®å·®ãŒå¤§ãã„ â†’ ãã®ãƒ•ãƒ©ã‚°ã®å½±éŸ¿ãŒå¤§ãã„\n",
    "\n",
    "### ğŸ’¡ **åº—é•·ã®å®Ÿå‹™ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**\n",
    "\n",
    "#### ğŸ¯ **å£²ä¸Šå¢—åŠ ç‡ãŒé«˜ã„ãƒ•ãƒ©ã‚°ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ**\n",
    "\n",
    "**ä¾‹: ã€Œé™é›¨ãƒ•ãƒ©ã‚°ã€ã®å£²ä¸Šå¢—åŠ ç‡ +25%**\n",
    "â†’ **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:\n",
    "- é™é›¨äºˆå ±ã®æ—¥ã®å‰æ—¥ã«ã€æ¸©ã‹ã„ç·èœãƒ»ã‚«ãƒƒãƒ—éººãƒ»ãƒ›ãƒƒãƒˆé£²æ–™ã®ç™ºæ³¨ã‚’1.3å€ã«å¢—ã‚„ã™\n",
    "- å…¥å£ä»˜è¿‘ã«å‚˜ãƒ»ãƒ¬ã‚¤ãƒ³ã‚³ãƒ¼ãƒˆãƒ»ãƒ›ãƒƒãƒˆå•†å“ã®ç‰¹è¨­ã‚³ãƒ¼ãƒŠãƒ¼ã‚’è¨­ç½®\n",
    "- ä¸­è¯ã¾ã‚“ãƒ»ãŠã§ã‚“ã®ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ‹¡å¤§\n",
    "\n",
    "**ä¾‹: ã€Œé€±æœ«ãƒ•ãƒ©ã‚°ã€ã®å£²ä¸Šå¢—åŠ ç‡ +18%**\n",
    "â†’ **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:\n",
    "- é‡‘æ›œå¤•æ–¹ã‹ã‚‰å¼å½“ãƒ»ãƒ‡ã‚¶ãƒ¼ãƒˆãƒ»é…’é¡ã®é™³åˆ—ã‚’å¼·åŒ–\n",
    "- åœŸæ—¥ã®æœã¯æœé£Ÿéœ€è¦ï¼ˆãƒ‘ãƒ³ãƒ»ã‚³ãƒ¼ãƒ’ãƒ¼ï¼‰ã€æ˜¼ã¯å¼å½“ã€å¤•æ–¹ã¯é…’é¡ã®ãƒ”ãƒ¼ã‚¯å¯¾å¿œ\n",
    "- å®¶æ—å‘ã‘å¤§å®¹é‡å•†å“ã®ãƒ•ã‚§ãƒ¼ã‚¹æ‹¡å¤§\n",
    "\n",
    "**ä¾‹: ã€Œçµ¦æ–™æ—¥ãƒ•ãƒ©ã‚°ã€ã®å£²ä¸Šå¢—åŠ ç‡ +12%**\n",
    "â†’ **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:\n",
    "- çµ¦æ–™æ—¥ï¼ˆ25æ—¥å‰å¾Œï¼‰ã¯é«˜å˜ä¾¡å¼å½“ãƒ»ã‚¹ã‚¤ãƒ¼ãƒ„ãƒ»ãƒ—ãƒ¬ãƒŸã‚¢ãƒ å•†å“ã‚’ç›®ç«‹ã¤ä½ç½®ã«\n",
    "- å¤•æ–¹ã®å‰å‡ºã—æ™‚é–“ã‚’æ—©ã‚ã‚‹ï¼ˆ17æ™‚â†’16æ™‚30åˆ†ï¼‰\n",
    "\n",
    "#### ğŸ“Š **ã‚«ãƒ†ã‚´ãƒªé¸æŠã®æ´»ç”¨æ–¹æ³•**\n",
    "\n",
    "ä¸Šã®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆï¼ˆSelectMultipleï¼‰ã§å•†å“ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã™ã‚‹ã¨ã€ãã®ã‚«ãƒ†ã‚´ãƒªã«ç‰¹åŒ–ã—ãŸãƒ•ãƒ©ã‚°åˆ†æãŒå†å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "**ä½¿ã„æ–¹**:\n",
    "1. ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‹ã‚‰åˆ†æã—ãŸã„ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠï¼ˆCtrl/Cmd + ã‚¯ãƒªãƒƒã‚¯ã§è¤‡æ•°é¸æŠï¼‰\n",
    "2. è‡ªå‹•ã§å†åˆ†æãŒå®Ÿè¡Œã•ã‚Œã€ãã®ã‚«ãƒ†ã‚´ãƒªã®å£²ä¸Šæœ€å¤§åŒ–ãƒ•ãƒ©ã‚°ãŒè¡¨ç¤ºã•ã‚Œã‚‹\n",
    "3. ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®æœ€é©ãªç™ºæ³¨ãƒ»é™³åˆ—æˆ¦ç•¥ã‚’ç«‹ã¦ã‚‹\n",
    "\n",
    "**ä¾‹**:\n",
    "- **ã€Œé£²æ–™ã€**ã‚’é¸æŠ â†’ ã€ŒçŒ›æš‘æ—¥ã€ã€ŒçœŸå¤æ—¥ã€ãƒ•ãƒ©ã‚°ã§å£²ä¸Šâ†‘ â†’ å¤æ—¥ã®å†·é£²æ–™ç™ºæ³¨å¼·åŒ–\n",
    "- **ã€Œå¼å½“ã€**ã‚’é¸æŠ â†’ ã€Œé€±æœ«ãƒ•ãƒ©ã‚°ã€ã€Œæ˜¼ãƒ”ãƒ¼ã‚¯ã€ã§å£²ä¸Šâ†‘ â†’ åœŸæ—¥ã®å¼å½“ç™ºæ³¨1.5å€\n",
    "- **ã€Œãƒ‡ã‚¶ãƒ¼ãƒˆã€**ã‚’é¸æŠ â†’ ã€Œçµ¦æ–™æ—¥ã€ã€Œé€±æœ«ã€ã§å£²ä¸Šâ†‘ â†’ é«˜å˜ä¾¡ã‚¹ã‚¤ãƒ¼ãƒ„é™³åˆ—å¼·åŒ–\n",
    "\n",
    "### ğŸš€ **å®Ÿè¡Œæ–¹æ³•**\n",
    "ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚è‡ªå‹•ã§ä»¥ä¸‹ãŒè¡Œã‚ã‚Œã¾ã™:\n",
    "1. ã‚«ãƒ†ã‚´ãƒªé¸æŠã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®è¡¨ç¤ºï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰\n",
    "2. å…¨ã‚«ãƒ†ã‚´ãƒªã§ã®ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šåˆ†æ\n",
    "3. TOP10ãƒ•ãƒ©ã‚°ã®è¡¨ç¤ºã¨ã‚°ãƒ©ãƒ•å¯è¦–åŒ–\n",
    "4. ã‚«ãƒ†ã‚´ãƒªé¸æŠæ™‚ã®è‡ªå‹•å†åˆ†æ\n",
    "\n",
    "### ğŸ’¾ **GPUé«˜é€ŸåŒ–ã«ã¤ã„ã¦**\n",
    "- ã“ã®ã‚»ãƒ«ã§ã¯ä¸»ã«ã‚°ãƒ©ãƒ•æç”»ã‚’è¡Œã†ãŸã‚ã€GPUåŠ¹æœã¯é™å®šçš„ã§ã™\n",
    "- æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆPyCaretï¼‰ã§å¤§è¦æ¨¡ãªAIå­¦ç¿’ãŒå®Ÿè¡Œã•ã‚Œã€GPUã®åŠ¹æœãŒæœ€å¤§åŒ–ã•ã‚Œã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ“Š å£²ä¸Šæœ€å¤§åŒ–åˆ†æ: ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šæ¯”è¼ƒï¼ˆå…¨ã‚«ãƒ†ã‚´ãƒªï¼‰\n",
    "# ========================================\n",
    "print('\\n' + '='*60)\n",
    "print('ğŸ“Š å£²ä¸Šæœ€å¤§åŒ–åˆ†æ: ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šæ¯”è¼ƒ')\n",
    "print('='*60)\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦ä½¿ç”¨ï¼‰\n",
    "# selected_categories = ['å…¨ã‚«ãƒ†ã‚´ãƒª']  # ã¾ãŸã¯ ['è“å­', 'é£²æ–™'] ã®ã‚ˆã†ã«æŒ‡å®š\n",
    "selected_categories = ['å…¨ã‚«ãƒ†ã‚´ãƒª']\n",
    "\n",
    "def analyze_sales_by_flags():\n",
    "    \"\"\"ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šåˆ†æã®å®Ÿè¡Œ\"\"\"\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª\n",
    "    if 'df' not in globals():\n",
    "        print('âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  \"df\" ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã‚¹ãƒ†ãƒƒãƒ—1ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚')\n",
    "        return\n",
    "    \n",
    "    # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿é©ç”¨\n",
    "    df_filtered = df.copy()\n",
    "    if 'å…¨ã‚«ãƒ†ã‚´ãƒª' not in selected_categories and 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡' in df.columns:\n",
    "        df_filtered = df_filtered[df_filtered['ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡'].isin(selected_categories)]\n",
    "        print(f'âœ… ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {selected_categories} ({len(df_filtered):,}ä»¶)')\n",
    "    else:\n",
    "        print('â„¹ï¸ å…¨ã‚«ãƒ†ã‚´ãƒªã§åˆ†æã—ã¾ã™')\n",
    "    \n",
    "    # ãƒ‡ãƒãƒƒã‚°: ã‚«ãƒ©ãƒ åã‚’è¡¨ç¤º\n",
    "    print(f'\\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ æ•°: {len(df_filtered.columns)}')\n",
    "    flag_like_cols = [c for c in df_filtered.columns if 'flag' in c.lower() or c.startswith('is_') or c.startswith('has_')]\n",
    "    \n",
    "    if flag_like_cols:\n",
    "        print(f'ğŸ“Œ ãƒ•ãƒ©ã‚°ç³»ã‚«ãƒ©ãƒ å€™è£œ: {len(flag_like_cols)}å€‹')\n",
    "        for i, col in enumerate(flag_like_cols[:20], 1):  # æœ€åˆã®20å€‹ã¾ã§è¡¨ç¤º\n",
    "            print(f'  {i}. {col}')\n",
    "        if len(flag_like_cols) > 20:\n",
    "            print(f'  ... ä»– {len(flag_like_cols)-20}å€‹')\n",
    "    \n",
    "    # ãƒ•ãƒ©ã‚°ã‚«ãƒ©ãƒ æ¤œå‡ºï¼ˆæŸ”è»Ÿãªæ¤œç´¢ï¼‰\n",
    "    flag_cols = []\n",
    "    \n",
    "    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: flag_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.startswith('flag_')])\n",
    "    \n",
    "    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: is_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆãƒ–ãƒ¼ãƒ«å€¤ï¼‰\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.startswith('is_')])\n",
    "    \n",
    "    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: has_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.startswith('has_')])\n",
    "    \n",
    "    # ãƒ‘ã‚¿ãƒ¼ãƒ³4: æ—¥æœ¬èªãƒ•ãƒ©ã‚°ï¼ˆ_ãƒ•ãƒ©ã‚° ã§çµ‚ã‚ã‚‹ï¼‰\n",
    "    flag_cols.extend([c for c in df_filtered.columns if c.endswith('_ãƒ•ãƒ©ã‚°') or c.endswith('ãƒ•ãƒ©ã‚°')])\n",
    "    \n",
    "    # é‡è¤‡å‰Šé™¤\n",
    "    flag_cols = list(set(flag_cols))\n",
    "    \n",
    "    if not flag_cols:\n",
    "        print('\\nâš ï¸ ãƒ•ãƒ©ã‚°ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')\n",
    "        print('\\nğŸ’¡ ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å½¢å¼ã§ãƒ•ãƒ©ã‚°ã‚«ãƒ©ãƒ ã‚’ä½œæˆã—ã¦ãã ã•ã„:')\n",
    "        print('  - flag_é›¨å¤©æ—¥')\n",
    "        print('  - is_weekend')\n",
    "        print('  - has_event')\n",
    "        print('  - ã‚¤ãƒ™ãƒ³ãƒˆ_ãƒ•ãƒ©ã‚°')\n",
    "        print('\\nğŸ“Œ ç¾åœ¨ã®ã‚«ãƒ©ãƒ ã§æ•°å€¤å‹ï¼ˆ0/1ã®å€™è£œï¼‰:')\n",
    "        numeric_binary = []\n",
    "        for col in df_filtered.select_dtypes(include=[np.number]).columns:\n",
    "            unique_vals = df_filtered[col].dropna().unique()\n",
    "            if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, 0.0, 1.0}):\n",
    "                numeric_binary.append(col)\n",
    "        \n",
    "        if numeric_binary:\n",
    "            for i, col in enumerate(numeric_binary[:10], 1):\n",
    "                print(f'  {i}. {col}')\n",
    "            print('\\nğŸ’¡ ã“ã‚Œã‚‰ã®ã‚«ãƒ©ãƒ ã‚’ \"flag_\" ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã«å¤‰æ›´ã™ã‚‹ã¨åˆ†æã§ãã¾ã™')\n",
    "        else:\n",
    "            print('  ãªã—ï¼ˆ0/1ã®2å€¤ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰')\n",
    "        return\n",
    "    \n",
    "    print(f'\\nğŸ“Œ åˆ†æå¯¾è±¡ãƒ•ãƒ©ã‚°: {len(flag_cols)}å€‹')\n",
    "    for i, col in enumerate(flag_cols, 1):\n",
    "        print(f'  {i}. {col}')\n",
    "    \n",
    "    # å£²ä¸Šã‚«ãƒ©ãƒ æ¤œå‡º\n",
    "    sales_col = None\n",
    "    for col_name in ['å£²ä¸Šé‡‘é¡', 'å£²ä¸Šé‡‘é¡', 'sales', 'amount', 'å£²ä¸Š']:\n",
    "        if col_name in df_filtered.columns:\n",
    "            sales_col = col_name\n",
    "            break\n",
    "    \n",
    "    if sales_col is None:\n",
    "        print('\\nâš ï¸ å£²ä¸Šã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')\n",
    "        print('ğŸ’¡ ä»¥ä¸‹ã®ã‚«ãƒ©ãƒ åã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„: sales_amt, å£²ä¸Šé‡‘é¡, sales, amount')\n",
    "        return\n",
    "    \n",
    "    print(f'\\nğŸ’° å£²ä¸Šã‚«ãƒ©ãƒ : {sales_col}')\n",
    "    \n",
    "    # ãƒ•ãƒ©ã‚°åˆ¥é›†è¨ˆ\n",
    "    results = []\n",
    "    for fc in flag_cols:\n",
    "        # 0/1ä»¥å¤–ã®å€¤ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "        unique_vals = df_filtered[fc].dropna().unique()\n",
    "        if not set(unique_vals).issubset({0, 1, 0.0, 1.0, True, False}):\n",
    "            print(f'âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {fc} (0/1ä»¥å¤–ã®å€¤ã‚’å«ã‚€: {unique_vals})')\n",
    "            continue\n",
    "        \n",
    "        flag_on = df_filtered[df_filtered[fc].isin([1, 1.0, True])]\n",
    "        flag_off = df_filtered[df_filtered[fc].isin([0, 0.0, False])]\n",
    "        \n",
    "        if len(flag_on) == 0 or len(flag_off) == 0:\n",
    "            continue\n",
    "        \n",
    "        on_mean = flag_on[sales_col].mean()\n",
    "        off_mean = flag_off[sales_col].mean()\n",
    "        on_sum = flag_on[sales_col].sum()\n",
    "        off_sum = flag_off[sales_col].sum()\n",
    "        \n",
    "        mean_diff = on_mean - off_mean\n",
    "        mean_lift = (mean_diff / off_mean * 100) if off_mean > 0 else 0\n",
    "        \n",
    "        # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¦è¡¨ç¤ºåã‚’ä½œæˆ\n",
    "        display_name = fc.replace('flag_', '').replace('is_', '').replace('has_', '').replace('_ãƒ•ãƒ©ã‚°', '')\n",
    "        \n",
    "        results.append({\n",
    "            'ãƒ•ãƒ©ã‚°': display_name,\n",
    "            'ONä»¶æ•°': len(flag_on),\n",
    "            'OFFä»¶æ•°': len(flag_off),\n",
    "            'ONå¹³å‡': on_mean,\n",
    "            'OFFå¹³å‡': off_mean,\n",
    "            'å¹³å‡å·®': mean_diff,\n",
    "            'å¹³å‡ãƒªãƒ•ãƒˆ(%)': mean_lift,\n",
    "            'ONåˆè¨ˆ': on_sum,\n",
    "            'OFFåˆè¨ˆ': off_sum,\n",
    "            'åˆè¨ˆå·®': on_sum - off_sum\n",
    "        })\n",
    "    \n",
    "    if not results:\n",
    "        print('âš ï¸ åˆ†æå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')\n",
    "        return\n",
    "    \n",
    "    # çµæœã‚’DataFrameã«å¤‰æ›\n",
    "    df_result = pd.DataFrame(results).sort_values('å¹³å‡ãƒªãƒ•ãƒˆ(%)', ascending=False)\n",
    "    \n",
    "    # å¯è¦–åŒ–: 4ãƒ‘ãƒãƒ«\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('ğŸ“Š ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ', fontsize=16, fontproperties=font_setup.jp_font)\n",
    "    \n",
    "    # 1. å¹³å‡ãƒªãƒ•ãƒˆç‡\n",
    "    ax1 = axes[0, 0]\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_result['å¹³å‡ãƒªãƒ•ãƒˆ(%)']]\n",
    "    ax1.barh(df_result['ãƒ•ãƒ©ã‚°'], df_result['å¹³å‡ãƒªãƒ•ãƒˆ(%)'], color=colors, alpha=0.7)\n",
    "    ax1.set_xlabel('å¹³å‡ãƒªãƒ•ãƒˆç‡ (%)', fontproperties=font_setup.jp_font)\n",
    "    ax1.set_title('1ï¸âƒ£ å¹³å‡å£²ä¸Šãƒªãƒ•ãƒˆç‡ï¼ˆONæ™‚ã®å¢—æ¸›ï¼‰', fontproperties=font_setup.jp_font)\n",
    "    ax1.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 2. ON/OFFå¹³å‡å£²ä¸Šæ¯”è¼ƒ\n",
    "    ax2 = axes[0, 1]\n",
    "    x = np.arange(len(df_result))\n",
    "    width = 0.35\n",
    "    ax2.bar(x - width/2, df_result['OFFå¹³å‡'], width, label='OFF', alpha=0.7, color='lightcoral')\n",
    "    ax2.bar(x + width/2, df_result['ONå¹³å‡'], width, label='ON', alpha=0.7, color='skyblue')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(df_result['ãƒ•ãƒ©ã‚°'], rotation=45, ha='right', fontproperties=font_setup.jp_font)\n",
    "    ax2.set_ylabel('å¹³å‡å£²ä¸Šï¼ˆå††ï¼‰', fontproperties=font_setup.jp_font)\n",
    "    ax2.set_title('2ï¸âƒ£ ON/OFFæ™‚ã®å¹³å‡å£²ä¸Šæ¯”è¼ƒ', fontproperties=font_setup.jp_font)\n",
    "    ax2.legend(prop=font_setup.jp_font)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 3. ä»¶æ•°åˆ†å¸ƒ\n",
    "    ax3 = axes[1, 0]\n",
    "    x = np.arange(len(df_result))\n",
    "    ax3.bar(x - width/2, df_result['OFFä»¶æ•°'], width, label='OFF', alpha=0.7, color='lightcoral')\n",
    "    ax3.bar(x + width/2, df_result['ONä»¶æ•°'], width, label='ON', alpha=0.7, color='skyblue')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(df_result['ãƒ•ãƒ©ã‚°'], rotation=45, ha='right', fontproperties=font_setup.jp_font)\n",
    "    ax3.set_ylabel('ä»¶æ•°', fontproperties=font_setup.jp_font)\n",
    "    ax3.set_title('3ï¸âƒ£ ON/OFFæ™‚ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°', fontproperties=font_setup.jp_font)\n",
    "    ax3.legend(prop=font_setup.jp_font)\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. åˆè¨ˆå£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ\n",
    "    ax4 = axes[1, 1]\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_result['åˆè¨ˆå·®']]\n",
    "    ax4.barh(df_result['ãƒ•ãƒ©ã‚°'], df_result['åˆè¨ˆå·®']/1000, color=colors, alpha=0.7)\n",
    "    ax4.set_xlabel('åˆè¨ˆå£²ä¸Šå·®ï¼ˆåƒå††ï¼‰', fontproperties=font_setup.jp_font)\n",
    "    ax4.set_title('4ï¸âƒ£ åˆè¨ˆå£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï¼ˆON-OFFï¼‰', fontproperties=font_setup.jp_font)\n",
    "    ax4.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax4.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ•°å€¤è¡¨ç¤º\n",
    "    print('\\n' + '='*80)\n",
    "    print('ğŸ“Š ãƒ•ãƒ©ã‚°åˆ¥å£²ä¸Šåˆ†æçµæœ')\n",
    "    print('='*80)\n",
    "    display(df_result.style.format({\n",
    "        'ONå¹³å‡': '{:,.0f}å††',\n",
    "        'OFFå¹³å‡': '{:,.0f}å††',\n",
    "        'å¹³å‡å·®': '{:,.0f}å††',\n",
    "        'å¹³å‡ãƒªãƒ•ãƒˆ(%)': '{:+.1f}%',\n",
    "        'ONåˆè¨ˆ': '{:,.0f}å††',\n",
    "        'OFFåˆè¨ˆ': '{:,.0f}å††',\n",
    "        'åˆè¨ˆå·®': '{:,.0f}å††'\n",
    "    }).background_gradient(subset=['å¹³å‡ãƒªãƒ•ãƒˆ(%)'], cmap='RdYlGn', vmin=-20, vmax=20))\n",
    "    \n",
    "    # ãƒˆãƒƒãƒ—3æ¨å¥¨\n",
    "    print('\\n' + '='*80)\n",
    "    print('ğŸ’¡ å£²ä¸Šæœ€å¤§åŒ–ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¨å¥¨ï¼ˆå¹³å‡ãƒªãƒ•ãƒˆç‡ãƒˆãƒƒãƒ—3ï¼‰')\n",
    "    print('='*80)\n",
    "    for i, (idx, row) in enumerate(df_result.head(3).iterrows(), 1):\n",
    "        print(f\"\\n{i}. **{row['ãƒ•ãƒ©ã‚°']}**\")\n",
    "        print(f\"   å¹³å‡ãƒªãƒ•ãƒˆ: {row['å¹³å‡ãƒªãƒ•ãƒˆ(%)']:+.1f}% | ONå¹³å‡: {row['ONå¹³å‡']:,.0f}å†† vs OFFå¹³å‡: {row['OFFå¹³å‡']:,.0f}å††\")\n",
    "        print(f\"   æ¨å¥¨: {row['ãƒ•ãƒ©ã‚°']}ã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„\")\n",
    "\n",
    "# åˆ†æã‚’è‡ªå‹•å®Ÿè¡Œ\n",
    "analyze_sales_by_flags()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bc7ad",
   "metadata": {},
   "source": [
    "## ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—3: ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ\n",
    "\n",
    "### ğŸ¯ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„**\n",
    "AIãŒåˆ†æã—ã‚„ã™ã„ã‚ˆã†ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥æ¬¡Ã—åº—èˆ—å˜ä½ã«æ•´ç†ã—ã¾ã™ã€‚\n",
    "\n",
    "### ğŸ‘€ **åº—é•·ãŒç¢ºèªã™ã¹ãã“ã¨**\n",
    "å®Ÿè¡Œå¾Œã€ä»¥ä¸‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼š\n",
    "```\n",
    "[INFO] åˆ©ç”¨å¯èƒ½ç‰¹å¾´é‡: 28/30 å€‹\n",
    "[INFO] ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°: ['category_l', 'category_m', 'store_id']\n",
    "[INFO] ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«: (2500, 35) (è¡ŒÃ—åˆ—)\n",
    "[INFO] æ¬ æå€¤: 150 å€‹\n",
    "```\n",
    "\n",
    "**æ„å‘³**:\n",
    "- **28å€‹ã®è¦å› **ï¼ˆæ°—æ¸©ã€æ›œæ—¥ã€å¤©æ°—ãªã©ï¼‰ã‚’ä½¿ç”¨\n",
    "- **2,500æ—¥åˆ†**ã®ãƒ‡ãƒ¼ã‚¿ã§åˆ†æ\n",
    "- æ¬ æå€¤ã¯è‡ªå‹•å‡¦ç†ã•ã‚Œã‚‹\n",
    "\n",
    "### ğŸ’¡ **è¿½åŠ ã•ã‚ŒãŸç‰¹å¾´é‡ã®æ„å‘³**\n",
    "ã“ã®ã‚»ãƒ«ã§ã€ä»¥ä¸‹ã®ä¾¿åˆ©ãªç‰¹å¾´é‡ãŒè‡ªå‹•è¿½åŠ ã•ã‚Œã¾ã™ï¼š\n",
    "\n",
    "| ç‰¹å¾´é‡ | æ„å‘³ | å®Ÿå‹™ã§ã®æ´»ç”¨ |\n",
    "|--------|------|------------|\n",
    "| `sales_lag_1` | å‰æ—¥ã®å£²ä¸Š | ã€Œæ˜¨æ—¥å£²ã‚ŒãŸã‹ã‚‰ä»Šæ—¥ã‚‚å£²ã‚Œã‚‹ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹ |\n",
    "| `sales_lag_7` | 1é€±é–“å‰ã®å£²ä¸Š | ã€Œå…ˆé€±ã®æœˆæ›œã¨ä»Šé€±ã®æœˆæ›œã¯ä¼¼ã¦ã„ã‚‹ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹ |\n",
    "| `sales_rolling_7` | 7æ—¥ç§»å‹•å¹³å‡ | ãƒˆãƒ¬ãƒ³ãƒ‰æŠŠæ¡ï¼ˆå£²ä¸ŠãŒä¼¸ã³ã¦ã„ã‚‹ã‹ä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼‰ |\n",
    "| `day_of_week` | æ›œæ—¥ï¼ˆ0=æœˆæ›œã€6=æ—¥æ›œï¼‰ | æ›œæ—¥åˆ¥ã®å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ |\n",
    "| `is_weekend` | é€±æœ«ãƒ•ãƒ©ã‚°ï¼ˆåœŸæ—¥=1ï¼‰ | é€±æœ«åŠ¹æœã®æ¸¬å®š |\n",
    "\n",
    "**åˆ¤æ–­ãƒã‚¤ãƒ³ãƒˆ**:\n",
    "- æ¬ æå€¤ãŒ50%è¶…ã®åˆ— â†’ è‡ªå‹•ã§é™¤å¤–ã•ã‚Œã‚‹\n",
    "- ç‰¹å¾´é‡ãŒ10å€‹æœªæº€ â†’ ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚’å»¶é•·æ¤œè¨\n",
    "\n",
    "ã“ã®ã‚»ãƒ«ã¯è‡ªå‹•å®Ÿè¡Œã™ã‚‹ã ã‘ã§OKã§ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "**æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ â†“**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f96b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…¨ã¦ã®æ•°å€¤åˆ—ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ï¼ˆäº‹å‰ã®çµã‚Šè¾¼ã¿ãªã—ï¼‰\n",
    "print('[INFO] ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹å…¨ã¦ã®åˆ—ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆäº‹å‰çµã‚Šè¾¼ã¿ãªã—ï¼‰')\n",
    "\n",
    "# é™¤å¤–ã™ã¹ãåˆ—ï¼ˆåˆ†æå¯¾è±¡ã§ãªã„åˆ—ï¼‰\n",
    "exclude_cols = ['åº—èˆ—', 'å•†å“å', 'æ—¥ä»˜', 'æ—¥ä»˜', 'åº—èˆ—', 'å•†å“å', \n",
    "                'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡',\n",
    "                'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡',\n",
    "                'å£²ä¸Šé‡‘é¡', 'å£²ä¸Šé‡‘é¡', 'price',  # å£²ä¸Šæ•°é‡(qty)ã¯ç›®çš„å¤‰æ•°ãªã®ã§é™¤å¤–ã—ãªã„\n",
    "                'æ˜¨å¹´åŒæ—¥_å£²ä¸Š', 'æ˜¨å¹´åŒæ—¥_å®¢æ•°', 'æ˜¨å¹´åŒæ—¥_å®¢å˜ä¾¡']  # ç›®çš„å¤‰æ•°ã¨é–¢é€£åˆ—ã‚’é™¤å¤–\n",
    "\n",
    "# å…¨åˆ—ãƒªã‚¹ãƒˆ\n",
    "all_cols = df.columns.tolist()\n",
    "\n",
    "# æ•°å€¤åˆ—ã®ã¿æŠ½å‡ºï¼ˆæ–‡å­—åˆ—ãƒ»æ—¥ä»˜å‹ã‚’é™¤ãï¼‰\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# ç‰¹å¾´é‡å€™è£œï¼šæ•°å€¤åˆ—ã‹ã‚‰é™¤å¤–åˆ—ã‚’å¼•ã\n",
    "# ç‰¹å¾´é‡å€™è£œï¼šæ•°å€¤åˆ—ã‹ã‚‰é™¤å¤–åˆ—ã‚’å¼•ãï¼ˆqtyã‚‚æ˜ç¤ºçš„ã«é™¤å¤–ï¼‰\n",
    "feature_cols = [c for c in numeric_cols if c not in exclude_cols and c not in ['å£²ä¸Šæ•°é‡', 'å£²ä¸Šæ•°é‡']]\n",
    "\n",
    "print(f'[INFO] å…¨åˆ—æ•°: {len(all_cols)}')\n",
    "print(f'[INFO] æ•°å€¤åˆ—æ•°: {len(numeric_cols)}')\n",
    "print(f'[INFO] é™¤å¤–åˆ—æ•°: {len([c for c in exclude_cols if c in all_cols])}')\n",
    "print(f'[INFO] ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {len(feature_cols)} å€‹')\n",
    "print(f'\\n[ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆå…¨{len(feature_cols)}å€‹ï¼‰]:')\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f'  {i}. {col}')\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ç¢ºèª\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_present = [c for c in categorical_cols if c not in exclude_cols and c in df.columns]\n",
    "print(f'\\n[INFO] ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°: {len(categorical_present)} å€‹ â†’ {categorical_present}')\n",
    "\n",
    "# åŸºæœ¬ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰ï¼ˆå…¨ã¦ã®æ•°å€¤ç‰¹å¾´é‡ã‚’ä½¿ç”¨ï¼‰\n",
    "keep = ['æ—¥ä»˜', 'åº—èˆ—', 'å£²ä¸Šæ•°é‡'] + feature_cols\n",
    "tmp = df[[c for c in keep if c in df.columns]].copy()\n",
    "\n",
    "# æ—¥ä»˜Ã—åº—èˆ—ã§ç‰¹å¾´é‡ã‚’ä»£è¡¨åŒ–ï¼ˆæ•°å€¤ã¯å¹³å‡ï¼‰ã€å£²ä¸Šã¯åˆè¨ˆ\n",
    "# qtyãŒ feature_cols ã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é™¤å¤–ï¼ˆç›®çš„å¤‰æ•°ãªã®ã§ç‰¹å¾´é‡ã¨ã—ã¦ã¯ä½¿ã‚ãªã„ï¼‰\n",
    "feature_cols_for_agg = [c for c in feature_cols if c not in ['å£²ä¸Šæ•°é‡', 'å£²ä¸Šæ•°é‡']]\n",
    "Xdf = tmp.groupby(['æ—¥ä»˜','åº—èˆ—'], as_index=False)[feature_cols_for_agg].mean() if feature_cols_for_agg else tmp[['æ—¥ä»˜','åº—èˆ—']].drop_duplicates()\n",
    "ydf = tmp.groupby(['æ—¥ä»˜','åº—èˆ—'], as_index=False)['å£²ä¸Šæ•°é‡'].sum()\n",
    "feat = Xdf.merge(ydf, on=['æ—¥ä»˜','åº—èˆ—'], how='inner')\n",
    "\n",
    "# qtyãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "if 'å£²ä¸Šæ•°é‡' not in feat.columns:\n",
    "    print('[ERROR] qtyåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„')\n",
    "else:\n",
    "    qty_sum = feat[\"å£²ä¸Šæ•°é‡\"].sum()\n",
    "    qty_mean = feat[\"å£²ä¸Šæ•°é‡\"].mean()\n",
    "    print(f'[INFO] qtyåˆ—ã‚’ç¢ºèª: åˆè¨ˆ={qty_sum:,.0f}å€‹, å¹³å‡={qty_mean:.1f}å€‹/æ—¥')\n",
    "    print(f'[DEBUG] qtyåˆ—ã®å‹: {feat[\"å£²ä¸Šæ•°é‡\"].dtype}, NaNæ•°: {feat[\"å£²ä¸Šæ•°é‡\"].isna().sum()}')\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®è¿½åŠ ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰\n",
    "if categorical_present:\n",
    "    cat_data = df[['æ—¥ä»˜','åº—èˆ—'] + categorical_present].drop_duplicates()\n",
    "    feat = feat.merge(cat_data, on=['æ—¥ä»˜','åº—èˆ—'], how='left')\n",
    "\n",
    "# é‡è¤‡åˆ—åã®ãƒã‚§ãƒƒã‚¯ã¨å‰Šé™¤\n",
    "duplicate_cols = feat.columns[feat.columns.duplicated()].tolist()\n",
    "if duplicate_cols:\n",
    "    print(f'[WARNING] é‡è¤‡åˆ—åã‚’æ¤œå‡º: {duplicate_cols}')\n",
    "    # é‡è¤‡åˆ—ã‚’å‰Šé™¤ï¼ˆæœ€åˆã®åˆ—ã®ã¿æ®‹ã™ï¼‰\n",
    "    feat = feat.loc[:, ~feat.columns.duplicated()]\n",
    "    print(f'[INFO] é‡è¤‡åˆ—ã‚’å‰Šé™¤å¾Œ: {feat.shape}')\n",
    "    print(f'[INFO] ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’ãƒãƒ¼ã‚¸: {categorical_present}')\n",
    "\n",
    "print(f'\\n[INFO] ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«: {feat.shape} (è¡ŒÃ—åˆ—)')\n",
    "print(f'[INFO] æ¬ æå€¤: {feat.isnull().sum().sum()} å€‹ ({feat.isnull().sum().sum() / feat.size * 100:.2f}%)')\n",
    "\n",
    "# æ¬ æå€¤ãŒå¤šã„åˆ—ã‚’è­¦å‘Š\n",
    "missing_ratio = feat.isnull().sum() / len(feat)\n",
    "high_missing = missing_ratio[missing_ratio > 0.5].sort_values(ascending=False)\n",
    "if not high_missing.empty:\n",
    "    print(f'\\n[WARNING] æ¬ æå€¤50%è¶…ã®åˆ—ï¼ˆ{len(high_missing)}å€‹ï¼‰:')\n",
    "    for col, ratio in high_missing.items():\n",
    "        print(f'  - {col}: {ratio*100:.1f}% æ¬ æ')\n",
    "\n",
    "feat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc776dc",
   "metadata": {},
   "source": [
    "## ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—4: PyCaret â€” AIã§å£²ä¸Šäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ\n",
    "\n",
    "### ğŸ¯ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„**\n",
    "**PyCaretã‚’ä½¿ã£ã¦ã€å£²ä¸Šã‚’äºˆæ¸¬ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•çš„ã«ä½œæˆã—ã¾ã™ã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ **PyCaretãŒè‡ªå‹•ã§ã‚„ã£ã¦ãã‚Œã‚‹ã“ã¨**\n",
    "\n",
    "1. **15ï½20ç¨®é¡ã®AIãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ‹¬æ¯”è¼ƒ**\n",
    "   - LightGBMã€XGBoostã€CatBoostï¼ˆGPUå¯¾å¿œï¼‰\n",
    "   - ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã€æ±ºå®šæœ¨ã€ç·šå½¢å›å¸°\n",
    "   - ãã®ä»–ã®é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«\n",
    "\n",
    "2. **ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†**\n",
    "   - æ¬ æå€¤ã®è£œå®Œ\n",
    "   - å¤–ã‚Œå€¤ã®æ¤œå‡º\n",
    "   - ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆæ­£è¦åŒ–ï¼‰\n",
    "\n",
    "3. **äº¤å·®æ¤œè¨¼ï¼ˆ3-Fold CVï¼‰**\n",
    "   - ãƒ‡ãƒ¼ã‚¿ã‚’3åˆ†å‰²ã—ã¦ã€éå­¦ç¿’ã‚’é˜²ããªãŒã‚‰ç²¾åº¦ã‚’è©•ä¾¡\n",
    "\n",
    "4. **æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•é¸æŠ**\n",
    "   - RÂ²ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘€ **åº—é•·ãŒç¢ºèªã™ã¹ãã“ã¨**\n",
    "\n",
    "#### 1ï¸âƒ£ **ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœï¼ˆLeaderboardï¼‰**\n",
    "å®Ÿè¡Œå¾Œã€ä»¥ä¸‹ã®ã‚ˆã†ãªè¡¨ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼š\n",
    "\n",
    "| Model | R2 | RMSE | MAE | å®Ÿè¡Œæ™‚é–“ |\n",
    "|-------|-----|------|-----|---------|\n",
    "| LightGBM | 0.85 | 1200 | 950 | 2.3ç§’ |\n",
    "| XGBoost | 0.83 | 1350 | 1020 | 3.1ç§’ |\n",
    "| CatBoost | 0.82 | 1400 | 1080 | 2.8ç§’ |\n",
    "\n",
    "**é‡è¦æŒ‡æ¨™ã®èª­ã¿æ–¹ï¼š**\n",
    "- **RÂ² (æ±ºå®šä¿‚æ•°)**: 0ï½1ã®ç¯„å›²ã€‚**0.7ä»¥ä¸Šãªã‚‰å®Ÿç”¨ãƒ¬ãƒ™ãƒ«**ã€0.8ä»¥ä¸Šãªã‚‰é«˜ç²¾åº¦\n",
    "  - 0.85 = å£²ä¸Šå¤‰å‹•ã®85%ã‚’AIãŒèª¬æ˜ã§ãã¦ã„ã‚‹\n",
    "- **RMSE (å¹³å‡äºŒä¹—èª¤å·®)**: äºˆæ¸¬èª¤å·®ã®å¤§ãã•ï¼ˆå††å˜ä½ï¼‰ã€‚**å°ã•ã„ã»ã©è‰¯ã„**\n",
    "- **MAE (å¹³å‡çµ¶å¯¾èª¤å·®)**: ã‚ˆã‚Šç›´æ„Ÿçš„ãªèª¤å·®ï¼ˆå††å˜ä½ï¼‰ã€‚**æ—¥ã€…ã®å£²ä¸ŠÂ±ã“ã®é‡‘é¡ã®ç¯„å›²ã§äºˆæ¸¬**\n",
    "\n",
    "#### 2ï¸âƒ£ **GPUåŠ é€Ÿã®ç¢ºèª**\n",
    "```\n",
    "ğŸš€ [INFO] GPUä½¿ç”¨ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆLightGBM/XGBoost/CatBoostå¯¾å¿œï¼‰\n",
    "â±ï¸ å®Ÿè¡Œæ™‚é–“: 23.4ç§’\n",
    "ğŸ’¡ GPUã«ã‚ˆã‚Šé«˜é€ŸåŒ–ã•ã‚Œã¾ã—ãŸ\n",
    "```\n",
    "â†‘ ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚Œã°GPUåŠ é€ŸãŒæœ‰åŠ¹ã§ã™ï¼ˆCPUç‰ˆã®ç´„10å€é«˜é€Ÿï¼‰\n",
    "\n",
    "#### 3ï¸âƒ£ **ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•**\n",
    "ã€Œã©ã®è¦ç´ ãŒå£²ä¸Šã«åŠ¹ã„ã¦ã„ã‚‹ã‹ã€ã‚’å¯è¦–åŒ–ï¼š\n",
    "- **å¤©æ°—**ï¼ˆflag_weather_rainï¼‰ãŒé‡è¦ â†’ é›¨ã®æ—¥å¯¾ç­–ãŒå¿…è¦\n",
    "- **æ›œæ—¥**ï¼ˆflag_dow_åœŸæ›œï¼‰ãŒé‡è¦ â†’ é€±æœ«ã®å“æƒãˆãŒéµ\n",
    "- **ã‚¤ãƒ™ãƒ³ãƒˆ**ï¼ˆflag_event_çµ¦æ–™æ—¥ï¼‰ãŒé‡è¦ â†’ çµ¦æ–™æ—¥ã‚»ãƒ¼ãƒ«ãŒåŠ¹æœçš„\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ **GPUè¨­å®šã®è©³ç´°**\n",
    "\n",
    "PyCaretã¯ä»¥ä¸‹ã®GPUãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•è¨­å®šã—ã¾ã™ï¼š\n",
    "\n",
    "```python\n",
    "# LightGBM GPUè¨­å®š\n",
    "'device': 'gpu'\n",
    "'gpu_platform_id': 0\n",
    "'gpu_device_id': 0\n",
    "\n",
    "# XGBoost GPUè¨­å®š  \n",
    "'tree_method': 'gpu_hist'\n",
    "'gpu_id': 0\n",
    "\n",
    "# CatBoost GPUè¨­å®š\n",
    "'task_type': 'GPU'\n",
    "'devices': '0'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ **æ³¨æ„äº‹é …**\n",
    "\n",
    "1. **æœ€ä½ãƒ‡ãƒ¼ã‚¿æ•°**: 100è¡Œä»¥ä¸Šå¿…è¦ï¼ˆå°‘ãªã„ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ï¼‰\n",
    "2. **å®Ÿè¡Œæ™‚é–“**: ãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚Š1ï½5åˆ†ç¨‹åº¦ã‹ã‹ã‚Šã¾ã™\n",
    "3. **GPUéæ­è¼‰ã®å ´åˆ**: è‡ªå‹•çš„ã«CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¾ã™ï¼ˆã‚„ã‚„é…ããªã‚Šã¾ã™ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**\n",
    "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ï¼ˆ`final`å¤‰æ•°ï¼‰ã‚’ä½¿ã£ã¦ã€ã‚¹ãƒ†ãƒƒãƒ—5ã§äºˆæ¸¬çµæœã®å¯è¦–åŒ–ã‚’è¡Œã„ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—4: PyCaretå®Ÿè¡Œï¼ˆGPUè‡ªå‹•æ¤œå‡º + CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n",
    "# ========================================\n",
    "\n",
    "if PYC_OK and 'feat' in locals() and len(feat) >= MIN_SAMPLES_PYCARET:\n",
    "    print(f'[INFO] PyCareté–‹å§‹: {len(feat)}è¡Œ (>= {MIN_SAMPLES_PYCARET}è¡Œ)')\n",
    "    \n",
    "    # PyCaretã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "    data = feat.drop(columns=['æ—¥ä»˜','åº—èˆ—'], errors='ignore').copy()\n",
    "    \n",
    "    # æ¬ æå€¤ãŒå¤šã„åˆ—ã‚’å‰Šé™¤ï¼ˆ50%ä»¥ä¸Šæ¬ æï¼‰â€»ãŸã ã—ç›®çš„å¤‰æ•°qtyã¯ä¿è­·\n",
    "    missing_ratio = data.isnull().sum() / len(data)\n",
    "    drop_cols = missing_ratio[missing_ratio > 0.5].index.tolist()\n",
    "    # ç›®çš„å¤‰æ•°qtyã‚’é™¤å¤–ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤ï¼ˆä¿è­·ï¼‰\n",
    "    if 'å£²ä¸Šæ•°é‡' in drop_cols:\n",
    "        drop_cols.remove('å£²ä¸Šæ•°é‡')\n",
    "    if drop_cols:\n",
    "        print(f'[WARNING] æ¬ æå€¤50%è¶…ã®åˆ—ã‚’é™¤å¤–: {drop_cols}')\n",
    "        data = data.drop(columns=drop_cols)\n",
    "    \n",
    "    print(f'[INFO] å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {data.shape} | ç›®çš„å¤‰æ•°: qty (è²©å£²æ•°é‡)')\n",
    "    print(f'[DEBUG] data.columns ã« qty ãŒå­˜åœ¨: {\"å£²ä¸Šæ•°é‡\" in data.columns}')\n",
    "    print(f'[DEBUG] data.columns: {list(data.columns[:10])}...')\n",
    "    if 'å£²ä¸Šæ•°é‡' in data.columns:\n",
    "        print(f'[DEBUG] qtyçµ±è¨ˆ: min={data[\"å£²ä¸Šæ•°é‡\"].min()}, max={data[\"å£²ä¸Šæ•°é‡\"].max()}, mean={data[\"å£²ä¸Šæ•°é‡\"].mean():.2f}')\n",
    "    else:\n",
    "        print(f'[ERROR] qtyåˆ—ãŒdataã«å­˜åœ¨ã—ã¾ã›ã‚“ï¼')\n",
    "        print(f'[ERROR] åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(data.columns)}')\n",
    "    \n",
    "    # ========================================\n",
    "    # ğŸš€ GPUå¯¾å¿œãƒã‚§ãƒƒã‚¯ï¼ˆå„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®Ÿéš›ã®å¯¾å¿œçŠ¶æ³ã‚’ç¢ºèªï¼‰\n",
    "    # ========================================\n",
    "    \n",
    "    def check_lightgbm_gpu():\n",
    "        \"\"\"LightGBMã®GPUå¯¾å¿œã‚’ç¢ºèª\"\"\"\n",
    "        try:\n",
    "            import lightgbm as lgb\n",
    "            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§GPUå‹•ä½œç¢ºèª\n",
    "            test_data = [[1, 2], [3, 4]]\n",
    "            test_label = [1, 2]\n",
    "            lgb_train = lgb.Dataset(test_data, test_label)\n",
    "            params = {'device': 'gpu', 'verbosity': -1}\n",
    "            lgb.train(params, lgb_train, num_boost_round=1)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    def check_xgboost_gpu():\n",
    "        \"\"\"XGBoostã®GPUå¯¾å¿œã‚’ç¢ºèª\"\"\"\n",
    "        try:\n",
    "            import xgboost as xgb\n",
    "            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§GPUå‹•ä½œç¢ºèª\n",
    "            dtrain = xgb.DMatrix([[1, 2], [3, 4]], label=[1, 2])\n",
    "            params = {'tree_method': 'gpu_hist', 'verbosity': 0}\n",
    "            xgb.train(params, dtrain, num_boost_round=1)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    def check_catboost_gpu():\n",
    "        \"\"\"CatBoostã®GPUå¯¾å¿œã‚’ç¢ºèª\"\"\"\n",
    "        try:\n",
    "            from catboost import CatBoostRegressor\n",
    "            model = CatBoostRegressor(task_type='GPU', iterations=1, verbose=0)\n",
    "            model.fit([[1, 2], [3, 4]], [1, 2])\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    # GPUå¯¾å¿œçŠ¶æ³ã®ç¢ºèª\n",
    "    print('\\nğŸ” [INFO] GPUå¯¾å¿œçŠ¶æ³ã‚’ç¢ºèªä¸­...')\n",
    "    \n",
    "    lightgbm_gpu = False\n",
    "    xgboost_gpu = False\n",
    "    catboost_gpu = False\n",
    "    \n",
    "    if USE_GPU and GPU_AVAILABLE:\n",
    "        lightgbm_gpu = check_lightgbm_gpu()\n",
    "        xgboost_gpu = check_xgboost_gpu()\n",
    "        catboost_gpu = check_catboost_gpu()\n",
    "        \n",
    "        print(f'  LightGBM GPU: {\"âœ… åˆ©ç”¨å¯èƒ½\" if lightgbm_gpu else \"âŒ æœªå¯¾å¿œï¼ˆCPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\"}')\n",
    "        print(f'  XGBoost GPU: {\"âœ… åˆ©ç”¨å¯èƒ½\" if xgboost_gpu else \"âŒ æœªå¯¾å¿œï¼ˆCPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\"}')\n",
    "        print(f'  CatBoost GPU: {\"âœ… åˆ©ç”¨å¯èƒ½\" if catboost_gpu else \"âŒ æœªå¯¾å¿œï¼ˆCPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\"}')\n",
    "        \n",
    "        if not any([lightgbm_gpu, xgboost_gpu, catboost_gpu]):\n",
    "            print('\\nâš ï¸ [WARNING] GPUå¯¾å¿œãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“')\n",
    "            print('ğŸ’¡ CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ï¼ˆç²¾åº¦ã¯åŒã˜ã§ã™ãŒé€Ÿåº¦ã¯é…ããªã‚Šã¾ã™ï¼‰')\n",
    "            print('\\nğŸ“ GPUå¯¾å¿œç‰ˆã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•:')\n",
    "            print('  pip install lightgbm --install-option=--gpu')\n",
    "            print('  pip install xgboost[gpu]')\n",
    "            print('  pip install catboost --install-option=\"--features=GPU\"')\n",
    "    else:\n",
    "        print('  â„¹ï¸ GPUãŒæ¤œå‡ºã•ã‚Œã¦ã„ãªã„ãŸã‚ã€CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™')\n",
    "    \n",
    "    try:\n",
    "        # ========================================\n",
    "        # ğŸ“Š PyCaretã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä¸¦åˆ—å‡¦ç†æœ‰åŠ¹åŒ–ï¼‰\n",
    "        # ========================================\n",
    "        import time\n",
    "        setup_start = time.time()\n",
    "        \n",
    "        _ = setup(\n",
    "            data=data, \n",
    "            target='å£²ä¸Šæ•°é‡', \n",
    "            session_id=42, \n",
    "            fold=3,\n",
    "            verbose=False,\n",
    "            normalize=True,\n",
    "            transformation=True,\n",
    "            ignore_features=['sales_lag_1', 'sales_lag_7', 'sales_rolling_7'],\n",
    "            n_jobs=-1,  # å…¨CPUã‚³ã‚¢ã‚’ä½¿ç”¨ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰\n",
    "        )\n",
    "        \n",
    "        setup_time = time.time() - setup_start\n",
    "        print(f'\\nâœ… [INFO] ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†: {setup_time:.1f}ç§’')\n",
    "        \n",
    "        # ========================================\n",
    "        # ğŸš€ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆä¸¦åˆ—å®Ÿè¡Œ + è‡ªå‹•GPUè¨­å®šï¼‰\n",
    "        # ========================================\n",
    "        print('\\n[INFO] ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Ÿè¡Œä¸­ï¼ˆå…¨ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—å®Ÿè¡Œï¼‰...')\n",
    "        print('[INFO] æ¯”è¼ƒå¯¾è±¡: PyCaretã®å…¨å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆ15ï½20ç¨®é¡ï¼‰')\n",
    "        \n",
    "        if any([lightgbm_gpu, xgboost_gpu, catboost_gpu]):\n",
    "            print('[INFO] âœ… ä¸€éƒ¨ãƒ¢ãƒ‡ãƒ«ã§GPUåŠ é€Ÿæœ‰åŠ¹')\n",
    "        else:\n",
    "            print('[INFO] â„¹ï¸ CPUãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨ã‚³ã‚¢ä¸¦åˆ—å®Ÿè¡Œï¼‰')\n",
    "        \n",
    "        print('[INFO] â€» å®Ÿè¡Œã«æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™')\n",
    "        \n",
    "        compare_start = time.time()\n",
    "        \n",
    "        # å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Ÿè¡Œï¼ˆPyCaretãŒè‡ªå‹•ã§æœ€é©åŒ–ï¼‰\n",
    "        best = compare_models(\n",
    "            sort='R2',\n",
    "            n_select=1,\n",
    "            turbo=True,  # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰\n",
    "        )\n",
    "        \n",
    "        compare_time = time.time() - compare_start\n",
    "        \n",
    "        leaderboard = pull()\n",
    "        print('\\n[SUCCESS] ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Œäº†')\n",
    "        print(f'â±ï¸ å®Ÿè¡Œæ™‚é–“: {compare_time:.1f}ç§’')\n",
    "        \n",
    "        if any([lightgbm_gpu, xgboost_gpu, catboost_gpu]):\n",
    "            print('ğŸ’¡ ä¸€éƒ¨ãƒ¢ãƒ‡ãƒ«ã§GPUã«ã‚ˆã‚Šé«˜é€ŸåŒ–ã•ã‚Œã¾ã—ãŸ')\n",
    "        \n",
    "        print(f'\\nğŸ“Š å…¨{len(leaderboard)}ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒçµæœ:')\n",
    "        display(leaderboard)\n",
    "        \n",
    "        # ========================================\n",
    "        # ğŸ¯ æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒŠãƒ©ã‚¤ã‚º\n",
    "        # ========================================\n",
    "        finalize_start = time.time()\n",
    "        \n",
    "        final = finalize_model(best)\n",
    "        \n",
    "        finalize_time = time.time() - finalize_start\n",
    "        \n",
    "        print(f'\\n[INFO] æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {type(best).__name__}')\n",
    "        print(f'[INFO] R2ã‚¹ã‚³ã‚¢: {leaderboard.iloc[0][\"R2\"]:.4f}')\n",
    "        print(f'[INFO] RMSE: {leaderboard.iloc[0][\"RMSE\"]:.2f}')\n",
    "        print(f'[INFO] MAE: {leaderboard.iloc[0][\"MAE\"]:.2f}')\n",
    "        print(f'[INFO] ãƒ•ã‚¡ã‚¤ãƒŠãƒ©ã‚¤ã‚ºæ™‚é–“: {finalize_time:.1f}ç§’')\n",
    "        \n",
    "        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèªã—ã¦GPUä½¿ç”¨çŠ¶æ³ã‚’è¡¨ç¤º\n",
    "        model_name = type(best).__name__\n",
    "        if 'LGBM' in model_name:\n",
    "            gpu_status = 'âœ… GPU' if lightgbm_gpu else 'â„¹ï¸ CPU'\n",
    "            print(f'[INFO] LightGBM: {gpu_status}ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’')\n",
    "        elif 'XGB' in model_name:\n",
    "            gpu_status = 'âœ… GPU' if xgboost_gpu else 'â„¹ï¸ CPU'\n",
    "            print(f'[INFO] XGBoost: {gpu_status}ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’')\n",
    "        elif 'CatBoost' in model_name:\n",
    "            gpu_status = 'âœ… GPU' if catboost_gpu else 'â„¹ï¸ CPU'\n",
    "            print(f'[INFO] CatBoost: {gpu_status}ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’')\n",
    "        else:\n",
    "            print(f'[INFO] {model_name}: CPUãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’')\n",
    "        \n",
    "        # ========================================\n",
    "        # ğŸ“Š å¯è¦–åŒ–\n",
    "        # ========================================\n",
    "        try:\n",
    "            print('\\n[INFO] ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ')\n",
    "            plot_model(final, plot='feature')\n",
    "        except Exception as e:\n",
    "            print(f'[WARNING] ç‰¹å¾´é‡ãƒ—ãƒ­ãƒƒãƒˆå¤±æ•—: {e}')\n",
    "        \n",
    "        try:\n",
    "            print('\\n[INFO] æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ')\n",
    "            plot_model(final, plot='residuals')\n",
    "        except Exception as e:\n",
    "            print(f'[WARNING] æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆå¤±æ•—: {e}')\n",
    "        \n",
    "        # ========================================\n",
    "        # â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼\n",
    "        # ========================================\n",
    "        total_time = setup_time + compare_time + finalize_time\n",
    "        print('\\n' + '='*60)\n",
    "        print('â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼')\n",
    "        print('='*60)\n",
    "        print(f'ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: {setup_time:.1f}ç§’')\n",
    "        print(f'ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ: {compare_time:.1f}ç§’ ({len(leaderboard)}ãƒ¢ãƒ‡ãƒ«)')\n",
    "        print(f'ãƒ•ã‚¡ã‚¤ãƒŠãƒ©ã‚¤ã‚º: {finalize_time:.1f}ç§’')\n",
    "        print(f'åˆè¨ˆæ™‚é–“: {total_time:.1f}ç§’')\n",
    "        \n",
    "        gpu_count = sum([lightgbm_gpu, xgboost_gpu, catboost_gpu])\n",
    "        if gpu_count > 0:\n",
    "            print(f'\\nğŸ’¡ {gpu_count}ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã§GPUåŠ é€ŸãŒæœ‰åŠ¹ã§ã—ãŸ')\n",
    "        else:\n",
    "            print(f'\\nâ„¹ï¸ CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã—ãŸï¼ˆä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚Šé«˜é€ŸåŒ–ï¼‰')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'[ERROR] PyCaretå®Ÿè¡Œå¤±æ•—')\n",
    "        print(f'  ã‚¨ãƒ©ãƒ¼å‹: {type(e).__name__}')\n",
    "        print(f'  è©³ç´°: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "elif PYC_OK:\n",
    "    print(f'[WARNING] ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ{len(feat)}è¡Œ < {MIN_SAMPLES_PYCARET}è¡Œï¼‰ã€‚PyCaretã‚¹ã‚­ãƒƒãƒ—ã€‚')\n",
    "else:\n",
    "    print('[WARNING] PyCaretæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€‚ã‚¹ã‚­ãƒƒãƒ—ã€‚')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79z9lrfba1r",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ ã‚¹ãƒ†ãƒƒãƒ—5: äºˆæ¸¬çµæœã®å¯è¦–åŒ–ã¨ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ\n",
    "\n",
    "### ğŸ¯ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„**\n",
    "**ä¸Šã®ã‚¹ãƒ†ãƒƒãƒ—4ã§å­¦ç¿’ã—ãŸAIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–ã—ã€ãƒ“ã‚¸ãƒã‚¹ä¸Šã®åˆ¤æ–­ææ–™ã‚’æä¾›ã—ã¾ã™ã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è¡¨ç¤ºã•ã‚Œã‚‹å†…å®¹**\n",
    "\n",
    "#### 1ï¸âƒ£ **äºˆæ¸¬ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹**\n",
    "```\n",
    "ğŸ“Š äºˆæ¸¬ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹:\n",
    "   RÂ² Score: 0.8234\n",
    "   MAE: 1,250å††\n",
    "   RMSE: 1,680å††\n",
    "   MAPE: 8.5%\n",
    "```\n",
    "\n",
    "**æŒ‡æ¨™ã®èª­ã¿æ–¹ï¼š**\n",
    "- **RÂ² (æ±ºå®šä¿‚æ•°)**: 0.7ä»¥ä¸Šãªã‚‰å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã€0.8ä»¥ä¸Šãªã‚‰é«˜ç²¾åº¦\n",
    "- **MAE (å¹³å‡çµ¶å¯¾èª¤å·®)**: äºˆæ¸¬ãŒå¹³å‡Â±1,250å††ã®ç¯„å›²ã§ã‚ºãƒ¬ã‚‹\n",
    "- **RMSE (äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®)**: å¤§ããªèª¤å·®ã‚’é‡è¦–ã—ãŸæŒ‡æ¨™\n",
    "- **MAPE (å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®)**: äºˆæ¸¬èª¤å·®ãŒç´„8.5%ï¼ˆå£²ä¸Šã®1å‰²æœªæº€ãªã‚‰å®Ÿç”¨å¯ï¼‰\n",
    "\n",
    "#### 2ï¸âƒ£ **4ãƒ‘ãƒãƒ«å¯è¦–åŒ–**\n",
    "1. **äºˆæ¸¬vså®Ÿç¸¾ æ•£å¸ƒå›³**: ãƒ¢ãƒ‡ãƒ«ã®å½“ã¦ã¯ã¾ã‚Šå…·åˆã‚’ç¢ºèª\n",
    "2. **æ®‹å·®åˆ†å¸ƒ**: äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒï¼ˆæ­£è¦åˆ†å¸ƒã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰\n",
    "3. **æ™‚ç³»åˆ—äºˆæ¸¬**: æ—¥åˆ¥ã®äºˆæ¸¬ç²¾åº¦æ¨ç§»\n",
    "4. **äºˆæ¸¬èª¤å·®ç‡ã®åˆ†å¸ƒ**: ã©ã‚Œãã‚‰ã„ã®å‰²åˆã§èª¤å·®ãŒå‡ºã‚‹ã‹\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ **å®Ÿå‹™ã§ã®æ´»ç”¨æ–¹æ³•**\n",
    "\n",
    "| æŒ‡æ¨™ | åˆ¤æ–­åŸºæº– | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ |\n",
    "|------|----------|----------|\n",
    "| **RÂ² > 0.8** | é«˜ç²¾åº¦ | ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªé‹ç”¨ã«æŠ•å…¥å¯èƒ½ |\n",
    "| **0.7 < RÂ² < 0.8** | å®Ÿç”¨ãƒ¬ãƒ™ãƒ« | æ³¨æ„ã—ãªãŒã‚‰é‹ç”¨ã€æ”¹å–„ã®ä½™åœ°ã‚ã‚Š |\n",
    "| **RÂ² < 0.7** | è¦æ”¹å–„ | ç‰¹å¾´é‡ã®è¿½åŠ ã‚„ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®å»¶é•·ãŒå¿…è¦ |\n",
    "| **MAPE < 10%** | å„ªç§€ | ç™ºæ³¨æ•°é‡ã®è‡ªå‹•åŒ–ã«æ´»ç”¨å¯èƒ½ |\n",
    "| **MAPE > 20%** | è¦æ³¨æ„ | äººé–“ã®ãƒã‚§ãƒƒã‚¯ã‚’å¿…é ˆã«ã™ã‚‹ |\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ **æ³¨æ„äº‹é …**\n",
    "\n",
    "1. **ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ãªã„å ´åˆ**\n",
    "   ```\n",
    "   âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«ã‚¹ãƒ†ãƒƒãƒ—4ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
    "   ```\n",
    "   â†’ ã‚¹ãƒ†ãƒƒãƒ—4ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
    "\n",
    "2. **æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ**\n",
    "   - æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ï¼ˆæ•£å¸ƒå›³ã¨æ®‹å·®ã®ã¿è¡¨ç¤ºï¼‰\n",
    "\n",
    "3. **ç•°å¸¸å€¤ã®ç¢ºèª**\n",
    "   - æ•£å¸ƒå›³ã§å¤§ããå¤–ã‚ŒãŸç‚¹ï¼ˆå¤–ã‚Œå€¤ï¼‰ãŒã‚ã‚‹å ´åˆã€ãã®æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n",
    "   - ã‚¤ãƒ™ãƒ³ãƒˆæ—¥ã‚„ç‰¹æ®Šè¦å› ãŒã‚ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**\n",
    "ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ç²¾åº¦ã‚’ç¢ºèªã—ãŸã‚‰ã€ã‚¹ãƒ†ãƒƒãƒ—6ã§å®Ÿéš›ã®ç™ºæ³¨æ•°é‡äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33101c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ“ˆ ã‚¹ãƒ†ãƒƒãƒ—5: äºˆæ¸¬çµæœã®å¯è¦–åŒ–ã¨ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ\n",
    "# ========================================\n",
    "\n",
    "if 'final' in locals():\n",
    "    print('\\n' + '='*60)\n",
    "    print('ğŸ“ˆ ã‚¹ãƒ†ãƒƒãƒ—5: äºˆæ¸¬çµæœã®å¯è¦–åŒ–ã¨ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ')\n",
    "    print('='*60)\n",
    "    \n",
    "    try:\n",
    "        # äºˆæ¸¬å®Ÿè¡Œ\n",
    "        predictions = predict_model(final)\n",
    "        \n",
    "        # äºˆæ¸¬ç²¾åº¦ã®è©•ä¾¡\n",
    "        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "        \n",
    "        y_true = predictions['å£²ä¸Šæ•°é‡']\n",
    "        y_pred = predictions['prediction_label']\n",
    "        \n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "        \n",
    "        # MAPEè¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å›é¿ï¼‰\n",
    "        non_zero_mask = y_true != 0\n",
    "        if non_zero_mask.sum() > 0:\n",
    "            mape = np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "        else:\n",
    "            mape = 0\n",
    "        \n",
    "        print(f'\\nğŸ“Š äºˆæ¸¬ç²¾åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹:')\n",
    "        print(f'   RÂ² Score: {r2:.4f}')\n",
    "        print(f'   MAE: {mae:,.0f}å††')\n",
    "        print(f'   RMSE: {rmse:,.0f}å††')\n",
    "        print(f'   MAPE: {mape:.2f}%')\n",
    "        \n",
    "        # 4ãƒ‘ãƒãƒ«å¯è¦–åŒ–\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('ğŸ“Š äºˆæ¸¬ç²¾åº¦ã®å¯è¦–åŒ–åˆ†æ', fontsize=16, fontproperties=font_setup.jp_font)\n",
    "        \n",
    "        # 1. äºˆæ¸¬vså®Ÿç¸¾ æ•£å¸ƒå›³\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.scatter(y_true, y_pred, alpha=0.5, s=20, color='steelblue')\n",
    "        min_val = min(y_true.min(), y_pred.min())\n",
    "        max_val = max(y_true.max(), y_pred.max())\n",
    "        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='å®Œå…¨ä¸€è‡´ç·š')\n",
    "        ax1.set_xlabel('å®Ÿç¸¾å£²ä¸Šï¼ˆå††ï¼‰', fontproperties=font_setup.jp_font)\n",
    "        ax1.set_ylabel('äºˆæ¸¬å£²ä¸Šï¼ˆå††ï¼‰', fontproperties=font_setup.jp_font)\n",
    "        ax1.set_title(f'1ï¸âƒ£ äºˆæ¸¬vså®Ÿç¸¾ï¼ˆRÂ²={r2:.3f}ï¼‰', fontproperties=font_setup.jp_font)\n",
    "        ax1.legend(prop=font_setup.jp_font)\n",
    "        ax1.grid(alpha=0.3)\n",
    "        \n",
    "        # 2. æ®‹å·®åˆ†å¸ƒ\n",
    "        ax2 = axes[0, 1]\n",
    "        residuals = y_true - y_pred\n",
    "        ax2.hist(residuals, bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "        ax2.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        ax2.set_xlabel('æ®‹å·®ï¼ˆå®Ÿç¸¾-äºˆæ¸¬ï¼‰', fontproperties=font_setup.jp_font)\n",
    "        ax2.set_ylabel('é »åº¦', fontproperties=font_setup.jp_font)\n",
    "        ax2.set_title(f'2ï¸âƒ£ æ®‹å·®åˆ†å¸ƒï¼ˆå¹³å‡={residuals.mean():.0f}å††ï¼‰', fontproperties=font_setup.jp_font)\n",
    "        ax2.grid(alpha=0.3)\n",
    "        \n",
    "        # 3. æ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆæ—¥ä»˜ãŒã‚ã‚‹å ´åˆï¼‰\n",
    "        ax3 = axes[1, 0]\n",
    "        \n",
    "        # predictionsã«æ—¥ä»˜ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "        if 'æ—¥ä»˜' in predictions.columns:\n",
    "            # æ—¢ã«æ—¥ä»˜ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ\n",
    "            pred_sorted = predictions.sort_values('æ—¥ä»˜')\n",
    "            ax3.plot(pred_sorted['æ—¥ä»˜'], pred_sorted['å£²ä¸Šæ•°é‡'], \n",
    "                    label='å®Ÿç¸¾', alpha=0.7, linewidth=1.5, color='blue', marker='o', markersize=3)\n",
    "            ax3.plot(pred_sorted['æ—¥ä»˜'], pred_sorted['prediction_label'], \n",
    "                    label='äºˆæ¸¬', alpha=0.7, linewidth=1.5, color='orange', marker='x', markersize=3)\n",
    "            ax3.set_xlabel('æ—¥ä»˜', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_ylabel('å£²ä¸Šï¼ˆå††ï¼‰', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_title('3ï¸âƒ£ æ™‚ç³»åˆ—äºˆæ¸¬æ¨ç§»', fontproperties=font_setup.jp_font)\n",
    "            ax3.legend(prop=font_setup.jp_font)\n",
    "            ax3.grid(alpha=0.3)\n",
    "            plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        else:\n",
    "            # æ—¥ä»˜ãŒãªã„å ´åˆã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§è¡¨ç¤º\n",
    "            ax3.plot(range(len(predictions)), predictions['å£²ä¸Šæ•°é‡'], \n",
    "                    label='å®Ÿç¸¾', alpha=0.7, linewidth=1.5, color='blue', marker='o', markersize=3)\n",
    "            ax3.plot(range(len(predictions)), predictions['prediction_label'], \n",
    "                    label='äºˆæ¸¬', alpha=0.7, linewidth=1.5, color='orange', marker='x', markersize=3)\n",
    "            ax3.set_xlabel('ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_ylabel('å£²ä¸Šï¼ˆå††ï¼‰', fontproperties=font_setup.jp_font)\n",
    "            ax3.set_title('3ï¸âƒ£ äºˆæ¸¬æ¨ç§»ï¼ˆæ™‚ç³»åˆ—é †ï¼‰', fontproperties=font_setup.jp_font)\n",
    "            ax3.legend(prop=font_setup.jp_font)\n",
    "            ax3.grid(alpha=0.3)\n",
    "        \n",
    "        # 4. äºˆæ¸¬èª¤å·®ç‡ã®åˆ†å¸ƒ\n",
    "        ax4 = axes[1, 1]\n",
    "        error_pct = ((y_pred - y_true) / y_true.replace(0, np.nan) * 100).dropna()\n",
    "        error_pct_clipped = error_pct.clip(-100, 100)\n",
    "        ax4.hist(error_pct_clipped, bins=30, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "        ax4.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        ax4.set_xlabel('äºˆæ¸¬èª¤å·®ç‡ï¼ˆ%ï¼‰', fontproperties=font_setup.jp_font)\n",
    "        ax4.set_ylabel('é »åº¦', fontproperties=font_setup.jp_font)\n",
    "        ax4.set_title(f'4ï¸âƒ£ äºˆæ¸¬èª¤å·®ç‡åˆ†å¸ƒï¼ˆMAPE={mape:.1f}%ï¼‰', fontproperties=font_setup.jp_font)\n",
    "        ax4.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ\n",
    "        print('\\n' + '='*60)\n",
    "        print('ğŸ’¡ ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ')\n",
    "        print('='*60)\n",
    "        \n",
    "        if r2 >= 0.8:\n",
    "            print('âœ… ã€é«˜ç²¾åº¦ã€‘ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯æœ¬ç•ªé‹ç”¨ã«æŠ•å…¥å¯èƒ½ã§ã™')\n",
    "            print(f'   - ãƒ¢ãƒ‡ãƒ«ã¯å£²ä¸Šå¤‰å‹•ã®{r2*100:.1f}%ã‚’èª¬æ˜ã§ãã¦ã„ã¾ã™')\n",
    "        elif r2 >= 0.7:\n",
    "            print('âš ï¸ ã€å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã€‘æ³¨æ„ã—ãªãŒã‚‰é‹ç”¨ã§ãã¾ã™ï¼ˆæ”¹å–„ã®ä½™åœ°ã‚ã‚Šï¼‰')\n",
    "            print(f'   - ãƒ¢ãƒ‡ãƒ«ã¯å£²ä¸Šå¤‰å‹•ã®{r2*100:.1f}%ã‚’èª¬æ˜ã§ãã¦ã„ã¾ã™')\n",
    "        else:\n",
    "            print('âŒ ã€è¦æ”¹å–„ã€‘ç‰¹å¾´é‡ã®è¿½åŠ ã‚„ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®å»¶é•·ãŒå¿…è¦ã§ã™')\n",
    "            print(f'   - ãƒ¢ãƒ‡ãƒ«ã¯å£²ä¸Šå¤‰å‹•ã®{r2*100:.1f}%ã—ã‹èª¬æ˜ã§ãã¦ã„ã¾ã›ã‚“')\n",
    "        \n",
    "        if mape < 10:\n",
    "            print('âœ… ã€å„ªç§€ã€‘ç™ºæ³¨æ•°é‡ã®è‡ªå‹•åŒ–ã«æ´»ç”¨ã§ãã¾ã™')\n",
    "        elif mape < 20:\n",
    "            print('âš ï¸ ã€å®Ÿç”¨å¯ã€‘äººé–“ã®ãƒã‚§ãƒƒã‚¯ã‚’ä½µç”¨ã—ã¦ãã ã•ã„')\n",
    "        else:\n",
    "            print('âŒ ã€è¦æ³¨æ„ã€‘è‡ªå‹•åŒ–ã¯é¿ã‘ã€å‚è€ƒå€¤ã¨ã—ã¦åˆ©ç”¨ã—ã¦ãã ã•ã„')\n",
    "        \n",
    "        print(f'\\nğŸ“Š äºˆæ¸¬ç²¾åº¦ã®å®Ÿå‹™çš„ãªæ„å‘³:')\n",
    "        print(f'  - å¹³å‡äºˆæ¸¬èª¤å·®: Â±{mae:,.0f}å††')\n",
    "        print(f'  - å¤§éƒ¨åˆ†ã®äºˆæ¸¬ã¯ Â±{rmse:,.0f}å†† ã®ç¯„å›²å†…')\n",
    "        print(f'  - äºˆæ¸¬ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(predictions):,}ä»¶')\n",
    "        \n",
    "        # æœ€å¤§èª¤å·®ã®åˆ†æ\n",
    "        abs_errors = np.abs(residuals)\n",
    "        max_error_idx = abs_errors.idxmax()\n",
    "        max_error_actual = y_true.loc[max_error_idx]\n",
    "        max_error_pred = y_pred.loc[max_error_idx]\n",
    "        max_error_diff = residuals.loc[max_error_idx]\n",
    "        \n",
    "        print(f'\\nâš ï¸ æœ€å¤§èª¤å·®ã®ã‚±ãƒ¼ã‚¹:')\n",
    "        print(f'  - å®Ÿç¸¾: {max_error_actual:,.0f}å††')\n",
    "        print(f'  - äºˆæ¸¬: {max_error_pred:,.0f}å††')\n",
    "        print(f'  - èª¤å·®: {max_error_diff:,.0f}å†† ({abs(max_error_diff/max_error_actual*100):.1f}%)')\n",
    "        print(f'  ğŸ’¡ ã“ã®ã‚ˆã†ãªå¤–ã‚Œå€¤ã¯ç‰¹æ®Šã‚¤ãƒ™ãƒ³ãƒˆã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print('âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«ã‚¹ãƒ†ãƒƒãƒ—4ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2br5d2hc0od",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ã‚¹ãƒ†ãƒƒãƒ—6: 1é€±é–“å…ˆã®ç™ºæ³¨æ•°é‡äºˆæ¸¬ï¼ˆå…¨å•†å“ï¼‰\n",
    "\n",
    "### ğŸ¯ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„**\n",
    "**å­¦ç¿’ã—ãŸAIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€2025å¹´10æœˆ15æ—¥ã‹ã‚‰1é€±é–“åˆ†ã®å…¨å•†å“ã®è²©å£²æ•°é‡ã‚’äºˆæ¸¬ã—ã€ç™ºæ³¨æ•°é‡ã‚’è‡ªå‹•è¨ˆç®—ã—ã¾ã™ã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ **äºˆæ¸¬ã®æµã‚Œ**\n",
    "\n",
    "1. **å¤–éƒ¨è¦å› ã®å…¥åŠ›** â†’ 1é€±é–“åˆ†ã®å¤©æ°—äºˆå ±ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æƒ…å ±ã‚’å…¥åŠ›\n",
    "2. **AIãŒäºˆæ¸¬** â†’ å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§å•†å“Ã—æ—¥ä»˜ã”ã¨ã«è²©å£²æ•°é‡ã‚’äºˆæ¸¬\n",
    "3. **ç™ºæ³¨æ•°é‡ã®è¨ˆç®—** â†’ äºˆæ¸¬å€¤ Ã— å®‰å…¨ä¿‚æ•°ã§ç™ºæ³¨æ•°é‡ã‚’ç®—å‡º\n",
    "4. **CSVå‡ºåŠ›** â†’ ç™ºæ³¨è¡¨ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘€ **åº—é•·ãŒå…¥åŠ›ã™ã¹ãæƒ…å ±**\n",
    "\n",
    "æ¬¡ã®ã‚»ãƒ«ã§ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š\n",
    "\n",
    "| é …ç›® | å…¥åŠ›ä¾‹ | èª¬æ˜ |\n",
    "|------|--------|------|\n",
    "| **äºˆæ¸¬é–‹å§‹æ—¥** | `2025-10-15` | ç™ºæ³¨ã‚’é–‹å§‹ã™ã‚‹æ—¥ |\n",
    "| **äºˆæ¸¬æ—¥æ•°** | `7` | ä½•æ—¥åˆ†äºˆæ¸¬ã™ã‚‹ã‹ï¼ˆé€šå¸¸ã¯7æ—¥ï¼‰ |\n",
    "| **å¤©æ°—äºˆå ±** | `['æ™´ã‚Œ', 'æ›‡ã‚Š', 'é›¨', ...]` | 1é€±é–“åˆ†ã®å¤©æ°—äºˆå ± |\n",
    "| **å¹³å‡æ°—æ¸©** | `[22, 23, 20, 18, ...]` | 1é€±é–“åˆ†ã®äºˆæ¸¬æ°—æ¸©ï¼ˆâ„ƒï¼‰ |\n",
    "| **é™æ°´ç¢ºç‡** | `[10, 30, 70, ...]` | 1é€±é–“åˆ†ã®é™æ°´ç¢ºç‡ï¼ˆ%ï¼‰ |\n",
    "| **å®‰å…¨ä¿‚æ•°** | `1.2` | æ¬ å“é˜²æ­¢ã®ãŸã‚ã®ä½™è£•ç‡ï¼ˆé€šå¸¸1.1ï½1.3ï¼‰ |\n",
    "\n",
    "**å®‰å…¨ä¿‚æ•°ã®ç›®å®‰**:\n",
    "- `1.0` â†’ äºˆæ¸¬å€¤ãã®ã¾ã¾ï¼ˆãƒªã‚¹ã‚¯é«˜ï¼‰\n",
    "- `1.1ï½1.2` â†’ é€šå¸¸ã®é‹ç”¨ï¼ˆæ¨å¥¨ï¼‰\n",
    "- `1.3ï½1.5` â†’ æ¬ å“ã‚’çµ¶å¯¾ã«é¿ã‘ãŸã„ï¼ˆå»ƒæ£„ãƒªã‚¹ã‚¯å¢—ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "**æ¬¡ã®ã‚»ãƒ«ã§å¤–éƒ¨è¦å› ã‚’å…¥åŠ›ã—ã€äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ â†“**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rbi69vvi24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ“Š Step 6-1: å…¨åº—èˆ—Ã—å…¨å•†å“ã®äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆGPUé«˜é€ŸåŒ–ç‰ˆï¼‰\n",
    "# ========================================\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('ğŸ“… Step 6-1: å…¨åº—èˆ—ã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿å–å¾— + äºˆæ¸¬ç”¨ç‰¹å¾´é‡ä½œæˆ')\n",
    "print('='*60)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# ========================================\n",
    "# ğŸ“ åº—èˆ—ãƒã‚¹ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "# ========================================\n",
    "\n",
    "print('\\nğŸ“ åº—èˆ—ãƒã‚¹ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...')\n",
    "stores_df = pd.read_csv('stores.csv')\n",
    "print(f'  âœ… åº—èˆ—æ•°: {len(stores_df)} åº—èˆ—')\n",
    "print(f'  åº—èˆ—ãƒªã‚¹ãƒˆ: {list(stores_df[\"åº—èˆ—å\"][:5])}...')\n",
    "\n",
    "# ========================================\n",
    "# ğŸ›ï¸ å•†å“ãƒã‚¹ã‚¿ã®ä½œæˆï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠ½å‡ºï¼‰\n",
    "# ========================================\n",
    "\n",
    "print('\\nğŸ›ï¸ å•†å“ãƒã‚¹ã‚¿ã‚’ä½œæˆä¸­...')\n",
    "if 'df' in globals() and 'å•†å“å' in df.columns:\n",
    "    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å•†å“æƒ…å ±ã‚’æŠ½å‡º\n",
    "    sku_master = df[['å•†å“å']].drop_duplicates().copy()\n",
    "    \n",
    "    # å•†å“å˜ä¾¡ã‚’è¨ˆç®—ï¼ˆpriceåˆ—ãŒã‚ã‚‹å ´åˆï¼‰\n",
    "    if 'price' in df.columns:\n",
    "        sku_prices = df.groupby('å•†å“å')['price'].mean().reset_index()\n",
    "        sku_master = sku_master.merge(sku_prices, on='å•†å“å', how='left')\n",
    "    elif 'å£²ä¸Šé‡‘é¡' in df.columns and 'å£²ä¸Šæ•°é‡' in df.columns:\n",
    "        # sales_amt / qty ã§å˜ä¾¡ã‚’è¨ˆç®—\n",
    "        df_with_price = df[df['å£²ä¸Šæ•°é‡'] > 0].copy()\n",
    "        df_with_price['calc_price'] = df_with_price['å£²ä¸Šé‡‘é¡'] / df_with_price['å£²ä¸Šæ•°é‡']\n",
    "        sku_prices = df_with_price.groupby('å•†å“å')['calc_price'].median().reset_index()\n",
    "        sku_prices.columns = ['å•†å“å', 'price']\n",
    "        sku_master = sku_master.merge(sku_prices, on='å•†å“å', how='left')\n",
    "    \n",
    "    print(f'  âœ… å•†å“æ•°: {len(sku_master)} SKU')\n",
    "    if 'price' in sku_master.columns:\n",
    "        print(f'  å¹³å‡å˜ä¾¡: Â¥{sku_master[\"price\"].mean():.0f}')\n",
    "else:\n",
    "    print('  âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å•†å“ãƒã‚¹ã‚¿ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸ')\n",
    "    sku_master = pd.DataFrame({'å•†å“å': [1]})  # ãƒ€ãƒŸãƒ¼\n",
    "\n",
    "# ========================================\n",
    "# ğŸŒ¤ï¸ å…¨åº—èˆ—ã®å¤©æ°—äºˆå ±ã‚’ä¸€æ‹¬å–å¾—ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰\n",
    "# ========================================\n",
    "\n",
    "FORECAST_START_DATE = '2025-10-15'  # äºˆæ¸¬é–‹å§‹æ—¥\n",
    "FORECAST_DAYS = 7  # äºˆæ¸¬æ—¥æ•°\n",
    "\n",
    "print(f'\\nğŸŒ¤ï¸ å…¨{len(stores_df)}åº—èˆ—ã®å¤©æ°—äºˆå ±ã‚’å–å¾—ä¸­...')\n",
    "print(f'  æœŸé–“: {FORECAST_START_DATE} ï½ {FORECAST_DAYS}æ—¥é–“')\n",
    "\n",
    "weather_codes = {\n",
    "    0: 'æ™´ã‚Œ', 1: 'æ™´ã‚Œ', 2: 'æ™´ã‚Œ', 3: 'æ›‡ã‚Š',\n",
    "    45: 'éœ§', 48: 'éœ§', 51: 'å°é›¨', 53: 'å°é›¨', 55: 'é›¨',\n",
    "    61: 'é›¨', 63: 'é›¨', 65: 'å¤§é›¨', 80: 'é›¨', 81: 'é›¨', 82: 'å¤§é›¨'\n",
    "}\n",
    "\n",
    "all_store_weather = []\n",
    "\n",
    "for idx, store in stores_df.iterrows():\n",
    "    store_name = store['åº—èˆ—å']\n",
    "    lat = store['ç·¯åº¦']\n",
    "    lon = store['çµŒåº¦']\n",
    "    \n",
    "    try:\n",
    "        url = 'https://api.open-meteo.com/v1/forecast'\n",
    "        params = {\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'daily': 'temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode',\n",
    "            'timezone': 'Asia/Tokyo',\n",
    "            'start_date': FORECAST_START_DATE,\n",
    "            'end_date': (datetime.strptime(FORECAST_START_DATE, '%Y-%m-%d') + timedelta(days=FORECAST_DAYS-1)).strftime('%Y-%m-%d')\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # åº—èˆ—ã”ã¨ã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜\n",
    "        for i in range(len(data['daily']['time'])):\n",
    "            weather_code = data['daily']['weathercode'][i]\n",
    "            all_store_weather.append({\n",
    "                'store_name': store_name,\n",
    "                'store_lat': lat,\n",
    "                'store_lon': lon,\n",
    "                'æ—¥ä»˜': data['daily']['time'][i],\n",
    "                'weather': weather_codes.get(weather_code, 'ä¸æ˜'),\n",
    "                'temp_max': data['daily']['temperature_2m_max'][i],\n",
    "                'temp_min': data['daily']['temperature_2m_min'][i],\n",
    "                'temp_avg': (data['daily']['temperature_2m_max'][i] + data['daily']['temperature_2m_min'][i]) / 2,\n",
    "                'precipitation': data['daily']['precipitation_sum'][i]\n",
    "            })\n",
    "        \n",
    "        print(f'  âœ… {store_name}: {len(data[\"daily\"][\"time\"])}æ—¥åˆ†å–å¾—')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'  âŒ {store_name}: APIå¤±æ•— ({e}) - ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨')\n",
    "        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿\n",
    "        for i in range(FORECAST_DAYS):\n",
    "            forecast_date = (datetime.strptime(FORECAST_START_DATE, '%Y-%m-%d') + timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "            all_store_weather.append({\n",
    "                'store_name': store_name,\n",
    "                'store_lat': lat,\n",
    "                'store_lon': lon,\n",
    "                'æ—¥ä»˜': forecast_date,\n",
    "                'weather': 'æ™´ã‚Œ',\n",
    "                'temp_max': 25.0,\n",
    "                'temp_min': 18.0,\n",
    "                'temp_avg': 21.5,\n",
    "                'precipitation': 0.0\n",
    "            })\n",
    "\n",
    "weather_all_df = pd.DataFrame(all_store_weather)\n",
    "print(f'\\nâœ… å¤©æ°—ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(weather_all_df)} ãƒ¬ã‚³ãƒ¼ãƒ‰')\n",
    "\n",
    "# ========================================\n",
    "# ğŸ”„ å…¨åº—èˆ—Ã—å…¨å•†å“Ã—å…¨æ—¥ä»˜ã®çµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆ\n",
    "# ========================================\n",
    "\n",
    "print('\\nğŸ”„ äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆä¸­...')\n",
    "\n",
    "# åº—èˆ—ãƒã‚¹ã‚¿ã«åº—èˆ—IDã‚’è¿½åŠ \n",
    "stores_df['åº—èˆ—'] = range(1, len(stores_df) + 1)\n",
    "\n",
    "# å…¨çµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆï¼ˆåº—èˆ—Ã—å•†å“Ã—æ—¥ä»˜ï¼‰\n",
    "forecast_combinations = []\n",
    "\n",
    "for _, store in stores_df.iterrows():\n",
    "    store_id = store['åº—èˆ—']\n",
    "    store_name = store['åº—èˆ—å']\n",
    "    \n",
    "    for _, sku in sku_master.iterrows():\n",
    "        sku_id = sku['å•†å“å']\n",
    "        sku_price = sku.get('price', np.nan)\n",
    "        \n",
    "        # ã“ã®åº—èˆ—ã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "        store_weather = weather_all_df[weather_all_df['store_name'] == store_name]\n",
    "        \n",
    "        for _, w_data in store_weather.iterrows():\n",
    "            date_obj = datetime.strptime(w_data['æ—¥ä»˜'], '%Y-%m-%d')\n",
    "            \n",
    "            features = {\n",
    "                'åº—èˆ—': store_id,\n",
    "                'å•†å“å': sku_id,\n",
    "                'price': sku_price,\n",
    "                'æ—¥ä»˜': w_data['æ—¥ä»˜'],\n",
    "                'å¹´': date_obj.year,\n",
    "                'æœˆ': date_obj.month,\n",
    "                'æ—¥': date_obj.day,\n",
    "                'æ›œæ—¥': date_obj.weekday(),\n",
    "                'é€±ç•ªå·': date_obj.isocalendar()[1],\n",
    "                'å¹´å†…æ—¥æ•°': date_obj.timetuple().tm_yday,\n",
    "                'ç¥æ—¥ãƒ•ãƒ©ã‚°': 0,\n",
    "                'åœŸæ›œãƒ•ãƒ©ã‚°': 1 if date_obj.weekday() == 5 else 0,\n",
    "                'æ—¥æ›œãƒ•ãƒ©ã‚°': 1 if date_obj.weekday() == 6 else 0,\n",
    "                'é€±æœ«ãƒ•ãƒ©ã‚°': 1 if date_obj.weekday() >= 5 else 0,\n",
    "                'å¹³æ—¥ãƒ•ãƒ©ã‚°': 1 if date_obj.weekday() < 5 else 0,\n",
    "                'å¤©æ°—': w_data['weather'],\n",
    "                'æœ€é«˜æ°—æ¸©': w_data['temp_max'],\n",
    "                'æœ€ä½æ°—æ¸©': w_data['temp_min'],\n",
    "                'å¹³å‡æ°—æ¸©': w_data['temp_avg'],\n",
    "                'æ°—æ¸©å·®': w_data['temp_max'] - w_data['temp_min'],\n",
    "                'é™æ°´é‡': w_data['precipitation'],\n",
    "            }\n",
    "            \n",
    "            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å…¨ã‚«ãƒ©ãƒ ã«å¯¾å¿œ\n",
    "            if 'feat' in globals():\n",
    "                for col in feat.columns:\n",
    "                    if col not in features and col not in ['å£²ä¸Šæ•°é‡', 'å£²ä¸Šé‡‘é¡']:\n",
    "                        # ãƒ©ã‚°ç‰¹å¾´é‡ã‚„ç§»å‹•å¹³å‡ã¯NaN\n",
    "                        if '_t-' in col or '_MA' in col or 'å¤‰åŒ–' in col or 'ãƒˆãƒ¬ãƒ³ãƒ‰' in col or 'ç´¯ç©' in col:\n",
    "                            features[col] = np.nan\n",
    "                        else:\n",
    "                            features[col] = 0\n",
    "            \n",
    "            forecast_combinations.append(features)\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_combinations)\n",
    "\n",
    "# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜åˆ—é †åºã«ä¸¦ã¹æ›¿ãˆ\n",
    "if 'feat' in globals():\n",
    "    common_cols = [c for c in feat.columns if c in forecast_df.columns and c not in ['å£²ä¸Šæ•°é‡', 'å£²ä¸Šé‡‘é¡']]\n",
    "    # å¿…é ˆåˆ—ï¼ˆåº—èˆ—ã€å•†å“åã€æ—¥ä»˜ï¼‰ã‚’ä¿æŒã—ã¤ã¤ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜åˆ—é †åºã«ä¸¦ã¹æ›¿ãˆ\n",
    "    essential_cols = ['åº—èˆ—', 'å•†å“å', 'æ—¥ä»˜']\n",
    "    feature_cols_only = [c for c in common_cols if c not in essential_cols]\n",
    "    final_cols = essential_cols + feature_cols_only + ['price']\n",
    "    # forecast_dfã«å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿é¸æŠ\n",
    "    final_cols = [c for c in final_cols if c in forecast_df.columns]\n",
    "    forecast_df = forecast_df[final_cols]\n",
    "\n",
    "print(f'\\nâœ… äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†:')\n",
    "print(f'  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(forecast_df):,} ä»¶')\n",
    "print(f'  = {len(stores_df)} åº—èˆ— Ã— {len(sku_master)} å•†å“ Ã— {FORECAST_DAYS} æ—¥')\n",
    "print(f'  åˆ—æ•°: {len(forecast_df.columns)}')\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\n",
    "print('\\nğŸ“‹ äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:')\n",
    "sample_cols = ['åº—èˆ—', 'å•†å“å', 'æ—¥ä»˜', 'å¹´', 'æœˆ', 'æ›œæ—¥', 'å¤©æ°—', 'æœ€é«˜æ°—æ¸©', 'price']\n",
    "display_cols = [c for c in sample_cols if c in forecast_df.columns]\n",
    "display(forecast_df[display_cols].head(10))\n",
    "\n",
    "print('\\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: Step 6-2ã§å•†å“åˆ¥ãƒ»åº—èˆ—åˆ¥ã®è²©å£²æ•°é‡ã‚’äºˆæ¸¬ã—ã¦ãã ã•ã„')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2qr8mow022t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ“¦ Step 6-2: å…¨åº—èˆ—Ã—å…¨å•†å“ã®è²©å£²æ•°é‡äºˆæ¸¬ï¼ˆGPUé«˜é€ŸåŒ–ç‰ˆï¼‰\n",
    "# ========================================\n",
    "\n",
    "if not PYC_OK or 'final' not in globals():\n",
    "    print('âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«ã‚¹ãƒ†ãƒƒãƒ—4ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')\n",
    "elif 'forecast_df' not in globals():\n",
    "    print('âš ï¸ äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«Step 6-1ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')\n",
    "else:\n",
    "    print('\\n' + '='*60)\n",
    "    print('ğŸ¤– å…¨åº—èˆ—Ã—å…¨å•†å“ã®è²©å£²æ•°é‡äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...')\n",
    "    print('='*60)\n",
    "    \n",
    "    total_records = len(forecast_df)\n",
    "    print(f'\\nğŸ“Š äºˆæ¸¬å¯¾è±¡:')\n",
    "    print(f'  å•†å“æ•°: {forecast_df[\"å•†å“å\"].nunique()} SKU')\n",
    "    print(f'  åº—èˆ—æ•°: {forecast_df[\"åº—èˆ—\"].nunique()} åº—èˆ—')\n",
    "    print(f'  æ—¥æ•°: {forecast_df[\"æ—¥ä»˜\"].nunique()} æ—¥')\n",
    "    print(f'  åˆè¨ˆäºˆæ¸¬ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,} ä»¶')\n",
    "    \n",
    "    # GPUä¸¦åˆ—åŒ–è¨­å®š\n",
    "    BATCH_SIZE = 10000  # GPUæœ€é©ãªãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰\n",
    "    \n",
    "    if USE_GPU and GPU_AVAILABLE:\n",
    "        print(f'\\nğŸš€ GPUä¸¦åˆ—åŒ–ãƒ¢ãƒ¼ãƒ‰: {BATCH_SIZE:,}ä»¶ãšã¤ãƒãƒƒãƒå‡¦ç†')\n",
    "    else:\n",
    "        print(f'\\nâ„¹ï¸ CPUå‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {BATCH_SIZE:,}ä»¶ãšã¤ãƒãƒƒãƒå‡¦ç†')\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ãƒãƒƒãƒäºˆæ¸¬ï¼ˆGPUé«˜é€ŸåŒ–ï¼‰\n",
    "    predictions_list = []\n",
    "    num_batches = (total_records + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = min((batch_idx + 1) * BATCH_SIZE, total_records)\n",
    "        \n",
    "        batch_data = forecast_df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # priceåˆ—ã‚’é™¤å¤–ã—ã¦äºˆæ¸¬\n",
    "        pred_cols = [c for c in batch_data.columns if c != 'price']\n",
    "        batch_pred_data = batch_data[pred_cols]\n",
    "        \n",
    "        # ãƒãƒƒãƒäºˆæ¸¬å®Ÿè¡Œ\n",
    "        try:\n",
    "            batch_pred = predict_model(final, data=batch_pred_data)\n",
    "            \n",
    "            # priceåˆ—ã‚’å¾©å…ƒ\n",
    "            if 'price' in batch_data.columns:\n",
    "                batch_pred['price'] = batch_data['price'].values\n",
    "            \n",
    "            predictions_list.append(batch_pred)\n",
    "            \n",
    "            # é€²æ—è¡¨ç¤º\n",
    "            progress = (batch_idx + 1) / num_batches * 100\n",
    "            print(f'\\râ³ äºˆæ¸¬é€²æ—: {progress:.1f}% ({batch_idx+1}/{num_batches} ãƒãƒƒãƒ)', end='')\n",
    "        except Exception as e:\n",
    "            print(f'\\nâš ï¸ ãƒãƒƒãƒ{batch_idx+1}ã§ã‚¨ãƒ©ãƒ¼: {e}')\n",
    "            continue\n",
    "    \n",
    "    print()  # æ”¹è¡Œ\n",
    "    \n",
    "    if predictions_list:\n",
    "        forecast_result = pd.concat(predictions_list, ignore_index=True)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        records_per_sec = total_records / elapsed if elapsed > 0 else 0\n",
    "        \n",
    "        print(f'\\nâœ… äºˆæ¸¬å®Œäº†:')\n",
    "        print(f'  ç·ä»¶æ•°: {len(forecast_result):,} ä»¶')\n",
    "        print(f'  å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’')\n",
    "        print(f'  å‡¦ç†é€Ÿåº¦: {records_per_sec:,.0f} ä»¶/ç§’')\n",
    "        if USE_GPU:\n",
    "            print(f'  ğŸ’¡ GPUã«ã‚ˆã‚Šé«˜é€ŸåŒ–ã•ã‚Œã¾ã—ãŸ')\n",
    "        \n",
    "        # äºˆæ¸¬å€¤ã‚’ã‚ã‹ã‚Šã‚„ã™ã„åˆ—åã«å¤‰æ›´\n",
    "        if 'prediction_label' in forecast_result.columns:\n",
    "            forecast_result = forecast_result.rename(columns={\n",
    "                'prediction_label': 'predicted_qty'  # è²©å£²æ•°é‡äºˆæ¸¬\n",
    "            })\n",
    "        \n",
    "        # ========================================\n",
    "        # ğŸ’° å£²ä¸Šé‡‘é¡ã®è¨ˆç®—ï¼ˆäºˆæ¸¬æ•°é‡ Ã— å˜ä¾¡ï¼‰\n",
    "        # ========================================\n",
    "        \n",
    "        if 'predicted_qty' in forecast_result.columns and 'price' in forecast_result.columns:\n",
    "            # è² ã®äºˆæ¸¬å€¤ã‚’0ã«è£œæ­£\n",
    "            forecast_result['predicted_qty'] = forecast_result['predicted_qty'].clip(lower=0)\n",
    "            \n",
    "            # å£²ä¸Šé‡‘é¡ = äºˆæ¸¬æ•°é‡ Ã— å˜ä¾¡\n",
    "            forecast_result['predicted_sales_amt'] = (\n",
    "                forecast_result['predicted_qty'] * forecast_result['price']\n",
    "            ).round(0)\n",
    "            \n",
    "            print(f'\\nğŸ’° å£²ä¸Šé‡‘é¡è¨ˆç®—å®Œäº†:')\n",
    "            print(f'  äºˆæ¸¬è²©å£²æ•°é‡åˆè¨ˆ: {forecast_result[\"predicted_qty\"].sum():,.0f} å€‹')\n",
    "            print(f'  äºˆæ¸¬å£²ä¸Šé‡‘é¡åˆè¨ˆ: Â¥{forecast_result[\"predicted_sales_amt\"].sum():,.0f}')\n",
    "        \n",
    "        # ========================================\n",
    "        # ğŸ“¦ ç™ºæ³¨æ•°é‡ã®è¨ˆç®—ï¼ˆå®‰å…¨åœ¨åº«ä¿‚æ•°ï¼‰\n",
    "        # ========================================\n",
    "        \n",
    "        SAFETY_FACTOR = 1.2  # 20%å¤šã‚ã«ç™ºæ³¨ï¼ˆæ©Ÿä¼šæå¤±ã‚’é˜²ãï¼‰\n",
    "        \n",
    "        if 'predicted_qty' in forecast_result.columns:\n",
    "            forecast_result['order_qty'] = (\n",
    "                forecast_result['predicted_qty'] * SAFETY_FACTOR\n",
    "            ).round(0).astype(int)\n",
    "            \n",
    "            print(f'\\nğŸ“¦ ç™ºæ³¨æ•°é‡è¨ˆç®—å®Œäº†:')\n",
    "            print(f'  å®‰å…¨ä¿‚æ•°: {SAFETY_FACTOR}å€')\n",
    "            print(f'  ç™ºæ³¨æ•°é‡åˆè¨ˆ: {forecast_result[\"order_qty\"].sum():,} å€‹')\n",
    "            print(f'  ï¼ˆäºˆæ¸¬æ•°é‡ã®{SAFETY_FACTOR}å€ã§åœ¨åº«åˆ‡ã‚Œãƒªã‚¹ã‚¯ã‚’ä½æ¸›ï¼‰')\n",
    "        \n",
    "        # ========================================\n",
    "        # ğŸ“Š çµæœã‚µãƒãƒªãƒ¼\n",
    "        # ========================================\n",
    "        \n",
    "        print(f'\\nğŸ“Š äºˆæ¸¬çµæœã‚µãƒãƒªãƒ¼ï¼ˆä¸Šä½10ä»¶ï¼‰:')\n",
    "        display_cols = []\n",
    "        for col in ['æ—¥ä»˜', 'åº—èˆ—', 'å•†å“å', 'predicted_qty', 'order_qty', 'price', 'predicted_sales_amt']:\n",
    "            if col in forecast_result.columns:\n",
    "                display_cols.append(col)\n",
    "        \n",
    "        if display_cols:\n",
    "            # äºˆæ¸¬è²©å£²æ•°é‡ãŒå¤šã„é †ã«ã‚½ãƒ¼ãƒˆ\n",
    "            top_results = forecast_result.nlargest(10, 'predicted_qty' if 'predicted_qty' in forecast_result.columns else 'predicted_sales_amt')\n",
    "            print(top_results[display_cols])\n",
    "        \n",
    "        # æ—¥åˆ¥ã‚µãƒãƒªãƒ¼\n",
    "        if 'æ—¥ä»˜' in forecast_result.columns and 'predicted_qty' in forecast_result.columns:\n",
    "            print(f'\\nğŸ“… æ—¥åˆ¥ã‚µãƒãƒªãƒ¼:')\n",
    "            daily_summary = forecast_result.groupby('æ—¥ä»˜').agg({\n",
    "                'predicted_qty': 'sum',\n",
    "                'order_qty': 'sum',\n",
    "                'predicted_sales_amt': 'sum'\n",
    "            }).reset_index()\n",
    "            daily_summary.columns = ['æ—¥ä»˜', 'äºˆæ¸¬è²©å£²æ•°é‡', 'ç™ºæ³¨æ•°é‡', 'äºˆæ¸¬å£²ä¸Šé‡‘é¡']\n",
    "            print(daily_summary)\n",
    "        \n",
    "        # åº—èˆ—åˆ¥ã‚µãƒãƒªãƒ¼\n",
    "        if 'åº—èˆ—' in forecast_result.columns and 'predicted_qty' in forecast_result.columns:\n",
    "            print(f'\\nğŸª åº—èˆ—åˆ¥ã‚µãƒãƒªãƒ¼ï¼ˆä¸Šä½5åº—èˆ—ï¼‰:')\n",
    "            store_summary = forecast_result.groupby('åº—èˆ—').agg({\n",
    "                'predicted_qty': 'sum',\n",
    "                'order_qty': 'sum',\n",
    "                'predicted_sales_amt': 'sum'\n",
    "            }).reset_index()\n",
    "            store_summary.columns = ['åº—èˆ—ID', 'äºˆæ¸¬è²©å£²æ•°é‡', 'ç™ºæ³¨æ•°é‡', 'äºˆæ¸¬å£²ä¸Šé‡‘é¡']\n",
    "            store_summary = store_summary.nlargest(5, 'äºˆæ¸¬å£²ä¸Šé‡‘é¡')\n",
    "            print(store_summary)\n",
    "        \n",
    "        print(f'\\nâœ… äºˆæ¸¬å®Œäº†ï¼æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: Step 6-3ã§CSVå‡ºåŠ›ã—ã¦ãã ã•ã„')\n",
    "    else:\n",
    "        print('\\nâŒ äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slf8tnkekhn",
   "metadata": {},
   "source": [
    "## ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—7: ç™ºæ³¨äºˆæ¸¬çµæœã®èª­ã¿æ–¹ã¨å®Ÿå‹™ã§ã®ä½¿ã„æ–¹\n",
    "\n",
    "### ğŸ¯ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„**\n",
    "**ä¸Šã§å‡ºåŠ›ã•ã‚ŒãŸç™ºæ³¨äºˆæ¸¬è¡¨ã‚’ã€æ˜æ—¥ã‹ã‚‰ã©ã†ä½¿ã†ã‹ã‚’è§£èª¬ã—ã¾ã™ã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ å‡ºåŠ›ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹\n",
    "\n",
    "### ğŸ“‹ **ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«: `ç™ºæ³¨äºˆæ¸¬_2025-10-15_to_2025-10-21.csv`**\n",
    "\n",
    "ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€å…¨å•†å“Ã—7æ—¥åˆ†ã®ç™ºæ³¨äºˆæ¸¬ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "| åˆ—å | æ„å‘³ | ä½¿ã„æ–¹ |\n",
    "|------|------|--------|\n",
    "| **æ—¥ä»˜** | è²©å£²äºˆå®šæ—¥ | ã“ã®æ—¥ã«åº—é ­ã«ä¸¦ã¶å•†å“ |\n",
    "| **æ›œæ—¥** | æ›œæ—¥ï¼ˆMondayï½Sundayï¼‰ | æ›œæ—¥åˆ¥ã®ç™ºæ³¨ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºèª |\n",
    "| **åº—èˆ—** | åº—èˆ—ã‚³ãƒ¼ãƒ‰ | è¤‡æ•°åº—èˆ—ã®å ´åˆã€åº—èˆ—ã”ã¨ã«åˆ†ã‘ã‚‹ |\n",
    "| **å•†å“ã‚³ãƒ¼ãƒ‰** | SKUè­˜åˆ¥å­ | ç™ºæ³¨ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å…¥åŠ›å€¤ |\n",
    "| **å¤§åˆ†é¡/ä¸­åˆ†é¡/å°åˆ†é¡** | ã‚«ãƒ†ã‚´ãƒª | ç™ºæ³¨ä½œæ¥­ã®æ•´ç†ç”¨ |\n",
    "| **äºˆæ¸¬è²©å£²æ•°é‡** | AIã®äºˆæ¸¬å€¤ | ã“ã®æ•°é‡ãŒå£²ã‚Œã‚‹ã¨äºˆæ¸¬ |\n",
    "| **ç™ºæ³¨æ•°é‡** | å®Ÿéš›ã®ç™ºæ³¨æ•° | **ã“ã‚Œã‚’ç™ºæ³¨ã‚·ã‚¹ãƒ†ãƒ ã«å…¥åŠ›** |\n",
    "| **å˜ä¾¡** | å¹³å‡å˜ä¾¡ | äºˆç®—è¨ˆç®—ç”¨ |\n",
    "| **å¤©æ°—/æ°—æ¸©** | äºˆæ¸¬æ—¥ã®å¤©å€™ | åˆ¤æ–­ææ–™ |\n",
    "| **é€±æœ«** | é€±æœ«/å¹³æ—¥ãƒ•ãƒ©ã‚° | é€±æœ«å¯¾å¿œã®ç›®å° |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“… **æ—¥ä»˜åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«: `ç™ºæ³¨äºˆæ¸¬_2025-10-15.csv`**\n",
    "\n",
    "å„æ—¥ä»˜ã”ã¨ã«åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚\n",
    "\n",
    "**ä½¿ã„æ–¹**:\n",
    "1. æ¯æœã€**ãã®æ—¥ã®ç™ºæ³¨ãƒ•ã‚¡ã‚¤ãƒ«**ã‚’é–‹ã\n",
    "2. **ç™ºæ³¨æ•°é‡**åˆ—ã‚’ãã®ã¾ã¾ç™ºæ³¨ã‚·ã‚¹ãƒ†ãƒ ã«å…¥åŠ›\n",
    "3. ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚½ãƒ¼ãƒˆã—ã¦ã€åŠ¹ç‡çš„ã«ç™ºæ³¨ä½œæ¥­ã‚’é€²ã‚ã‚‹\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸª **åº—èˆ—åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«: `ç™ºæ³¨äºˆæ¸¬_åº—èˆ—A_2025-10-15.csv`**\n",
    "\n",
    "è¤‡æ•°åº—èˆ—ãŒã‚ã‚‹å ´åˆã€åº—èˆ—ã”ã¨ã«åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚\n",
    "\n",
    "**ä½¿ã„æ–¹**:\n",
    "- å„åº—èˆ—ã®åº—é•·ã«é…å¸ƒ\n",
    "- åº—èˆ—ã”ã¨ã®ç‰¹æ€§ã‚’åæ˜ ã—ãŸç™ºæ³¨ãŒå¯èƒ½\n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ ç™ºæ³¨ä½œæ¥­ã®å®Ÿå‹™ãƒ•ãƒ­ãƒ¼ï¼ˆæ¯æ—¥ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ï¼‰\n",
    "\n",
    "### ğŸ“ **æ¯æœã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**\n",
    "\n",
    "#### **ã‚¹ãƒ†ãƒƒãƒ—1: CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãï¼ˆ5åˆ†ï¼‰**\n",
    "```\n",
    "1. output/ç™ºæ³¨äºˆæ¸¬_[ä»Šæ—¥ã®æ—¥ä»˜].csv ã‚’é–‹ã\n",
    "2. Excelã§é–‹ã„ã¦ã€ã‚«ãƒ†ã‚´ãƒªã§ã‚½ãƒ¼ãƒˆ\n",
    "3. ç™ºæ³¨ã‚·ã‚¹ãƒ†ãƒ ã¨ç”»é¢ã‚’ä¸¦ã¹ã‚‹\n",
    "```\n",
    "\n",
    "#### **ã‚¹ãƒ†ãƒƒãƒ—2: ç™ºæ³¨æ•°é‡ã‚’ç¢ºèªï¼ˆ5åˆ†ï¼‰**\n",
    "```\n",
    "â–¡ ç™ºæ³¨æ•°é‡ãŒç•°å¸¸ã«å¤šã„å•†å“ã¯ãªã„ã‹ï¼Ÿ\n",
    "  â†’ é€šå¸¸ã®2å€ä»¥ä¸Š â†’ å¤©æ°—ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆã‚’å†ç¢ºèª\n",
    "  â†’ å•é¡Œãªã‘ã‚Œã°ãã®ã¾ã¾ç™ºæ³¨\n",
    "\n",
    "â–¡ ç™ºæ³¨æ•°é‡ãŒ0ã®å•†å“ã¯ãªã„ã‹ï¼Ÿ\n",
    "  â†’ 0ã®å ´åˆ â†’ éå»å®Ÿç¸¾ã‚’ç¢ºèªã—ã¦å°‘é‡ç™ºæ³¨ã‚’æ¤œè¨\n",
    "```\n",
    "\n",
    "#### **ã‚¹ãƒ†ãƒƒãƒ—3: ç™ºæ³¨ã‚·ã‚¹ãƒ†ãƒ ã«å…¥åŠ›ï¼ˆ10ï½15åˆ†ï¼‰**\n",
    "```\n",
    "1. ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ç™ºæ³¨æ•°é‡ã‚’å…¥åŠ›\n",
    "2. ç‰¹ã«æ³¨æ„ã™ã¹ãå•†å“:\n",
    "   - ç™ºæ³¨æ•°é‡ãƒˆãƒƒãƒ—20 â†’ æ¬ å“ã•ã›ãªã„\n",
    "   - é›¨ã®æ—¥ã«å£²ã‚Œã‚‹å•†å“ â†’ é™æ°´ç¢ºç‡ã‚’å†ç¢ºèª\n",
    "   - é€±æœ«ã«å£²ã‚Œã‚‹å•†å“ â†’ é‡‘æ›œã®æœã¾ã§ã«ç™ºæ³¨\n",
    "```\n",
    "\n",
    "#### **ã‚¹ãƒ†ãƒƒãƒ—4: èª¿æ•´ï¼ˆ5åˆ†ï¼‰**\n",
    "```\n",
    "â–¡ å¤©æ°—äºˆå ±ãŒå¤‰ã‚ã£ã¦ã„ãªã„ã‹ç¢ºèª\n",
    "  â†’ å¤‰ã‚ã£ã¦ã„ã‚‹å ´åˆã€æ‰‹å‹•ã§Â±10%èª¿æ•´\n",
    "\n",
    "â–¡ çªç™ºã‚¤ãƒ™ãƒ³ãƒˆï¼ˆã‚»ãƒ¼ãƒ«ãªã©ï¼‰ãŒãªã„ã‹ç¢ºèª\n",
    "  â†’ ã‚ã‚‹å ´åˆã€è©²å½“ã‚«ãƒ†ã‚´ãƒªã‚’+20ï½30%å¢—é‡\n",
    "\n",
    "â–¡ æ˜¨æ—¥ã®å£²ä¸Šå®Ÿç¸¾ã¨æ¯”è¼ƒ\n",
    "  â†’ äºˆæ¸¬ãŒå¤§ããå¤–ã‚Œã¦ã„ã‚‹å ´åˆã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3ï¸âƒ£ çµæœã®èª­ã¿æ–¹ï¼ˆæ•°å­—ã®æ„å‘³ï¼‰\n",
    "\n",
    "### ğŸ“Š **æ—¥ä»˜åˆ¥ã‚µãƒãƒªãƒ¼ã®è¦‹æ–¹**\n",
    "\n",
    "ä¸Šã®ã‚»ãƒ«ã§è¡¨ç¤ºã•ã‚ŒãŸã€Œæ—¥ä»˜åˆ¥ã‚µãƒãƒªãƒ¼ã€:\n",
    "\n",
    "| æ—¥ä»˜ | ç™ºæ³¨æ•°é‡ | äºˆæ¸¬å£²ä¸Šé‡‘é¡ | å•†å“ç¨®é¡æ•° |\n",
    "|------|----------|------------|----------|\n",
    "| 2025-10-15 | 850 | Â¥127,500 | 120 |\n",
    "| 2025-10-16 | 820 | Â¥123,000 | 120 |\n",
    "| 2025-10-19 (é›¨) | 950 | Â¥142,500 | 120 |\n",
    "\n",
    "**èª­ã¿æ–¹**:\n",
    "- **10/19ï¼ˆé›¨ã®æ—¥ï¼‰** â†’ ç™ºæ³¨æ•°é‡ãŒé€šå¸¸ã‚ˆã‚Š+15%å¢—\n",
    "- **æ„å‘³**: AIãŒã€Œé›¨ã®æ—¥ã¯å£²ä¸ŠãŒå¢—ãˆã‚‹ã€ã¨åˆ¤æ–­\n",
    "- **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: æ¸©ã‹ã„å•†å“ãƒ»ã‚«ãƒƒãƒ—éººãªã©ã‚’é‡ç‚¹ç™ºæ³¨\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ **ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚µãƒãƒªãƒ¼ã®è¦‹æ–¹**\n",
    "\n",
    "| å¤§åˆ†é¡ | ç™ºæ³¨æ•°é‡ | äºˆæ¸¬å£²ä¸Šé‡‘é¡ |\n",
    "|--------|----------|------------|\n",
    "| å¼å½“ | 2,100 | Â¥315,000 |\n",
    "| é£²æ–™ | 1,800 | Â¥108,000 |\n",
    "| ç·èœ | 1,500 | Â¥225,000 |\n",
    "\n",
    "**èª­ã¿æ–¹**:\n",
    "- **å¼å½“ãŒæœ€ã‚‚å£²ã‚Œã‚‹** â†’ é™³åˆ—ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å„ªå…ˆç¢ºä¿\n",
    "- **ç™ºæ³¨æ•°é‡ã®æ¯”ç‡** â†’ æ£šå‰²ã‚Šã®å‚è€ƒã«\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” **ç™ºæ³¨æ•°é‡ãƒˆãƒƒãƒ—20ã®ä½¿ã„æ–¹**\n",
    "\n",
    "ä¸Šä½20å•†å“ = **çµ¶å¯¾ã«æ¬ å“ã•ã›ã¦ã¯ã„ã‘ãªã„å•†å“**\n",
    "\n",
    "**å®Ÿå‹™ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:\n",
    "1. **æ¯æ—¥ãƒã‚§ãƒƒã‚¯** â†’ ãƒˆãƒƒãƒ—20å•†å“ã®åœ¨åº«ã‚’æ¯å¤•ç¢ºèª\n",
    "2. **ãƒ•ã‚§ãƒ¼ã‚¹å¢—** â†’ é™³åˆ—ã‚¹ãƒšãƒ¼ã‚¹ã‚’é€šå¸¸ã®1.5å€ç¢ºä¿\n",
    "3. **å‰å‡ºã—å¼·åŒ–** â†’ æ˜¼ãƒ»å¤•ãƒ”ãƒ¼ã‚¯å‰ã«å¿…ãšå‰å‡ºã—\n",
    "4. **æ¬ å“æ™‚ã®å¯¾å¿œ** â†’ äºˆå‚™åœ¨åº«ã‚’ç”¨æ„ã€ã¾ãŸã¯é¡ä¼¼å•†å“ã§ä»£æ›¿\n",
    "\n",
    "---\n",
    "\n",
    "## 4ï¸âƒ£ ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆFAQï¼‰\n",
    "\n",
    "### â“ **äºˆæ¸¬ãŒå¤–ã‚ŒãŸå ´åˆã¯ã©ã†ã™ã‚‹ï¼Ÿ**\n",
    "\n",
    "**å›ç­”**:\n",
    "- **1æ—¥ã ã‘å¤–ã‚ŒãŸ** â†’ çªç™ºè¦å› ï¼ˆç«¶åˆåº—ã®ã‚»ãƒ¼ãƒ«ç­‰ï¼‰ã®å¯èƒ½æ€§ã€‚è¨˜éŒ²ã—ã¦æ¬¡å›ã«æ´»ã‹ã™\n",
    "- **é€£ç¶šã§å¤–ã‚Œã‚‹** â†’ AIã®å†å­¦ç¿’ãŒå¿…è¦ã€‚ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚’å»¶é•·ï¼ˆ3ãƒ¶æœˆâ†’6ãƒ¶æœˆï¼‰ã—ã¦å†å®Ÿè¡Œ\n",
    "\n",
    "---\n",
    "\n",
    "### â“ **å®‰å…¨ä¿‚æ•°ã¯ã©ã†æ±ºã‚ã‚‹ï¼Ÿ**\n",
    "\n",
    "**å›ç­”**:\n",
    "\n",
    "| çŠ¶æ³ | æ¨å¥¨å€¤ | ç†ç”± |\n",
    "|------|--------|------|\n",
    "| **é€šå¸¸é‹ç”¨** | 1.1ï½1.2 | æ¬ å“ã¨å»ƒæ£„ã®ãƒãƒ©ãƒ³ã‚¹ |\n",
    "| **æ–°å•†å“** | 1.3ï½1.5 | éœ€è¦ãŒèª­ã‚ãªã„ãŸã‚ä¿å®ˆçš„ã« |\n",
    "| **å»ƒæ£„ç‡ãŒé«˜ã„** | 1.0ï½1.1 | å»ƒæ£„å‰Šæ¸›ã‚’å„ªå…ˆ |\n",
    "| **æ¬ å“ãŒå¤šç™º** | 1.2ï½1.3 | å£²ä¸Šæ©Ÿä¼šæå¤±ã‚’é˜²ã |\n",
    "\n",
    "**èª¿æ•´æ–¹æ³•**:\n",
    "- 1é€±é–“é‹ç”¨ã—ã¦ã€å»ƒæ£„ç‡ã¨æ¬ å“ç‡ã‚’æ¸¬å®š\n",
    "- å»ƒæ£„ç‡5%ä»¥ä¸Š â†’ å®‰å…¨ä¿‚æ•°ã‚’-0.1ä¸‹ã’ã‚‹\n",
    "- æ¬ å“ç‡3%ä»¥ä¸Š â†’ å®‰å…¨ä¿‚æ•°ã‚’+0.1ä¸Šã’ã‚‹\n",
    "\n",
    "---\n",
    "\n",
    "### â“ **å¤©æ°—äºˆå ±ãŒå¤‰ã‚ã£ãŸã‚‰ã©ã†ã™ã‚‹ï¼Ÿ**\n",
    "\n",
    "**å›ç­”**:\n",
    "1. **å‰æ—¥å¤•æ–¹** ã«æœ€æ–°ã®å¤©æ°—äºˆå ±ã‚’ç¢ºèª\n",
    "2. **é™æ°´ç¢ºç‡ãŒ30%ä»¥ä¸Šå¤‰ã‚ã£ãŸå ´åˆ**:\n",
    "   - æ™´ã‚Œâ†’é›¨ â†’ æ¸©ã‹ã„å•†å“ã‚’+10ï½20%å¢—é‡\n",
    "   - é›¨â†’æ™´ã‚Œ â†’ å†·ãŸã„å•†å“ã‚’+10ï½20%å¢—é‡\n",
    "3. **æ°—æ¸©ãŒ5â„ƒä»¥ä¸Šå¤‰ã‚ã£ãŸå ´åˆ**:\n",
    "   - æš‘ããªã‚‹ â†’ å†·é£²æ–™ãƒ»ã‚¢ã‚¤ã‚¹ã‚’+20%å¢—é‡\n",
    "   - å¯’ããªã‚‹ â†’ ãƒ›ãƒƒãƒˆé£²æ–™ãƒ»ç·èœã‚’+20%å¢—é‡\n",
    "\n",
    "---\n",
    "\n",
    "### â“ **ç™ºæ³¨æ•°é‡ãŒ0ã®å•†å“ã¯ã©ã†ã™ã‚‹ï¼Ÿ**\n",
    "\n",
    "**å›ç­”**:\n",
    "- **AIã®åˆ¤æ–­**: ãã®å•†å“ã¯ãã®æ—¥å£²ã‚Œã«ãã„\n",
    "- **å®Ÿå‹™å¯¾å¿œ**:\n",
    "  1. éå»å®Ÿç¸¾ã‚’ç¢ºèª â†’ æœ¬å½“ã«å£²ã‚Œã¦ã„ãªã„ã‹ï¼Ÿ\n",
    "  2. å£²ã‚Œã¦ã„ã‚‹ â†’ æœ€ä½ç™ºæ³¨æ•°ï¼ˆ1ï½2å€‹ï¼‰ã‚’æ‰‹å‹•å…¥åŠ›\n",
    "  3. å£²ã‚Œã¦ã„ãªã„ â†’ 0ã®ã¾ã¾ç™ºæ³¨ã—ãªã„ï¼ˆåœ¨åº«å‰Šæ¸›ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£ åŠ¹æœæ¸¬å®šï¼ˆ1é€±é–“å¾Œã«ãƒã‚§ãƒƒã‚¯ï¼‰\n",
    "\n",
    "### âœ… **æˆåŠŸæŒ‡æ¨™**\n",
    "\n",
    "| æŒ‡æ¨™ | ç›®æ¨™å€¤ | æ¸¬å®šæ–¹æ³• |\n",
    "|------|--------|----------|\n",
    "| **æ¬ å“ç‡** | 3%ä»¥ä¸‹ | æ¬ å“å•†å“æ•° Ã· å…¨å•†å“æ•° |\n",
    "| **å»ƒæ£„ç‡** | 5%ä»¥ä¸‹ | å»ƒæ£„æ•°é‡ Ã· ç™ºæ³¨æ•°é‡ |\n",
    "| **äºˆæ¸¬ç²¾åº¦** | 80%ä»¥ä¸Š | å®Ÿå£²æ•°é‡ Ã· äºˆæ¸¬æ•°é‡ |\n",
    "| **å£²ä¸Šå¢—åŠ ç‡** | +5%ä»¥ä¸Š | ä»Šé€±å£²ä¸Š vs å…ˆé€±å£²ä¸Š |\n",
    "\n",
    "**æ¸¬å®šã‚·ãƒ¼ãƒˆï¼ˆExcelã§ä½œæˆï¼‰**:\n",
    "```\n",
    "| æ—¥ä»˜ | ç™ºæ³¨æ•°é‡ | å®Ÿå£²æ•°é‡ | å»ƒæ£„æ•°é‡ | æ¬ å“å•†å“æ•° | äºˆæ¸¬ç²¾åº¦ |\n",
    "|------|----------|----------|----------|-----------|---------|\n",
    "| 10/15 | 850 | 820 | 30 | 2 | 96% |\n",
    "| 10/16 | 820 | 790 | 30 | 1 | 96% |\n",
    "| ...  | ... | ... | ... | ... | ... |\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ ã¾ã¨ã‚: AIç™ºæ³¨äºˆæ¸¬ã®æ´»ç”¨ãƒã‚¤ãƒ³ãƒˆ\n",
    "\n",
    "### **æœ€é‡è¦ãƒã‚¤ãƒ³ãƒˆ 3ã¤**\n",
    "\n",
    "1. **æ¯æœ5åˆ†ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³åŒ–**\n",
    "   - CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã â†’ ç™ºæ³¨æ•°é‡ã‚’ç¢ºèª â†’ ç™ºæ³¨ã‚·ã‚¹ãƒ†ãƒ ã«å…¥åŠ›\n",
    "\n",
    "2. **ãƒˆãƒƒãƒ—20å•†å“ã¯çµ¶å¯¾æ¬ å“ã•ã›ãªã„**\n",
    "   - æ¯å¤•ã€åœ¨åº«ãƒã‚§ãƒƒã‚¯\n",
    "   - ãƒ•ã‚§ãƒ¼ã‚¹1.5å€ç¢ºä¿\n",
    "   - äºˆå‚™åœ¨åº«ã‚’ç”¨æ„\n",
    "\n",
    "3. **1é€±é–“é‹ç”¨ã—ã¦ã€å®‰å…¨ä¿‚æ•°ã‚’èª¿æ•´**\n",
    "   - å»ƒæ£„ç‡5%ä»¥ä¸Š â†’ ä¿‚æ•°-0.1\n",
    "   - æ¬ å“ç‡3%ä»¥ä¸Š â†’ ä¿‚æ•°+0.1\n",
    "\n",
    "---\n",
    "\n",
    "**ã“ã‚Œã§ã€AIç™ºæ³¨äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®èª¬æ˜ã¯å®Œäº†ã§ã™ï¼**\n",
    "\n",
    "æ˜æ—¥ã‹ã‚‰å®Ÿéš›ã«é‹ç”¨ã—ã¦ã¿ã¦ãã ã•ã„ã€‚1é€±é–“å¾Œã«åŠ¹æœã‚’æ¸¬å®šã—ã€ç¶™ç¶šçš„ã«æ”¹å–„ã—ã¦ã„ãã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6sn7okpdz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================",
    "# ğŸ’¾ Step 6-3: ç™ºæ³¨è¡¨ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›",
    "# ========================================",
    "",
    "from pathlib import Path",
    "",
    "if 'forecast_result' not in globals() or forecast_result.empty:",
    "    print('[ERROR] äºˆæ¸¬çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«Step 6-2ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')",
    "else:",
    "    # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ",
    "    output_dir = Path('output')",
    "    output_dir.mkdir(exist_ok=True)",
    "    ",
    "    print('\\n' + '='*60)",
    "    print('ğŸ’¾ ç™ºæ³¨è¡¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ä¸­...')",
    "    print('='*60)",
    "    ",
    "    # ========================================",
    "    # ğŸ“„ ãƒ¡ã‚¤ãƒ³ç™ºæ³¨è¡¨ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰",
    "    # ========================================",
    "    ",
    "    # æ—¥ä»˜ç¯„å›²ã‚’å–å¾—",
    "    if 'æ—¥ä»˜' in forecast_result.columns:",
    "        # Categoricalå‹ã®å ´åˆã¯æ–‡å­—åˆ—ã«å¤‰æ›",
    "        date_col = forecast_result['æ—¥ä»˜']",
    "        if hasattr(date_col, 'cat'):  # Categoricalã®å ´åˆ",
    "            date_col = date_col.astype(str)",
    "        ",
    "        # ã‚½ãƒ¼ãƒˆã—ã¦æœ€åˆã¨æœ€å¾Œã‚’å–å¾—",
    "        dates_sorted = sorted(date_col.unique())",
    "        start_date = dates_sorted[0] if len(dates_sorted) > 0 else 'unknown'",
    "        end_date = dates_sorted[-1] if len(dates_sorted) > 0 else 'unknown'",
    "        output_filename = f'ç™ºæ³¨è¡¨_å…¨åº—èˆ—_{start_date}_to_{end_date}.csv'",
    "    else:",
    "        output_filename = 'ç™ºæ³¨è¡¨_å…¨åº—èˆ—.csv'",
    "    ",
    "    output_path = output_dir / output_filename",
    "    ",
    "    # ç™ºæ³¨è¡¨ã¨ã—ã¦å¿…è¦ãªåˆ—ã‚’é¸æŠ",
    "    order_cols = []",
    "    for col in ['æ—¥ä»˜', 'åº—èˆ—', 'å•†å“å', 'predicted_qty', 'order_qty', 'price', 'predicted_sales_amt']:",
    "        if col in forecast_result.columns:",
    "            order_cols.append(col)",
    "    ",
    "    # æ—¥æœ¬èªåˆ—åã«å¤‰æ›",
    "    order_df = forecast_result[order_cols].copy()",
    "    rename_dict = {",
    "        'æ—¥ä»˜': 'æ—¥ä»˜',",
    "        'åº—èˆ—': 'åº—èˆ—ID',",
    "        'å•†å“å': 'å•†å“ID',",
    "        'predicted_qty': 'äºˆæ¸¬è²©å£²æ•°é‡',",
    "        'order_qty': 'ç™ºæ³¨æ•°é‡',",
    "        'price': 'å˜ä¾¡',",
    "        'predicted_sales_amt': 'äºˆæ¸¬å£²ä¸Šé‡‘é¡'",
    "    }",
    "    order_df = order_df.rename(columns={k: v for k, v in rename_dict.items() if k in order_df.columns})",
    "    ",
    "    # CSVå‡ºåŠ›",
    "    order_df.to_csv(output_path, index=False, encoding='utf-8-sig')",
    "    ",
    "    print(f'\\nâœ… ãƒ¡ã‚¤ãƒ³ç™ºæ³¨è¡¨ã‚’ä¿å­˜:')",
    "    print(f'  ãƒ•ã‚¡ã‚¤ãƒ«å: {output_path}')",
    "    print(f'  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_path.stat().st_size / 1024:.1f} KB')",
    "    print(f'  ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(order_df):,} ä»¶')",
    "    ",
    "    # ========================================",
    "    # ğŸ“… æ—¥ä»˜åˆ¥CSVãƒ•ã‚¡ã‚¤ãƒ«",
    "    # ========================================",
    "    ",
    "    if 'æ—¥ä»˜' in order_df.columns:",
    "        print(f'\\nğŸ“… æ—¥ä»˜åˆ¥CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ä¸­...')",
    "        for date in sorted(order_df['æ—¥ä»˜'].unique()):",
    "            date_df = order_df[order_df['æ—¥ä»˜'] == date].copy()",
    "            date_filename = f'ç™ºæ³¨è¡¨_{date}.csv'",
    "            date_path = output_dir / date_filename",
    "            date_df.to_csv(date_path, index=False, encoding='utf-8-sig')",
    "            ",
    "            total_qty = date_df['ç™ºæ³¨æ•°é‡'].sum() if 'ç™ºæ³¨æ•°é‡' in date_df.columns else 0",
    "            total_amt = date_df['äºˆæ¸¬å£²ä¸Šé‡‘é¡'].sum() if 'äºˆæ¸¬å£²ä¸Šé‡‘é¡' in date_df.columns else 0",
    "            ",
    "            print(f'  âœ… {date_filename}: {len(date_df):,}ä»¶ | ç™ºæ³¨{total_qty:,}å€‹ | äºˆæ¸¬å£²ä¸ŠÂ¥{total_amt:,.0f}')",
    "    ",
    "    # ========================================",
    "    # ğŸª åº—èˆ—åˆ¥CSVãƒ•ã‚¡ã‚¤ãƒ«",
    "    # ========================================",
    "    ",
    "    if 'åº—èˆ—ID' in order_df.columns and order_df['åº—èˆ—ID'].nunique() > 1:",
    "        print(f'\\nğŸª åº—èˆ—åˆ¥CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ä¸­...')",
    "        for store_id in sorted(order_df['åº—èˆ—ID'].unique()):",
    "            store_df = order_df[order_df['åº—èˆ—ID'] == store_id].copy()",
    "            store_filename = f'ç™ºæ³¨è¡¨_åº—èˆ—{int(store_id)}.csv'",
    "            store_path = output_dir / store_filename",
    "            store_df.to_csv(store_path, index=False, encoding='utf-8-sig')",
    "            ",
    "            total_qty = store_df['ç™ºæ³¨æ•°é‡'].sum() if 'ç™ºæ³¨æ•°é‡' in store_df.columns else 0",
    "            total_amt = store_df['äºˆæ¸¬å£²ä¸Šé‡‘é¡'].sum() if 'äºˆæ¸¬å£²ä¸Šé‡‘é¡' in store_df.columns else 0",
    "            ",
    "            print(f'  âœ… {store_filename}: {len(store_df):,}ä»¶ | ç™ºæ³¨{total_qty:,}å€‹ | äºˆæ¸¬å£²ä¸ŠÂ¥{total_amt:,.0f}')",
    "    ",
    "    # ========================================",
    "    # ğŸ›ï¸ å•†å“åˆ¥ã‚µãƒãƒªãƒ¼ï¼ˆé«˜å›è»¢å•†å“TOP100ï¼‰",
    "    # ========================================",
    "    ",
    "    if 'å•†å“ID' in order_df.columns and 'ç™ºæ³¨æ•°é‡' in order_df.columns:",
    "        print(f'\\nğŸ›ï¸ å•†å“åˆ¥ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›ä¸­...')",
    "        ",
    "        sku_summary = order_df.groupby('å•†å“ID').agg({",
    "            'ç™ºæ³¨æ•°é‡': 'sum',",
    "            'äºˆæ¸¬å£²ä¸Šé‡‘é¡': 'sum'",
    "        }).reset_index()",
    "        sku_summary.columns = ['å•†å“ID', 'ç·ç™ºæ³¨æ•°é‡', 'ç·äºˆæ¸¬å£²ä¸Šé‡‘é¡']",
    "        sku_summary = sku_summary.nlargest(100, 'ç·ç™ºæ³¨æ•°é‡')",
    "        ",
    "        sku_summary_path = output_dir / 'å•†å“åˆ¥ã‚µãƒãƒªãƒ¼_TOP100.csv'",
    "        sku_summary.to_csv(sku_summary_path, index=False, encoding='utf-8-sig')",
    "        print(f'  âœ… å•†å“åˆ¥ã‚µãƒãƒªãƒ¼_TOP100.csv: {len(sku_summary)}ä»¶')",
    "    ",
    "    # ========================================",
    "    # ğŸ“Š å…¨ä½“ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ",
    "    # ========================================",
    "    ",
    "    print(f'\\nğŸ“Š å…¨ä½“ã‚µãƒãƒªãƒ¼:')",
    "    if 'ç™ºæ³¨æ•°é‡' in order_df.columns:",
    "        print(f'  ç·ç™ºæ³¨æ•°é‡: {order_df[\"ç™ºæ³¨æ•°é‡\"].sum():,} å€‹')",
    "    if 'äºˆæ¸¬å£²ä¸Šé‡‘é¡' in order_df.columns:",
    "        print(f'  ç·äºˆæ¸¬å£²ä¸Š: Â¥{order_df[\"äºˆæ¸¬å£²ä¸Šé‡‘é¡\"].sum():,.0f}')",
    "    if 'åº—èˆ—ID' in order_df.columns:",
    "        print(f'  å¯¾è±¡åº—èˆ—æ•°: {order_df[\"åº—èˆ—ID\"].nunique()} åº—èˆ—')",
    "    if 'å•†å“ID' in order_df.columns:",
    "        print(f'  å¯¾è±¡å•†å“æ•°: {order_df[\"å•†å“ID\"].nunique()} SKU')",
    "    if 'æ—¥ä»˜' in order_df.columns:",
    "        # æ—¥ä»˜åˆ—ã‚’datetimeã«å¤‰æ›ã—ã¦min/maxã‚’å–å¾—",
    "        try:",
    "            date_col = pd.to_datetime(order_df[\"æ—¥ä»˜\"])",
    "            print(f'  äºˆæ¸¬æœŸé–“: {date_col.min()} ï½ {date_col.max()}')",
    "        except:",
    "            # Categoricalå‹ã®å ´åˆã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã§ã‚½ãƒ¼ãƒˆ",
    "            dates = sorted(order_df[\"æ—¥ä»˜\"].unique())",
    "            if len(dates) > 0:",
    "                print(f'  äºˆæ¸¬æœŸé–“: {dates[0]} ï½ {dates[-1]}')",
    "    ",
    "    print(f'\\nâœ… ã™ã¹ã¦ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ output/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã—ã¾ã—ãŸ')",
    "    print(f'\\nğŸ’¡ ç™ºæ³¨è¡¨ã®ä½¿ã„æ–¹:')",
    "    print(f'  1. æ—¥ä»˜åˆ¥CSV: æ—¥æ¬¡ã®ç™ºæ³¨è¨ˆç”»ã«ä½¿ç”¨')",
    "    print(f'  2. åº—èˆ—åˆ¥CSV: åº—èˆ—ã”ã¨ã®ç™ºæ³¨æŒ‡ç¤ºã«ä½¿ç”¨')",
    "    print(f'  3. å•†å“åˆ¥ã‚µãƒãƒªãƒ¼: é‡ç‚¹å•†å“ã®åœ¨åº«ç®¡ç†ã«ä½¿ç”¨')",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}