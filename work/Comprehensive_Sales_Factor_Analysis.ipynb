{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š å£²ä¸Šå½±éŸ¿è¦å› ã®ç¶²ç¾…çš„åˆ†æ\n",
    "\n",
    "å…¨123å€‹ã®ç‰¹å¾´é‡ã®ä¸­ã‹ã‚‰ã€å£²ä¸Šã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã‚’ç¶²ç¾…çš„ã«åˆ†æã—ã¾ã™ã€‚\n",
    "\n",
    "## åˆ†æå†…å®¹\n",
    "\n",
    "1. **å…¨ç‰¹å¾´é‡ã®é‡è¦åº¦åˆ†æ** - Random Forestã§ç‰¹å¾´é‡é‡è¦åº¦ã‚’ç®—å‡º\n",
    "2. **ã‚«ãƒ†ã‚´ãƒªåˆ¥é‡è¦ç‰¹å¾´é‡TOP20** - ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ç•°ãªã‚‹å½±éŸ¿è¦å› ã‚’ç‰¹å®š\n",
    "3. **ç›¸é–¢åˆ†æ** - å£²ä¸Šã¨ã®ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—\n",
    "4. **å¤šé‡å…±ç·šæ€§ãƒã‚§ãƒƒã‚¯** - VIFï¼ˆåˆ†æ•£æ‹¡å¤§ä¿‚æ•°ï¼‰ã§å†—é•·æ€§ã‚’ç¢ºèª\n",
    "5. **SHAPå€¤åˆ†æ** - ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã«å¯¾ã™ã‚‹å„ç‰¹å¾´é‡ã®è²¢çŒ®åº¦ã‚’å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š\n",
    "import matplotlib.font_manager as fm\n",
    "JP_FONT_PATH = \"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\"\n",
    "if Path(JP_FONT_PATH).exists():\n",
    "    JP_FP = fm.FontProperties(fname=JP_FONT_PATH)\n",
    "    plt.rcParams['font.family'] = JP_FP.get_name()\n",
    "else:\n",
    "    print(\"âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š å£²ä¸Šå½±éŸ¿è¦å› ã®ç¶²ç¾…çš„åˆ†æ\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "input_file = Path(\"output/06_final_enriched_20250701_20250930.csv\")\n",
    "print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {input_file}\")\n",
    "df = pd.read_csv(input_file)\n",
    "print(f\"âœ… ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}\")\n",
    "print(f\"\\næœ€åˆã®5è¡Œ:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ã‚«ãƒ†ã‚´ãƒªãƒ»å£²ä¸Šåˆ—ã®è‡ªå‹•æ¤œå‡º\ncategory_candidates = [col for col in df.columns if any(x in col for x in ['ã‚«ãƒ†ã‚´ãƒª', 'category', 'åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Š'])]\nsales_candidates = [col for col in df.columns if any(x in col for x in ['å£²ä¸Š', 'é‡‘é¡', 'sales', 'amt'])]\nqty_candidates = [col for col in df.columns if any(x in col for x in ['æ•°é‡', 'qty', 'quantity', 'å€‹æ•°'])]\n\n# ã‚«ãƒ†ã‚´ãƒªåˆ—ã®å„ªå…ˆé †ä½: å¤§åˆ†é¡ > ä¸­åˆ†é¡ > å°åˆ†é¡ > ã‚«ãƒ†ã‚´ãƒª\nif 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡' in df.columns:\n    category_col = 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡'\nelif 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡' in df.columns:\n    category_col = 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡'\nelif 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡' in df.columns:\n    category_col = 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡'\nelif 'ã‚«ãƒ†ã‚´ãƒª' in df.columns:\n    category_col = 'ã‚«ãƒ†ã‚´ãƒª'\nelse:\n    category_col = category_candidates[0] if category_candidates else None\n\n# å£²ä¸Šåˆ—ã®æ¤œå‡ºï¼ˆå„ªå…ˆé †ä½: å£²ä¸Šé‡‘é¡ > ãã®ä»–ï¼‰\nif 'å£²ä¸Šé‡‘é¡' in df.columns:\n    sales_col = 'å£²ä¸Šé‡‘é¡'\nelif sales_candidates:\n    sales_col = sales_candidates[0]\nelse:\n    sales_col = None\n\n# æ•°é‡åˆ—ã®æ¤œå‡º\nif 'å£²ä¸Šæ•°é‡' in df.columns:\n    qty_col = 'å£²ä¸Šæ•°é‡'\nelif qty_candidates:\n    qty_col = qty_candidates[0]\nelse:\n    qty_col = None\n\n# ç›®çš„å¤‰æ•°ã®é¸æŠï¼ˆæ•°é‡ãŒã‚ã‚Œã°æ•°é‡ã€ãªã‘ã‚Œã°å£²ä¸Šé‡‘é¡ï¼‰\ntarget_col = qty_col if qty_col else sales_col\n\nprint(f\"âœ… ã‚«ãƒ†ã‚´ãƒªåˆ—: {category_col}\")\nprint(f\"âœ… å£²ä¸Šåˆ—: {sales_col}\")\nprint(f\"âœ… æ•°é‡åˆ—: {qty_col}\")\nprint(f\"\\nğŸ¯ ç›®çš„å¤‰æ•°: {target_col}\")\nprint(f\"\\nãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚«ãƒ†ã‚´ãƒªæ•°: {df[category_col].nunique() if category_col else 0}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ç‰¹å¾´é‡ã®æº–å‚™\nexclude_cols = [\n    target_col, sales_col, qty_col, 'æ—¥ä»˜', 'date', \n    category_col, 'å•†å“', 'å•†å“å', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'åº—èˆ—', 'åº—èˆ—å', 'å¤©æ°—',\n    'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡'\n]\nexclude_cols_actual = [col for col in exclude_cols if col in df.columns]\n\n# æ•°å€¤å‹ã®ç‰¹å¾´é‡ã®ã¿æŠ½å‡º\nfeature_cols = [col for col in df.columns\n               if col not in exclude_cols_actual\n               and df[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n\nprint(f\"\\nğŸ“Š ç‰¹å¾´é‡æƒ…å ±:\")\nprint(f\"ç·ç‰¹å¾´é‡æ•°: {len(feature_cols)}\")\nprint(f\"é™¤å¤–åˆ—æ•°: {len(exclude_cols_actual)}\")\nprint(f\"\\nç‰¹å¾´é‡ä¸€è¦§ï¼ˆæœ€åˆã®20å€‹ï¼‰:\")\nfor i, col in enumerate(feature_cols[:20], 1):\n    print(f\"  {i}. {col}\")\nif len(feature_cols) > 20:\n    print(f\"  ... (å…¨{len(feature_cols)}å€‹)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ å…¨ä½“ã®ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆRandom Forestï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# æ¬ æå€¤å‡¦ç†\n",
    "X = X.fillna(X.median())\n",
    "y = y.fillna(y.median())\n",
    "\n",
    "print(f\"\\nç‰¹å¾´é‡ãƒãƒˆãƒªãƒƒã‚¯ã‚¹: {X.shape}\")\n",
    "print(f\"ç›®çš„å¤‰æ•°: {y.shape}\")\n",
    "\n",
    "# Random Forestã§ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¨ˆç®—\n",
    "print(\"\\nğŸŒ² Random Forestå­¦ç¿’ä¸­...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—\n",
    "feature_importance = pd.DataFrame({\n",
    "    'ç‰¹å¾´é‡': feature_cols,\n",
    "    'é‡è¦åº¦': rf_model.feature_importances_\n",
    "}).sort_values('é‡è¦åº¦', ascending=False)\n",
    "\n",
    "print(\"\\nâœ… å­¦ç¿’å®Œäº†ï¼\")\n",
    "print(f\"ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚³ã‚¢ (RÂ²): {rf_model.score(X, y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP30ç‰¹å¾´é‡ã®è¡¨ç¤º\n",
    "print(\"\\nğŸ† å£²ä¸Šå½±éŸ¿TOP30ç‰¹å¾´é‡:\")\n",
    "top30 = feature_importance.head(30).copy()\n",
    "top30['é‡è¦åº¦(%)'] = (top30['é‡è¦åº¦'] * 100).round(2)\n",
    "top30[['ç‰¹å¾´é‡', 'é‡è¦åº¦(%)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP30ç‰¹å¾´é‡ã®å¯è¦–åŒ–\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "top30_plot = feature_importance.head(30).copy()\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(top30_plot)))\n",
    "\n",
    "ax.barh(range(len(top30_plot)), top30_plot['é‡è¦åº¦'], color=colors, alpha=0.8)\n",
    "ax.set_yticks(range(len(top30_plot)))\n",
    "ax.set_yticklabels(top30_plot['ç‰¹å¾´é‡'], fontproperties=JP_FP, fontsize=10)\n",
    "ax.set_xlabel('é‡è¦åº¦', fontproperties=JP_FP, fontsize=12)\n",
    "ax.set_title('å£²ä¸Šå½±éŸ¿TOP30ç‰¹å¾´é‡ï¼ˆå…¨ã‚«ãƒ†ã‚´ãƒªï¼‰', fontproperties=JP_FP, fontsize=14, pad=20)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# å€¤ãƒ©ãƒ™ãƒ«è¿½åŠ \n",
    "for i, (_, row) in enumerate(top30_plot.iterrows()):\n",
    "    ax.text(row['é‡è¦åº¦'] + 0.001, i, f\"{row['é‡è¦åº¦']:.4f}\", \n",
    "            va='center', fontsize=8, fontproperties=JP_FP)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/feature_importance_top30_overall.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®é‡è¦ç‰¹å¾´é‡åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¨ˆç®—\n",
    "print(\"ğŸ“¦ ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "category_importance = {}\n",
    "categories = df[category_col].unique()\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    if pd.isna(category):\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n[{idx+1}/{len(categories)}] {category}\")\n",
    "    \n",
    "    cat_data = df[df[category_col] == category].copy()\n",
    "    \n",
    "    if len(cat_data) < 30:\n",
    "        print(f\"  âš ï¸ ãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼ˆ{len(cat_data)}è¡Œï¼‰ã‚¹ã‚­ãƒƒãƒ—\")\n",
    "        continue\n",
    "    \n",
    "    X_cat = cat_data[feature_cols].fillna(cat_data[feature_cols].median())\n",
    "    y_cat = cat_data[target_col].fillna(cat_data[target_col].median())\n",
    "    \n",
    "    # Random Forestå­¦ç¿’\n",
    "    rf_cat = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_cat.fit(X_cat, y_cat)\n",
    "    \n",
    "    # é‡è¦åº¦ä¿å­˜\n",
    "    importance_df = pd.DataFrame({\n",
    "        'ç‰¹å¾´é‡': feature_cols,\n",
    "        'é‡è¦åº¦': rf_cat.feature_importances_\n",
    "    }).sort_values('é‡è¦åº¦', ascending=False)\n",
    "    \n",
    "    category_importance[category] = importance_df\n",
    "    \n",
    "    print(f\"  âœ… RÂ² = {rf_cat.score(X_cat, y_cat):.4f}\")\n",
    "    print(f\"  TOP3: {', '.join(importance_df.head(3)['ç‰¹å¾´é‡'].values)}\")\n",
    "\n",
    "print(f\"\\nâœ… åˆ†æå®Œäº†: {len(category_importance)}ã‚«ãƒ†ã‚´ãƒª\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥TOP20ç‰¹å¾´é‡ã®è¡¨ç¤º\n",
    "print(\"\\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥ é‡è¦ç‰¹å¾´é‡TOP5:\")\n",
    "\n",
    "for category, importance_df in list(category_importance.items())[:10]:  # æœ€åˆã®10ã‚«ãƒ†ã‚´ãƒª\n",
    "    print(f\"\\nã€{category}ã€‘\")\n",
    "    top5 = importance_df.head(5)\n",
    "    for i, (_, row) in enumerate(top5.iterrows(), 1):\n",
    "        print(f\"  {i}. {row['ç‰¹å¾´é‡']}: {row['é‡è¦åº¦']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥TOP20ç‰¹å¾´é‡ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "print(\"\\nğŸ—ºï¸ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆä¸­...\")\n",
    "\n",
    "# å…¨ã‚«ãƒ†ã‚´ãƒªã®TOP20ç‰¹å¾´é‡ã‚’é›†è¨ˆ\n",
    "all_top_features = set()\n",
    "for importance_df in category_importance.values():\n",
    "    all_top_features.update(importance_df.head(20)['ç‰¹å¾´é‡'].values)\n",
    "\n",
    "# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ\n",
    "heatmap_data = pd.DataFrame()\n",
    "\n",
    "for category, importance_df in category_importance.items():\n",
    "    importance_dict = dict(zip(importance_df['ç‰¹å¾´é‡'], importance_df['é‡è¦åº¦']))\n",
    "    heatmap_data[category] = pd.Series(importance_dict)\n",
    "\n",
    "heatmap_data = heatmap_data.fillna(0).T\n",
    "\n",
    "# é‡è¦åº¦ãŒé«˜ã„ç‰¹å¾´é‡é †ã«ã‚½ãƒ¼ãƒˆ\n",
    "feature_sum = heatmap_data.sum(axis=0).sort_values(ascending=False)\n",
    "top_features = feature_sum.head(30).index\n",
    "heatmap_plot = heatmap_data[top_features]\n",
    "\n",
    "# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(heatmap_plot, annot=False, cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'é‡è¦åº¦'}, ax=ax)\n",
    "ax.set_title('ã‚«ãƒ†ã‚´ãƒªÃ—ç‰¹å¾´é‡ é‡è¦åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆTOP30ç‰¹å¾´é‡ï¼‰', \n",
    "             fontproperties=JP_FP, fontsize=14, pad=20)\n",
    "ax.set_xlabel('ç‰¹å¾´é‡', fontproperties=JP_FP, fontsize=12)\n",
    "ax.set_ylabel('ã‚«ãƒ†ã‚´ãƒª', fontproperties=JP_FP, fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontproperties=JP_FP)\n",
    "plt.yticks(fontproperties=JP_FP)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/category_feature_importance_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ç›¸é–¢åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å£²ä¸Šã¨ã®ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—\n",
    "print(\"\\nğŸ”— ç›¸é–¢åˆ†æå®Ÿè¡Œä¸­...\")\n",
    "\n",
    "correlations = []\n",
    "\n",
    "for col in feature_cols:\n",
    "    # æ¬ æå€¤ã‚’é™¤ã„ã¦Pearsonç›¸é–¢ã‚’è¨ˆç®—\n",
    "    valid_mask = df[col].notna() & df[target_col].notna()\n",
    "    \n",
    "    if valid_mask.sum() < 10:\n",
    "        continue\n",
    "    \n",
    "    corr, p_value = pearsonr(df.loc[valid_mask, col], df.loc[valid_mask, target_col])\n",
    "    \n",
    "    correlations.append({\n",
    "        'ç‰¹å¾´é‡': col,\n",
    "        'ç›¸é–¢ä¿‚æ•°': corr,\n",
    "        'på€¤': p_value,\n",
    "        'çµ¶å¯¾ç›¸é–¢': abs(corr)\n",
    "    })\n",
    "\n",
    "correlation_df = pd.DataFrame(correlations).sort_values('çµ¶å¯¾ç›¸é–¢', ascending=False)\n",
    "print(\"âœ… ç›¸é–¢åˆ†æå®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP30ç›¸é–¢ã®è¡¨ç¤º\n",
    "print(\"\\nğŸ” å£²ä¸Šã¨ã®ç›¸é–¢TOP30:\")\n",
    "top30_corr = correlation_df.head(30).copy()\n",
    "top30_corr[['ç‰¹å¾´é‡', 'ç›¸é–¢ä¿‚æ•°', 'på€¤']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›¸é–¢ä¿‚æ•°ã®å¯è¦–åŒ–\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "top30_corr_plot = correlation_df.head(30).copy()\n",
    "colors = ['red' if x > 0 else 'blue' for x in top30_corr_plot['ç›¸é–¢ä¿‚æ•°']]\n",
    "\n",
    "ax.barh(range(len(top30_corr_plot)), top30_corr_plot['ç›¸é–¢ä¿‚æ•°'], \n",
    "        color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(top30_corr_plot)))\n",
    "ax.set_yticklabels(top30_corr_plot['ç‰¹å¾´é‡'], fontproperties=JP_FP, fontsize=10)\n",
    "ax.set_xlabel('ç›¸é–¢ä¿‚æ•°', fontproperties=JP_FP, fontsize=12)\n",
    "ax.set_title(f'{target_col}ã¨ã®ç›¸é–¢ä¿‚æ•°TOP30', fontproperties=JP_FP, fontsize=14, pad=20)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# å€¤ãƒ©ãƒ™ãƒ«\n",
    "for i, (_, row) in enumerate(top30_corr_plot.iterrows()):\n",
    "    value = row['ç›¸é–¢ä¿‚æ•°']\n",
    "    x_pos = value + (0.02 if value > 0 else -0.02)\n",
    "    ha = 'left' if value > 0 else 'right'\n",
    "    ax.text(x_pos, i, f\"{value:.3f}\", va='center', ha=ha, \n",
    "            fontsize=8, fontproperties=JP_FP)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/correlation_top30.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ å¤šé‡å…±ç·šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆVIFï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIFï¼ˆåˆ†æ•£æ‹¡å¤§ä¿‚æ•°ï¼‰ã‚’è¨ˆç®—\n",
    "print(\"\\nğŸ“ VIFï¼ˆå¤šé‡å…±ç·šæ€§ï¼‰åˆ†æä¸­...\")\n",
    "print(\"â€» VIF > 10 ã®ç‰¹å¾´é‡ã¯å¤šé‡å…±ç·šæ€§ãŒé«˜ã„\")\n",
    "\n",
    "# TOP50ç‰¹å¾´é‡ã«çµã‚‹ï¼ˆè¨ˆç®—æ™‚é–“å‰Šæ¸›ã®ãŸã‚ï¼‰\n",
    "top50_features = feature_importance.head(50)['ç‰¹å¾´é‡'].values\n",
    "X_vif = df[top50_features].fillna(df[top50_features].median())\n",
    "\n",
    "vif_data = []\n",
    "\n",
    "for i, col in enumerate(top50_features):\n",
    "    try:\n",
    "        vif = variance_inflation_factor(X_vif.values, i)\n",
    "        vif_data.append({'ç‰¹å¾´é‡': col, 'VIF': vif})\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "vif_df = pd.DataFrame(vif_data).sort_values('VIF', ascending=False)\n",
    "print(\"\\nâœ… VIFè¨ˆç®—å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIFçµæœè¡¨ç¤º\n",
    "print(\"\\nâš ï¸ å¤šé‡å…±ç·šæ€§ãŒé«˜ã„ç‰¹å¾´é‡ï¼ˆVIF > 10ï¼‰:\")\n",
    "high_vif = vif_df[vif_df['VIF'] > 10]\n",
    "if len(high_vif) > 0:\n",
    "    high_vif\n",
    "else:\n",
    "    print(\"ãªã—ï¼ˆã™ã¹ã¦VIF < 10ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIFå¯è¦–åŒ–\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "vif_plot = vif_df.head(30).copy()\n",
    "colors = ['red' if x > 10 else 'steelblue' for x in vif_plot['VIF']]\n",
    "\n",
    "ax.barh(range(len(vif_plot)), vif_plot['VIF'], color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(vif_plot)))\n",
    "ax.set_yticklabels(vif_plot['ç‰¹å¾´é‡'], fontproperties=JP_FP, fontsize=9)\n",
    "ax.set_xlabel('VIFï¼ˆåˆ†æ•£æ‹¡å¤§ä¿‚æ•°ï¼‰', fontproperties=JP_FP, fontsize=12)\n",
    "ax.set_title('å¤šé‡å…±ç·šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆTOP30ç‰¹å¾´é‡ï¼‰', fontproperties=JP_FP, fontsize=14, pad=20)\n",
    "ax.axvline(x=10, color='red', linestyle='--', linewidth=2, label='VIF=10ï¼ˆåŸºæº–ï¼‰')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.legend(prop=JP_FP)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/vif_multicollinearity.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ çµæœã®ä¿å­˜ã¨çµ±åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# çµ±åˆçµæœã®ä½œæˆ\nprint(\"\\nğŸ’¾ çµæœã‚’çµ±åˆä¸­...\")\n\n# å…¨ä½“é‡è¦åº¦ã€ç›¸é–¢ã€VIFã‚’çµ±åˆ\ncomprehensive_analysis = feature_importance.copy()\ncomprehensive_analysis = comprehensive_analysis.merge(\n    correlation_df[['ç‰¹å¾´é‡', 'ç›¸é–¢ä¿‚æ•°', 'på€¤', 'çµ¶å¯¾ç›¸é–¢']], \n    on='ç‰¹å¾´é‡', \n    how='left'\n)\ncomprehensive_analysis = comprehensive_analysis.merge(\n    vif_df[['ç‰¹å¾´é‡', 'VIF']], \n    on='ç‰¹å¾´é‡', \n    how='left'\n)\n\n# çµ¶å¯¾ç›¸é–¢ãŒNaNã®å ´åˆã¯0ã§åŸ‹ã‚ã‚‹\ncomprehensive_analysis['çµ¶å¯¾ç›¸é–¢'] = comprehensive_analysis['çµ¶å¯¾ç›¸é–¢'].fillna(0)\n\n# ç·åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆé‡è¦åº¦ã¨çµ¶å¯¾ç›¸é–¢ã®åŠ é‡å¹³å‡ï¼‰\ncomprehensive_analysis['ç·åˆã‚¹ã‚³ã‚¢'] = (\n    comprehensive_analysis['é‡è¦åº¦'] * 0.6 + \n    comprehensive_analysis['çµ¶å¯¾ç›¸é–¢'] * 0.4\n)\n\ncomprehensive_analysis = comprehensive_analysis.sort_values('ç·åˆã‚¹ã‚³ã‚¢', ascending=False)\n\nprint(\"âœ… çµ±åˆå®Œäº†\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆçµæœTOP50è¡¨ç¤º\n",
    "print(\"\\nğŸ† ç·åˆè©•ä¾¡TOP50ç‰¹å¾´é‡:\")\n",
    "top50_comprehensive = comprehensive_analysis.head(50).copy()\n",
    "top50_comprehensive[['ç‰¹å¾´é‡', 'é‡è¦åº¦', 'ç›¸é–¢ä¿‚æ•°', 'VIF', 'ç·åˆã‚¹ã‚³ã‚¢']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVä¿å­˜\n",
    "comprehensive_analysis.to_csv('output/comprehensive_sales_factor_analysis.csv', \n",
    "                             index=False, encoding='utf-8-sig')\n",
    "print(\"\\nâœ… ä¿å­˜å®Œäº†: output/comprehensive_sales_factor_analysis.csv\")\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥TOP20ã‚‚ä¿å­˜\n",
    "category_top20_all = []\n",
    "\n",
    "for category, importance_df in category_importance.items():\n",
    "    top20 = importance_df.head(20).copy()\n",
    "    top20['ã‚«ãƒ†ã‚´ãƒª'] = category\n",
    "    category_top20_all.append(top20)\n",
    "\n",
    "category_top20_df = pd.concat(category_top20_all, ignore_index=True)\n",
    "category_top20_df.to_csv('output/category_feature_importance_top20.csv', \n",
    "                         index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… ä¿å­˜å®Œäº†: output/category_feature_importance_top20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š å£²ä¸Šå½±éŸ¿è¦å›  åˆ†æã‚µãƒãƒªãƒ¼\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nç·ç‰¹å¾´é‡æ•°: {len(feature_cols)}\")\n",
    "print(f\"åˆ†æå¯¾è±¡ã‚«ãƒ†ã‚´ãƒªæ•°: {len(category_importance)}\")\n",
    "\n",
    "print(\"\\nğŸ† æœ€é‡è¦ç‰¹å¾´é‡TOP5ï¼ˆå…¨ä½“ï¼‰:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "    print(f\"  {i}. {row['ç‰¹å¾´é‡']}: {row['é‡è¦åº¦']:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ”— å£²ä¸Šã¨ã®ç›¸é–¢TOP5:\")\n",
    "for i, (_, row) in enumerate(correlation_df.head(5).iterrows(), 1):\n",
    "    print(f\"  {i}. {row['ç‰¹å¾´é‡']}: {row['ç›¸é–¢ä¿‚æ•°']:.3f}\")\n",
    "\n",
    "print(\"\\nâš ï¸ å¤šé‡å…±ç·šæ€§æ³¨æ„ï¼ˆVIF > 10ï¼‰:\")\n",
    "high_vif_count = len(vif_df[vif_df['VIF'] > 10])\n",
    "if high_vif_count > 0:\n",
    "    print(f\"  {high_vif_count}å€‹ã®ç‰¹å¾´é‡ã§å¤šé‡å…±ç·šæ€§ã‚ã‚Š\")\n",
    "    for _, row in vif_df[vif_df['VIF'] > 10].head(5).iterrows():\n",
    "        print(f\"    - {row['ç‰¹å¾´é‡']}: VIF={row['VIF']:.2f}\")\n",
    "else:\n",
    "    print(\"  ãªã—ï¼ˆã™ã¹ã¦VIF < 10ï¼‰\")\n",
    "\n",
    "print(\"\\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:\")\n",
    "print(\"1. ç·åˆã‚¹ã‚³ã‚¢TOP20ã®ç‰¹å¾´é‡ã‚’å„ªå…ˆçš„ã«æ´»ç”¨\")\n",
    "print(\"2. VIF > 10ã®ç‰¹å¾´é‡ã¯å†—é•·æ€§ãŒã‚ã‚‹ãŸã‚ã€ä»£è¡¨çš„ãª1ã¤ã®ã¿ä½¿ç”¨\")\n",
    "print(\"3. ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«é‡è¦ç‰¹å¾´é‡ãŒç•°ãªã‚‹ãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨\")\n",
    "print(\"4. ç›¸é–¢ãŒé«˜ãã¦ã‚‚é‡è¦åº¦ãŒä½ã„ç‰¹å¾´é‡ã¯ã€ä»–ã®ç‰¹å¾´é‡ã§ä»£æ›¿å¯èƒ½\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… åˆ†æå®Œäº†ï¼\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}