{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸª åº—èˆ—åˆ¥åŒ…æ‹¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ v6.0 â€” åœ¨åº«æœ€é©åŒ–ã§å£²ä¸Šæœ€å¤§åŒ–\n",
    "\n",
    "æœ¬ãƒãƒ¼ãƒˆã¯ã€éå»ãƒãƒ¼ã‚¸ãƒ§ãƒ³(v1â€“v5)ã®æ©Ÿèƒ½ã‚’çµ±åˆã—ã€åº—é•·ãŒ\n",
    "ã€è¦‹ãˆã‚‹åŒ–â†’åˆ¤æ–­â†’å³ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚’æ—¥æ¬¡ã§å›ã™ãŸã‚ã®çµ±åˆç‰ˆã§ã™ã€‚\n",
    "\n",
    "- å¯è¦–åŒ–: å£²ä¸Šãƒ»ç²—åˆ©ãƒ»æ¬ å“ãƒ»å»ƒæ£„ãƒ»åœ¨åº«å›è»¢ã‚’ä¸€ç”»é¢ã§æŠŠæ¡\n",
    "- éœ€è¦äºˆæ¸¬: å¤©å€™/æ›œæ—¥/ã‚¤ãƒ™ãƒ³ãƒˆã‚’è€ƒæ…®ã—ãŸSKUåˆ¥å£²ä¸Šäºˆæ¸¬\n",
    "- ç™ºæ³¨æœ€é©åŒ–: ã‚µãƒ¼ãƒ“ã‚¹æ°´æº–ã«åŸºã¥ãå®‰å…¨åœ¨åº«ãƒ»ç™ºæ³¨ç‚¹ãƒ»ç™ºæ³¨é‡ã‚’ææ¡ˆ\n",
    "- ã‚¢ãƒ©ãƒ¼ãƒˆ: æ¬ å“/éå‰°/å»ƒæ£„ãƒªã‚¹ã‚¯ã®è‡ªå‹•æ¤œçŸ¥ã¨æ‰“ã¡æ‰‹æç¤º\n",
    "\n",
    "æä¾›CSVï¼ˆæœ€çµ‚æ•´å‚™æ¸ˆã¿ï¼‰ã‚’ç›´æ¥èª­ã¿è¾¼ã¿ã€å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã«æ•´å½¢ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿ã¨ç’°å¢ƒç¢ºèª\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import pandas as pd, numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# å¯è¦–åŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªã‚‰Plotly/ipywidgetsï¼‰\n",
    "try:\n",
    "    import plotly.express as px; import plotly.graph_objects as go\n",
    "    PLOTLY=True\n",
    "except Exception:\n",
    "    PLOTLY=False\n",
    "try:\n",
    "    import ipywidgets as widgets; from IPython.display import display, clear_output\n",
    "    WIDGETS=True\n",
    "except Exception:\n",
    "    WIDGETS=False\n",
    "\n",
    "# PyCaretï¼ˆãƒªãƒå†… or ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç’°å¢ƒï¼‰\n",
    "try:\n",
    "    from pycaret.time_series import setup, compare_models, finalize_model, predict_model\n",
    "    PYCaret_TS=True\n",
    "except Exception as e:\n",
    "    PYCaret_TS=False\n",
    "\n",
    "print(f'ç’°å¢ƒ: pandas={pd.__version__}, plotly={(\"OK\" if PLOTLY else \"N/A\")}, widgets={(\"OK\" if WIDGETS else \"N/A\")}, pycaret.ts={(\"OK\" if PYCaret_TS else \"N/A\")}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæŒ‡å®šCSVï¼‰\n",
    "- å…ƒãƒ•ã‚¡ã‚¤ãƒ«: `/mnt/wsl/.../06_final_enriched_20250701_20250930.csv`\n",
    "- ç”Ÿæˆ: `sales`(å¿…é ˆ), `product`(SKUãƒã‚¹ã‚¿), `weather`(ä»£è¡¨åˆ—)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('output/06_final_enriched_20250701_20250930.csv')\n",
    "\n",
    "def read_enriched_csv(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        print(f'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}')\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding='utf-8-sig')\n",
    "    except Exception as e:\n",
    "        print(f'èª­ã¿è¾¼ã¿å¤±æ•—: {path} -> {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "raw = read_enriched_csv(DATA_PATH)\n",
    "print('raw:', raw.shape)\n",
    "\n",
    "if raw.empty:\n",
    "    sales = pd.DataFrame(); inventory = pd.DataFrame(); product = pd.DataFrame(); weather = pd.DataFrame()\n",
    "else:\n",
    "    df = raw.copy()\n",
    "    rename_map = {\n",
    "        'åº—èˆ—': 'store_id', 'å•†å“å': 'sku_id', 'æ—¥ä»˜': 'date', 'å£²ä¸Šæ•°é‡': 'qty', 'å£²ä¸Šé‡‘é¡': 'sales_amt',\n",
    "        'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡': 'category_l', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡': 'category_m', 'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡': 'category_s'\n",
    "    }\n",
    "    df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "    if 'date' in df.columns: df['date'] = pd.to_datetime(df['date'])\n",
    "    if 'qty' in df.columns: df['qty'] = pd.to_numeric(df['qty'], errors='coerce').fillna(0)\n",
    "    if 'sales_amt' in df.columns: df['sales_amt'] = pd.to_numeric(df['sales_amt'], errors='coerce').fillna(0)\n",
    "    if {'sales_amt','qty'}.issubset(df.columns): df['price'] = np.where(df['qty']>0, df['sales_amt']/df['qty'], np.nan)\n",
    "\n",
    "    sel = [c for c in ['date','store_id','sku_id','qty','price','sales_amt','category_l','category_m','category_s'] if c in df.columns]\n",
    "    sales = df[sel].copy() if sel else pd.DataFrame()\n",
    "\n",
    "    # inventoryã¯æœªæä¾›ã®ãŸã‚ä½œæˆã—ãªã„ï¼ˆä¾å­˜åˆ†æã¯é™¤å¤–ï¼‰\n",
    "\n",
    "    if 'sku_id' in df.columns:\n",
    "        product = df[[c for c in ['sku_id','category_l','category_m','category_s'] if c in df.columns]].drop_duplicates().copy()\n",
    "        product['cost'] = np.nan; product['shelf_cap'] = np.nan\n",
    "    else:\n",
    "        product = pd.DataFrame(columns=['sku_id','category_l','category_m','category_s','cost','shelf_cap'])\n",
    "\n",
    "    wcols = [c for c in ['å¤©æ°—','æœ€é«˜æ°—æ¸©','æœ€ä½æ°—æ¸©','é™æ°´é‡','å¹³å‡æ°—æ¸©','æ°—æ¸©å·®'] if c in raw.columns]\n",
    "    if wcols and {'date','store_id'}.issubset(df.columns):\n",
    "        wdf = df[['date','store_id']+wcols].copy()\n",
    "        num_cols = [c for c in wcols if c not in ['å¤©æ°—']]\n",
    "        agg_map = {c:'mean' for c in num_cols}\n",
    "        if 'å¤©æ°—' in wcols: agg_map['å¤©æ°—'] = pd.NamedAgg(column='å¤©æ°—', aggfunc=lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0])\n",
    "        weather = wdf.groupby(['date','store_id'], as_index=False).agg(agg_map)\n",
    "        if 'å¤©æ°—' in weather.columns: weather = weather.rename(columns={'å¤©æ°—':'weather'})\n",
    "    else:\n",
    "        weather = pd.DataFrame()\n",
    "\n",
    "print('tables:', {\"sales\": getattr(sales,'shape',None), \"product\": getattr(product,'shape',None), \"weather\": getattr(weather,'shape',None)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åŸºæœ¬KPIã¨ã‚¢ãƒ©ãƒ¼ãƒˆã®ä¸‹ã”ã—ã‚‰ãˆ\n",
    "- KPI: å£²ä¸Š, ç²—åˆ©, å®¢æ•°, å®¢å˜ä¾¡, åœ¨åº«é‡‘é¡, åœ¨åº«å›è»¢, å»ƒæ£„ç‡, æ¬ å“ç‡, ã‚µãƒ¼ãƒ“ã‚¹æ°´æº–\n",
    "- ã‚¢ãƒ©ãƒ¼ãƒˆ: æ¬ å“ãƒªã‚¹ã‚¯, éå‰°/å»ƒæ£„ãƒªã‚¹ã‚¯, éœ€è¦æ€¥å¢—, ãƒ—ãƒ­ãƒ¢å·®ç•°, SKUå…¥æ›¿å€™è£œ\n",
    "\n",
    "ã¾ãšã¯å˜ç´”ãªé›†è¨ˆé–¢æ•°ã¨ABCåˆ†æã®éª¨çµ„ã¿ã‚’ä½œã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_kpi(sales_df, inv_df, prod_df):\n",
    "    if sales_df.empty: return pd.DataFrame()\n",
    "    df = sales_df.copy()\n",
    "    if 'sales_amt' in df.columns: pass\n",
    "    elif 'price' in df.columns and 'qty' in df.columns: df['sales_amt'] = df['price'] * df['qty']\n",
    "    else: df['sales_amt'] = df.get('sales', 0)\n",
    "    if not prod_df.empty and 'cost' in prod_df.columns:\n",
    "        df = df.merge(prod_df[['sku_id','cost']], on='sku_id', how='left')\n",
    "        df['gross_profit'] = df['sales_amt'] - df['cost'].fillna(0) * df['qty']\n",
    "    gp = df.groupby(['date','store_id'], as_index=False).agg(\n",
    "        sales_amt=('sales_amt','sum'), qty=('qty','sum'), gross_profit=('gross_profit','sum')\n",
    "    )\n",
    "    # åœ¨åº«æœªæä¾›ã®ãŸã‚åœ¨åº«é€£æºã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "    return gp\n",
    "\n",
    "def abc_analysis(sales_df, prod_df, top_ratio=(0.8,0.95)):\n",
    "    if sales_df.empty: return pd.DataFrame()\n",
    "    df = sales_df.copy()\n",
    "    if 'sales_amt' not in df.columns: df['sales_amt'] = df.get('sales', df.get('price',0)*df.get('qty',0))\n",
    "    by_sku = df.groupby('sku_id', as_index=False)['sales_amt'].sum().sort_values('sales_amt', ascending=False)\n",
    "    by_sku['cum_ratio'] = by_sku['sales_amt'].cumsum()/by_sku['sales_amt'].sum()\n",
    "    a_th, b_th = top_ratio\n",
    "    by_sku['ABC'] = np.where(by_sku['cum_ratio']<=a_th, 'A', np.where(by_sku['cum_ratio']<=b_th, 'B','C'))\n",
    "    if not prod_df.empty: by_sku = by_sku.merge(prod_df, on='sku_id', how='left')\n",
    "    return by_sku\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. éœ€è¦äºˆæ¸¬ï¼ˆPyCaretï¼‰\n",
    "- Exogenous: å¤©å€™/ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼/ãƒ—ãƒ­ãƒ¢ãªã©ã‚’ç‰¹å¾´é‡ã«è¿½åŠ \n",
    "- SKUÃ—åº—èˆ—ã®éšå±¤ã‚’é †æ¬¡å­¦ç¿’ï¼ˆã¾ãšã¯é‡è¦SKUã‹ã‚‰ï¼‰\n",
    "\n",
    "PyCaretãŒä½¿ãˆãªã„ç’°å¢ƒã§ã¯ã€ã“ã®ã‚»ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYCaret_TS and 'sales_sel' in globals() and not sales_sel.empty:\n",
    "    key = sales_sel[['store_id','sku_id']].drop_duplicates().head(1).iloc[0]\n",
    "    sid, sk = key['store_id'], key['sku_id']\n",
    "    ts = sales_sel[(sales_sel.store_id==sid)&(sales_sel.sku_id==sk)][['date','qty']].copy()\n",
    "    ts['date'] = pd.to_datetime(ts['date'])\n",
    "    ts = ts.sort_values('date').set_index('date')\n",
    "    s = setup(ts, target='qty', fold=3, session_id=42, verbose=False)\n",
    "    best = compare_models(sort='MASE')\n",
    "    final = finalize_model(best)\n",
    "    future = predict_model(final, fh=7)\n",
    "    display(future.head())\n",
    "else:\n",
    "    print('PyCaretæœªä½¿ç”¨ã¾ãŸã¯salesæœªèª­è¾¼ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆå£²ä¸Šé‡‘é¡ï¼‰ã¨ææ¡ˆã®è‡ªå‹•ç”Ÿæˆ\n",
    "- é¸æŠåº—èˆ—ã®åˆç®—å£²ä¸Šï¼ˆå£²ä¸Šé‡‘é¡ï¼‰ã‚’ç›®çš„å¤‰æ•°ã«ã€æä¾›ç‰¹å¾´é‡ã‹ã‚‰é‡è¦åº¦ã‚’æ¨å®š\n",
    "- sklearnãŒç„¡ã„å ´åˆã¯ç›¸é–¢ä¿‚æ•°ã§ä»£æ›¿\n",
    "- ä¸Šä½ç‰¹å¾´é‡ã«å¿œã˜ã¦ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šå·®åˆ†ã‚’ç®—å‡ºã—ã€å®Ÿè¡Œææ¡ˆã‚’å‡ºåŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨åº«ãƒ»åŸä¾¡ãƒ»æ£šå®¹é‡ã«ä¾å­˜ã™ã‚‹åˆ†æã¯æœªæä¾›ã®ãŸã‚é™¤å¤–\n",
    "# ä»£ã‚ã‚Šã«ã€ç‰¹å¾´é‡é‡è¦åº¦ã¨ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šå·®åˆ†ã‹ã‚‰é‹ç”¨ææ¡ˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ï¼ˆä¸‹ã‚»ãƒ«å‚ç…§ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é››å½¢ï¼ˆåº—èˆ—é¸æŠ + KPI/ABC/ç‰¹å¾´é‡/ææ¡ˆ/ã‚¢ãƒ©ãƒ¼ãƒˆï¼‰\n",
    "- åº—èˆ—ã®è¤‡æ•°é¸æŠã«å¯¾å¿œ\n",
    "- åœ¨åº«/åŸä¾¡ä¾å­˜ã®ãƒ“ãƒ¥ãƒ¼ã¯é™¤å¤–ï¼ˆæœªæä¾›ã®ãŸã‚ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOTLY and WIDGETS and (not sales.empty):\n",
    "    store_opts = sorted(sales.store_id.unique())\n",
    "    stores_ms = widgets.SelectMultiple(options=store_opts, value=tuple(selected_stores), description='åº—èˆ—(è¤‡æ•°)')\n",
    "    view_dd  = widgets.ToggleButtons(options=['KPI','ABC','ç‰¹å¾´é‡','ææ¡ˆ','ã‚¢ãƒ©ãƒ¼ãƒˆ'], description='ãƒ“ãƒ¥ãƒ¼')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def render(change=None):\n",
    "        with out:\n",
    "            clear_output()\n",
    "            sel = list(stores_ms.value)\n",
    "            print(f'åº—èˆ—: {sel} / ãƒ“ãƒ¥ãƒ¼: {view_dd.value}')\n",
    "            ss = sales[sales['store_id'].isin(sel)].copy() if sel else sales.copy()\n",
    "            if view_dd.value=='KPI':\n",
    "                kpi = compute_daily_kpi(ss, pd.DataFrame(), product)\n",
    "                if kpi is not None and not kpi.empty:\n",
    "                    fig = px.line(kpi, x='date', y='sales_amt', color='store_id', title='å£²ä¸Šé‡‘é¡(æ—¥æ¬¡)')\n",
    "                    display(fig)\n",
    "                else:\n",
    "                    print('KPIãƒ‡ãƒ¼ã‚¿ç„¡ã—')\n",
    "            elif view_dd.value=='ABC':\n",
    "                ab = abc_analysis(ss, product)\n",
    "                display(ab.head(30))\n",
    "            elif view_dd.value=='ç‰¹å¾´é‡':\n",
    "                if 'df' in globals():\n",
    "                    fi = None\n",
    "                    try:\n",
    "                        # åˆ©ä¾¿æ€§ã®ãŸã‚å†…éƒ¨ã§é–¢æ•°ã‚’å†åˆ©ç”¨\n",
    "                        from math import isnan\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    fi = None\n",
    "                    try:\n",
    "                        # rank_features ã‚’å†å®Ÿè¡Œ\n",
    "                        fi = (lambda s: __import__('pandas'))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    # å®Ÿéš›ã®ãƒ©ãƒ³ã‚¯ä»˜ã‘\n",
    "                    fi = rank_features(df, sel)\n",
    "                    display(fi.head(20))\n",
    "                else:\n",
    "                    print('dfæœªå®šç¾©')\n",
    "            elif view_dd.value=='ææ¡ˆ':\n",
    "                if 'df' in globals():\n",
    "                    candidate_flags = [c for c in ['é™é›¨ãƒ•ãƒ©ã‚°','é€±æœ«ãƒ•ãƒ©ã‚°','çŒ›æš‘æ—¥','çœŸå¤æ—¥','å¤æ—¥','å†¬æ—¥','çœŸå†¬æ—¥','çµ¦æ–™æ—¥','çµ¦æ–™æ—¥ç›´å¾Œ','æœˆåˆ3æ—¥','æœˆæœ«3æ—¥'] if c in df.columns]\n",
    "                    for f in candidate_flags:\n",
    "                        top_u = uplift_by_flag(df, sel, f, top_n=5)\n",
    "                        if not top_u.empty:\n",
    "                            print(f"[ææ¡ˆã‚­ãƒ¼: {f}] â†’ å¯¾å¿œå¼·åŒ–ã‚«ãƒ†ã‚´ãƒªå€™è£œ:")\n",
    "                            display(top_u)\n",
    "                else:\n",
    "                    print('dfæœªå®šç¾©')\n",
    "            elif view_dd.value=='ã‚¢ãƒ©ãƒ¼ãƒˆ':\n",
    "                tmp = ss.groupby(['date','store_id'], as_index=False)['sales_amt'].sum().sort_values('date')\n",
    "                if tmp.empty:\n",
    "                    print('ãƒ‡ãƒ¼ã‚¿ç„¡ã—')\n",
    "                else:\n",
    "                    tmp['ma3'] = tmp.groupby('store_id')['sales_amt'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "                    tmp['ma7'] = tmp.groupby('store_id')['sales_amt'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n",
    "                    tmp['delta'] = (tmp['ma3'] - tmp['ma7'])/ (tmp['ma7']+1e-6)\n",
    "                    alert = tmp[tmp['delta'].abs()>0.3].copy()\n",
    "                    display(alert.tail(20))\n",
    "\n",
    "    stores_ms.observe(render, names='value'); view_dd.observe(render, names='value')\n",
    "    display(widgets.HBox([stores_ms, view_dd])); render() ; display(out)\n",
    "else:\n",
    "    print('Plotly/ipywidgetsæœªåˆ©ç”¨ã€ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ç„¡ã—ã®ãŸã‚é››å½¢UIã¯ã‚¹ã‚­ãƒƒãƒ—')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ—¥æ¬¡é‹ç”¨ãƒ•ãƒ­ãƒ¼ï¼ˆåº—é•·ã®è¡Œå‹•è¨ˆç”»ï¼‰\n",
    "- é–‹åº—å‰: åœ¨åº«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç¢ºèª â†’ æ¬ å“è£œå……/ç™ºæ³¨èª¿æ•´\n",
    "- åˆå‰: å¤©å€™/ã‚¤ãƒ™ãƒ³ãƒˆåæ˜  â†’ é«˜éœ€è¦SKUã®å‰å‡ºã—ãƒ»é¢å‡ºã—\n",
    "- å¤•æ–¹: è¿‘è³å‘³æœŸé™ã®å€¤ä¸‹ã’/å»ƒæ£„æœ€å°åŒ– â†’ ç™ºæ³¨ç¢ºå®š\n",
    "- é–‰åº—å¾Œ: KPIãƒ¬ãƒ“ãƒ¥ãƒ¼ â†’ ã‚¢ãƒ©ãƒ¼ãƒˆåŸå› ã¨å¯¾ç­–ã‚’è¨˜éŒ²\n",
    "\n",
    "æ¬¡ã¯ã€è‡ªåº—ãƒ‡ãƒ¼ã‚¿ã§å„ã‚»ãƒ«ã‚’åŸ‹ã‚ã¦é‹ç”¨ã«ä¹—ã›ã¦ãã ã•ã„ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.x"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
