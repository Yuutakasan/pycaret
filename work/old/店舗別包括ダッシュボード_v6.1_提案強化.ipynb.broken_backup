{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸª åº—èˆ—åˆ¥åŒ…æ‹¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ v6.1 â€” è¤‡æ•°åº—èˆ—é¸æŠãƒ»ç‰¹å¾´é‡ææ¡ˆå¼·åŒ–\n",
    "\n",
    "- æŒ‡å®šCSVã‚’èª­ã¿è¾¼ã¿ã€å£²ä¸Šã«åŠ¹ãç‰¹å¾´é‡ã‚’ç‰¹å®šã—ã€åº—èˆ—é¸æŠã«å¿œã˜ãŸææ¡ˆã‚’è‡ªå‹•ç”Ÿæˆ\n",
    "- åœ¨åº«(on_hand)/åŸä¾¡(cost)/æ£šå®¹é‡ã¯æœªæä¾› â†’ ä¾å­˜åˆ†æã¯é™¤å¤–\n",
    "- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¯ KPI / ABC / ç‰¹å¾´é‡ / ææ¡ˆ / ã‚¢ãƒ©ãƒ¼ãƒˆ ã‚’åˆ‡æ›¿\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## åº—é•·ã®ä½¿ã„æ–¹ï¼ˆæ„æ€æ±ºå®šã‚¬ã‚¤ãƒ‰)\n",
    "ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¯ã€è¦‹ã‚‹â†’åˆ¤æ–­â†’å³ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã®é †ã«ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚æ¯æ—¥5ã€œ10åˆ†ã§ä¸‹è¨˜ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "### 1) KPIï¼ˆå…¨ä½“å‚¾å‘ã®æŠŠæ¡ï¼š1åˆ†ï¼‰\n",
    "- ãƒã‚§ãƒƒã‚¯: å£²ä¸Šãƒ»å®¢æ•°ãƒ»å®¢å˜ä¾¡ã®æ¨ç§»ã€‚æ˜¨æ—¥/ä¸€æ˜¨æ—¥ã¨æ¯”ã¹ã¦å¤§ããä¸Šä¸‹ã—ã¦ã„ãªã„ã‹ã€‚\n",
    "- è¡Œå‹•: ä¸‹æŒ¯ã‚Œæ™‚ã¯æ¬¡ã®ã€ã‚¢ãƒ©ãƒ¼ãƒˆã€ã€ææ¡ˆã€ã§åŸå› ã¨æ‰“ã¡æ‰‹ã‚’ç¢ºèªã—ã€è©²å½“ã‚«ãƒ†ã‚´ãƒªã®é¢å‡ºã—/ãƒ•ã‚§ãƒ¼ã‚¹å¢—ã‚„å‰å‡ºã—æ™‚é–“ã®å‰å€’ã—ã‚’å®Ÿæ–½ã€‚\n",
    "\n",
    "### 2) ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆæ€¥å¤‰ã®æ—©æœŸå¯¾å¿œï¼š1ã€œ2åˆ†ï¼‰\n",
    "- å®šç¾©: å£²ä¸Šã®3æ—¥ç§»å‹•å¹³å‡ã¨7æ—¥ç§»å‹•å¹³å‡ã®ä¹–é›¢ãŒÂ±30%ã‚’è¶…ãˆãŸåº—èˆ—æ—¥ã€‚\n",
    "- è¡Œå‹•: ä¸ŠæŒ¯ã‚Œâ†’è©²å½“ã‚«ãƒ†ã‚´ãƒªã®ãƒ•ã‚§ãƒ¼ã‚¹/åœ¨åº«é¢ï¼ˆå‰å‡ºã—ï¼‰ã‚’å¢—ã‚„ã™ã€‚ä¸‹æŒ¯ã‚Œâ†’é™³åˆ—å ´æ‰€ã‚„å°ç·šã®è¦‹ç›´ã—ãƒ»å€¤é ƒè¨´æ±‚ï¼ˆã®ã¡ã®è¦‹åˆ‡ã‚ŠåŸºæº–ã‚’èª¿æ•´ï¼‰ã€‚\n",
    "\n",
    "### 3) ææ¡ˆï¼ˆä»Šæ—¥ã®æ‰“ã¡æ‰‹ï¼š2ã€œ3åˆ†ï¼‰\n",
    "- ãƒ­ã‚¸ãƒƒã‚¯: å¤©å€™ãƒ»æ›œæ—¥ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆç­‰ã®ãƒ•ãƒ©ã‚°ã”ã¨ã«ã€å£²ä¸ŠãŒä¸ŠæŒ¯ã‚Œã—ã‚„ã™ã„ã‚«ãƒ†ã‚´ãƒªã‚’æç¤ºã€‚\n",
    "- è¡Œå‹•: ä¸Šä½ã‚«ãƒ†ã‚´ãƒªã«å¯¾ã—ã¦ã€æ™‚é–“å¸¯åˆ¥ã®å‰å‡ºã—/ãƒ•ã‚§ãƒ¼ã‚¹å¢—/å°ç·šå¼·åŒ–ã‚’å®Ÿè¡Œã€‚ä¾‹:\n",
    "  - é™é›¨ãƒ•ãƒ©ã‚°: æ¸©ã‹ã„ç·èœ/ã‚«ãƒƒãƒ—éºº/ãƒ›ãƒƒãƒˆé£²æ–™/ä¸­è¯ã¾ã‚“ï¼ˆå…¥å£å´/ãƒ¬ã‚¸æ¨ªã®å°ç·šå¼·åŒ–ï¼‰\n",
    "  - çŒ›æš‘æ—¥/çœŸå¤æ—¥: å†·é£²æ–™/ã‚¢ã‚¤ã‚¹/ãƒãƒ«ãƒ‰ãƒ‡ã‚¶ãƒ¼ãƒˆï¼ˆå†·ã‚±ãƒ¼ã‚¹ã®ãƒ•ã‚§ãƒ¼ã‚¹å¢—ã€æ°·/ä¿å†·å“ã®è¨´æ±‚ï¼‰\n",
    "  - é€±æœ«: å¼å½“/éºº/ãƒ‡ã‚¶ãƒ¼ãƒˆï¼ˆæ˜¼ãƒ»å¤•ãƒ”ãƒ¼ã‚¯å‰ã®å‰å‡ºã—å¼·åŒ–ï¼‰\n",
    "  - çµ¦æ–™æ—¥/çµ¦æ–™æ—¥ç›´å¾Œ: é«˜å˜ä¾¡å¼å½“/ã‚¹ã‚¤ãƒ¼ãƒ„ï¼ˆå¤•æ–¹æ‰‹å‰ã§ã®åšã‚é™³åˆ—ï¼‰\n",
    "  - æœˆåˆ3æ—¥: ä¸»åŠ›å®šç•ªã®é¢ç¢ºä¿ï¼ˆç™ºæ³¨å¼·ã‚ã®åˆ¤æ–­ææ–™ã«ï¼‰\n",
    "  - æœˆæœ«3æ—¥: å€¤é ƒå“/ç¯€ç´„è¨´æ±‚ï¼ˆä¾¡æ ¼ãƒãƒƒãƒ—/ã‚¯ãƒ­ã‚¹MDï¼‰\n",
    "\n",
    "### 4) ABCï¼ˆæ£šã®é…åˆ†èª¿æ•´ï¼š2åˆ†ï¼‰\n",
    "- A: å£²ä¸Š80%ã‚’ä½œã‚‹ä¸»åŠ›ã€‚ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æœ€å„ªå…ˆã§ç¢ºä¿ã—ã€æ¬ å“ã•ã›ãªã„ï¼ˆå‰å‡ºã—æ™‚é–“ã‚’å‰å€’ã—ï¼‰ã€‚\n",
    "- B: è£œå®Œã€‚ãƒ”ãƒ¼ã‚¯å‰è£œå……ã¨è¦‹ã›æ–¹ã§å·®ã‚’å‡ºã™ã€‚\n",
    "- C: åœ§ç¸®/å…¥æ›¿å€™è£œã€‚å£²å ´ã‚¹ãƒšãƒ¼ã‚¹ã‚’A/Bã¸å¯„ã›ã‚‹ã€‚\n",
    "\n",
    "### æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆä¾‹ï¼‰\n",
    "- [ ] KPIã§ä¸‹æŒ¯ã‚Œã¯ãªã„ã‹â†’ã‚ã‚‹å ´åˆã¯ã€ã‚¢ãƒ©ãƒ¼ãƒˆã€ã€ææ¡ˆã€ã‚’å„ªå…ˆç¢ºèª\n",
    "- [ ] ä»Šæ—¥ã®ææ¡ˆã‚­ãƒ¼ï¼ˆé™é›¨/çŒ›æš‘/é€±æœ«/çµ¦æ–™æ—¥ãªã©ï¼‰ã¨ä¸Šä½ã‚«ãƒ†ã‚´ãƒªã‚’ãƒ¡ãƒ¢\n",
    "- [ ] é–‹åº—å‰: ä¸Šä½ã‚«ãƒ†ã‚´ãƒªã®é¢å‡ºã—/ãƒ•ã‚§ãƒ¼ã‚¹å¢—ï¼ˆå…¥å£/ãƒ¬ã‚¸æ¨ª/ç«¯å°ç·šï¼‰\n",
    "- [ ] æ˜¼ãƒ”ãƒ¼ã‚¯å‰ï¼ˆã€œ11æ™‚ï¼‰: è£œå……/å‰å‡ºã—å¼·åŒ–\n",
    "- [ ] å¤•ãƒ”ãƒ¼ã‚¯å‰ï¼ˆã€œ17æ™‚ï¼‰: è£œå……/å‰å‡ºã—å¼·åŒ–\n",
    "- [ ] é–‰åº—å‰: å€¤é ƒè¨´æ±‚/è¦‹åˆ‡ã‚Šï¼ˆåœ¨åº«é€£å‹•ã¯æœªå®Ÿè£…ã®ãŸã‚åˆ¤æ–­åŸºæº–ã‚’åº—èˆ—é‹ç”¨ã§ï¼‰\n",
    "\n",
    "### è£œè¶³\n",
    "- æœ¬ã‚·ãƒ¼ãƒˆã¯åœ¨åº«ãƒ»åŸä¾¡ãªã—ã®å‰æã§ã™ã€‚æ¬ å“/å»ƒæ£„/ç²—åˆ©ã®æœ€é©åŒ–ã¯åˆ¥ãƒãƒ¼ãƒˆï¼ˆåœ¨åº«é€£å‹•ï¼‰ã¨é€£æºã‚’æ¤œè¨ã€‚\n",
    "- ç‰¹å¾´é‡ï¼ˆè¦å› ï¼‰ã®ä¸Šä½ã‚’ã€æ˜æ—¥ã€ã®æ‰“ã¡æ‰‹ï¼ˆé™³åˆ—/è²©ä¿ƒ/å°ç·šï¼‰ã¸åæ˜ ã—ã€ç¿Œæ—¥ã®KPIæ”¹å–„ã«ç¹‹ã’ã¦ãã ã•ã„ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒª",
    "import warnings; warnings.filterwarnings('ignore')",
    "import pandas as pd, numpy as np",
    "from pathlib import Path",
    "import font_setup  # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ/Plotlyãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
    "",
    "try:",
    "    import plotly.express as px; import plotly.graph_objects as go",
    "    PLOTLY=True",
    "except Exception:",
    "    PLOTLY=False",
    "try:",
    "    import ipywidgets as widgets; from IPython.display import display, clear_output",
    "    WIDGETS=True",
    "except Exception:",
    "    WIDGETS=False",
    "try:",
    "    from sklearn.ensemble import RandomForestRegressor",
    "    SK_OK=True",
    "except Exception:",
    "    SK_OK=False",
    "",
    "# ========================================",
    "# ğŸš€ GPUæ¤œå‡ºã¨è¨­å®š",
    "# ========================================",
    "print('='*60)",
    "print('ğŸ–¥ï¸ GPUæ¤œå‡º')",
    "print('='*60)",
    "",
    "GPU_AVAILABLE = False",
    "GPU_DEVICE = 'cpu'",
    "",
    "try:",
    "    import torch",
    "    if torch.cuda.is_available():",
    "        GPU_AVAILABLE = True",
    "        GPU_DEVICE = 'cuda'",
    "        print(f'âœ… NVIDIA GPUæ¤œå‡º: {torch.cuda.get_device_name(0)}')",
    "        print(f'   CUDA Version: {torch.version.cuda}')",
    "        print(f'   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')",
    "    else:",
    "        print('âš ï¸ PyTorch installed but no CUDA GPU found')",
    "except ImportError:",
    "    print('â„¹ï¸ PyTorch not installed (GPU detection skipped)')",
    "",
    "",
    "# cuDF (GPU-accelerated Pandas) ãƒã‚§ãƒƒã‚¯",
    "CUDF_AVAILABLE = False",
    "try:",
    "    import cudf",
    "    if GPU_AVAILABLE:",
    "        CUDF_AVAILABLE = True",
    "        print('âœ… cuDF (GPU Pandas) å¯¾å¿œ: å¯èƒ½')",
    "        print('   ğŸ’¡ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒ10ï½50å€é«˜é€ŸåŒ–ã•ã‚Œã¾ã™')",
    "    else:",
    "        print('â„¹ï¸ cuDF: GPUæœªæ¤œå‡ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—')",
    "except ImportError:",
    "    print('â„¹ï¸ cuDF not installed (pip install cudf-cu12)')",
    "",
    "# GPUä½¿ç”¨ãƒ•ãƒ©ã‚°",
    "USE_GPU = GPU_AVAILABLE",
    "",
    "if USE_GPU:",
    "    print(f'ğŸš€ GPUä½¿ç”¨: æœ‰åŠ¹ï¼ˆãƒ‡ãƒ¼ã‚¿å‡¦ç†é«˜é€ŸåŒ–ï¼‰')",
    "    print(f'   Device: {GPU_DEVICE}')",
    "else:",
    "    print(f'\\nâ„¹ï¸ GPUä½¿ç”¨: ç„¡åŠ¹ï¼ˆCPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼‰')",
    "",
    "print('='*60)",
    "",
    "print(f\"\\nEnv: pandas={pd.__version__}, plotly={'OK' if PLOTLY else 'N/A'}, widgets={'OK' if WIDGETS else 'N/A'}, sklearn={'OK' if SK_OK else 'N/A'}, GPU={'YES' if GPU_AVAILABLE else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================",
    "# ğŸ”§ GPU/CPU ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£",
    "# ========================================",
    "",
    "def to_gpu(df):",
    "    \"\"\"pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’GPU (cuDF) ã«å¤‰æ›ï¼ˆUSE_GPU=Trueã®å ´åˆã®ã¿ï¼‰\"\"\"",
    "    if USE_GPU and CUDF_AVAILABLE and df is not None and not df.empty:",
    "        try:",
    "            import cudf",
    "            return cudf.from_pandas(df)",
    "        except Exception as e:",
    "            print(f'âš ï¸ GPUå¤‰æ›å¤±æ•—ã€CPUãƒ¢ãƒ¼ãƒ‰ç¶™ç¶š: {e}')",
    "            return df",
    "    return df",
    "",
    "def to_cpu(df):",
    "    \"\"\"cuDFãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’pandasã«å¤‰æ›\"\"\"",
    "    if df is None:",
    "        return None",
    "    try:",
    "        import cudf",
    "        if isinstance(df, cudf.DataFrame):",
    "            return df.to_pandas()",
    "    except:",
    "        pass",
    "    return df",
    "",
    "# GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³è¡¨ç¤º",
    "def show_gpu_memory():",
    "    if GPU_AVAILABLE:",
    "        try:",
    "            import torch",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3",
    "            reserved = torch.cuda.memory_reserved(0) / 1024**3",
    "            print(f'ğŸ“Š GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved')",
    "        except:",
    "            pass",
    "",
    "if USE_GPU and CUDF_AVAILABLE:",
    "    print('âœ… GPUé«˜é€ŸåŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£: æº–å‚™å®Œäº†')",
    "    print('   to_gpu(df) ã§GPUå‡¦ç†ã€to_cpu(df) ã§CPUæˆ»ã—')",
    "    show_gpu_memory()",
    "else:",
    "    print('â„¹ï¸ CPUå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆGPUãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¯ç„¡åŠ¹ï¼‰')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. æŒ‡å®šCSVèª­ã¿è¾¼ã¿ã¨æ•´å½¢\n",
    "- ç”Ÿæˆ: `sales`(å¿…é ˆ), `product`(SKUãƒã‚¹ã‚¿), `df`(è§£æç”¨ãƒ™ãƒ¼ã‚¹), `weather`(ä»£è¡¨åˆ—)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆç’°å¢ƒå¤‰æ•°å„ªå…ˆâ†’æ—¢å®šãƒ‘ã‚¹ï¼‰\n",
    "import os\n",
    "cand_env = [os.environ.get('DATA_PATH'), os.environ.get('ENRICHED_CSV')]\n",
    "DATA_PATH = None\n",
    "for p in cand_env:\n",
    "    if p and Path(p).exists():\n",
    "        DATA_PATH = Path(p); break\n",
    "if DATA_PATH is None:\n",
    "    DATA_PATH = Path('output/06_final_enriched_20250701_20250930.csv')\n",
    "\n",
    "raw = pd.read_csv(DATA_PATH, encoding='utf-8-sig')\n",
    "df = raw.copy()\n",
    "# åˆ—åæ­£è¦åŒ–ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰\n",
    "rename_map = {\n",
    "    'åº—èˆ—':'store_id','å•†å“å':'sku_id','æ—¥ä»˜':'date','å£²ä¸Šæ•°é‡':'qty','å£²ä¸Šé‡‘é¡':'sales_amt',\n",
    "    'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡':'category_l','ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šä¸­åˆ†é¡':'category_m','ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå°åˆ†é¡':'category_s'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "if 'date' in df.columns: df['date'] = pd.to_datetime(df['date'])\n",
    "if 'qty' in df.columns: df['qty'] = pd.to_numeric(df['qty'], errors='coerce').fillna(0)\n",
    "if 'sales_amt' in df.columns: df['sales_amt'] = pd.to_numeric(df['sales_amt'], errors='coerce').fillna(0)\n",
    "if {'sales_amt','qty'}.issubset(df.columns): df['price'] = np.where(df['qty']>0, df['sales_amt']/df['qty'], np.nan)\n",
    "\n",
    "sales = df[[c for c in ['date','store_id','sku_id','qty','price','sales_amt','category_l','category_m','category_s'] if c in df.columns]].copy()\n",
    "product = df[[c for c in ['sku_id','category_l','category_m','category_s'] if c in df.columns]].drop_duplicates().copy() if 'sku_id' in df.columns else pd.DataFrame()\n",
    "\n",
    "# weatherï¼ˆä»£è¡¨åˆ—ãŒã‚ã‚Œã°é›†ç´„ï¼‰\n",
    "wcols = [c for c in ['å¤©æ°—','æœ€é«˜æ°—æ¸©','æœ€ä½æ°—æ¸©','é™æ°´é‡','å¹³å‡æ°—æ¸©','æ°—æ¸©å·®'] if c in df.columns]\n",
    "if wcols and {'date','store_id'}.issubset(df.columns):\n",
    "    wdf = df[['date','store_id']+wcols].copy()\n",
    "    num_cols = [c for c in wcols if c!='å¤©æ°—']\n",
    "    agg = {c:'mean' for c in num_cols}\n",
    "    if 'å¤©æ°—' in wcols:\n",
    "        # æœ€é »å€¤ã‚’ä»£è¡¨ã¨ã™ã‚‹\n",
    "        def _mode(x):\n",
    "            m = x.mode()\n",
    "            return m.iloc[0] if not m.empty else x.iloc[0]\n",
    "        agg['å¤©æ°—'] = _mode\n",
    "    weather = wdf.groupby(['date','store_id'], as_index=False).agg(agg)\n",
    "    if 'å¤©æ°—' in weather.columns: weather = weather.rename(columns={'å¤©æ°—':'weather'})\n",
    "else:\n",
    "    weather = pd.DataFrame()\n",
    "\n",
    "print('èª­ã¿è¾¼ã¿:', {'raw': raw.shape, 'sales': sales.shape, 'product': product.shape, 'weather': getattr(weather,'shape',None)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KPI/ABC ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_daily_kpi(sales_df, prod_df):\n",
    "    if sales_df is None or sales_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df0 = sales_df.copy()\n",
    "    if 'sales_amt' not in df0.columns:\n",
    "        if {'price','qty'}.issubset(df0.columns):\n",
    "            df0['sales_amt'] = df0['price'] * df0['qty']\n",
    "        else:\n",
    "            df0['sales_amt'] = 0\n",
    "    if not prod_df.empty and 'cost' in prod_df.columns:\n",
    "        df0 = df0.merge(prod_df[['sku_id','cost']], on='sku_id', how='left')\n",
    "        df0['gross_profit'] = df0['sales_amt'] - df0['cost'].fillna(0) * df0['qty'].fillna(0)\n",
    "    agg_map = dict(sales_amt=('sales_amt','sum'), qty=('qty','sum'))\n",
    "    if 'gross_profit' in df0.columns:\n",
    "        agg_map['gross_profit'] = ('gross_profit','sum')\n",
    "    gp = df0.groupby(['date','store_id'], as_index=False).agg(**agg_map)\n",
    "    return gp\n",
    "\n",
    "def abc_analysis(sales_df, prod_df, top_ratio=(0.8,0.95)):\n",
    "    if sales_df is None or sales_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    d = sales_df.copy()\n",
    "    if 'sales_amt' not in d.columns:\n",
    "        if {'price','qty'}.issubset(d.columns):\n",
    "            d['sales_amt'] = d['price'] * d['qty']\n",
    "        else:\n",
    "            d['sales_amt'] = 0\n",
    "    by = d.groupby('sku_id', as_index=False)['sales_amt'].sum().sort_values('sales_amt', ascending=False)\n",
    "    if by['sales_amt'].sum() == 0:\n",
    "        by['cum_ratio'] = 0\n",
    "    else:\n",
    "        by['cum_ratio'] = by['sales_amt'].cumsum()/by['sales_amt'].sum()\n",
    "    a_th, b_th = top_ratio\n",
    "    by['ABC'] = np.where(by['cum_ratio']<=a_th, 'A', np.where(by['cum_ratio']<=b_th, 'B','C'))\n",
    "    if not prod_df.empty:\n",
    "        by = by.merge(prod_df, on='sku_id', how='left')\n",
    "    return by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. åº—èˆ—é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# åº—èˆ—é¸æŠã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆï¼ˆã“ã®æ™‚ç‚¹ã§ã¯è¡¨ç¤ºã®ã¿ã€é¸æŠã¯ cell-14 ã§è¡Œã†ï¼‰\nstore_opts = sorted(sales['store_id'].dropna().unique().tolist()) if not sales.empty and 'store_id' in sales.columns else []\nif WIDGETS and store_opts:\n    print(f'âœ… åº—èˆ—é¸æŠã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’æº–å‚™ã—ã¾ã—ãŸï¼ˆ{len(store_opts)}åº—èˆ—ï¼‰')\n    print('ğŸ‘‰ ä¸‹ã®ã€Œ6. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„')\nelse:\n    print('âš ï¸ widgetsç„¡åŠ¹ã€ã¾ãŸã¯åº—èˆ—ãƒ‡ãƒ¼ã‚¿ãªã—')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. éœ€è¦äºˆæ¸¬ï¼ˆPyCaretï¼‰\n",
    "- Exogenous: å¤©å€™/ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼/ãƒ—ãƒ­ãƒ¢ãªã©ï¼ˆæœ¬ã‚µãƒ³ãƒ—ãƒ«ã§ã¯æœªçµåˆï¼‰\n",
    "- SKUÃ—åº—èˆ—ã®å˜ä¸€ç³»åˆ—ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    from pycaret.time_series import setup as ts_setup, compare_models as ts_compare, finalize_model as ts_finalize, predict_model as ts_predict\n    PYCaret_TS=True\nexcept Exception as e:\n    PYCaret_TS=False\n    print(f'PyCaret TS ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}')\n\n# PyCaret TSã¯ cell-14 ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆåº—èˆ—é¸æŠå¾Œï¼‰\nif PYCaret_TS:\n    print('âœ… PyCaret TS åˆ©ç”¨å¯èƒ½ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¾ã™ï¼‰')\nelif not PYCaret_TS:\n    print('âš ï¸ PyCaret TS ç„¡åŠ¹ï¼ˆã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ï¼‰')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆå£²ä¸Šé‡‘é¡ï¼‰ã¨ææ¡ˆã®è‡ªå‹•ç”Ÿæˆ\n",
    "- é¸æŠåº—èˆ—ã®åˆç®—å£²ä¸Šï¼ˆå£²ä¸Šé‡‘é¡ï¼‰ã‚’ç›®çš„å¤‰æ•°ã«ã€æä¾›ç‰¹å¾´é‡ã‹ã‚‰é‡è¦åº¦ã‚’æ¨å®š\n",
    "- sklearnãŒç„¡ã„å ´åˆã¯ç›¸é–¢ä¿‚æ•°ã§ä»£æ›¿\n",
    "- ä¸Šä½ç‰¹å¾´é‡ã«å¿œã˜ã¦ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šå·®åˆ†ã‚’ç®—å‡ºã—ã€å®Ÿè¡Œææ¡ˆã‚’å‡ºåŠ›\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡ä½œæˆ\n",
    "def build_feature_dataset(df_all, stores):\n",
    "    d = df_all.copy()\n",
    "    if stores: d = d[d['store_id'].isin(stores)]\n",
    "    cand = [\n",
    "        'ç¥æ—¥ãƒ•ãƒ©ã‚°','åœŸæ›œãƒ•ãƒ©ã‚°','æ—¥æ›œãƒ•ãƒ©ã‚°','é€±æœ«ãƒ•ãƒ©ã‚°','å¹³æ—¥ãƒ•ãƒ©ã‚°','ä¼‘æ—¥ãƒ•ãƒ©ã‚°','é™é›¨ãƒ•ãƒ©ã‚°','å¼±é›¨','æ™®é€šé›¨','å¼·é›¨','è±ªé›¨',\n",
    "        'æœ€é«˜æ°—æ¸©','æœ€ä½æ°—æ¸©','å¹³å‡æ°—æ¸©','æ°—æ¸©å·®','é™æ°´é‡','æœ€é«˜æ°—æ¸©_t-1','æœ€é«˜æ°—æ¸©_t-7','æœ€ä½æ°—æ¸©_t-1','æœ€ä½æ°—æ¸©_t-7','å¹³å‡æ°—æ¸©_t-1','å¹³å‡æ°—æ¸©_t-7',\n",
    "        'æœ€é«˜æ°—æ¸©_MA3','æœ€é«˜æ°—æ¸©_MA7','å¹³å‡æ°—æ¸©_MA3','å¹³å‡æ°—æ¸©_MA7','æ°—æ¸©ãƒˆãƒ¬ãƒ³ãƒ‰_7d','å­£ç¯€å¤‰å‹•æŒ‡æ•°_æœˆ','å­£ç¯€å¤‰å‹•æŒ‡æ•°_é€±','é€±'\n",
    "    ]\n",
    "    present = [c for c in cand if c in d.columns]\n",
    "    keep = ['date','store_id','sales_amt'] + present\n",
    "    t = d[keep].copy()\n",
    "    # æ—¥ä»˜Ã—åº—èˆ—ã§ç‰¹å¾´é‡ã‚’ä»£è¡¨åŒ–ï¼ˆæ•°å€¤ã¯å¹³å‡ï¼‰ã€å£²ä¸Šã¯åˆè¨ˆ\n",
    "    Xdf = t.groupby(['date','store_id'], as_index=False)[present].mean() if present else t[['date','store_id']].drop_duplicates()\n",
    "    ydf = t.groupby(['date','store_id'], as_index=False)['sales_amt'].sum().rename(columns={'sales_amt':'y'})\n",
    "    feat = Xdf.merge(ydf, on=['date','store_id'], how='inner')\n",
    "    return feat, present\n",
    "\n",
    "# é‡è¦åº¦\n",
    "def rank_features(df_all, stores):\n",
    "    feat, cols = build_feature_dataset(df_all, stores)\n",
    "    if len(feat)<10 or not cols:\n",
    "        return pd.DataFrame(columns=['feature','importance'])\n",
    "    if SK_OK:\n",
    "        try:\n",
    "            model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "            X = feat[cols].fillna(0).values\n",
    "            y = feat['y'].values\n",
    "            model.fit(X, y)\n",
    "            imp = model.feature_importances_\n",
    "            return pd.DataFrame({'feature': cols, 'importance': imp}).sort_values('importance', ascending=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # fallback: ç›¸é–¢\n",
    "    dfm = feat[cols+['y']].copy()\n",
    "    cor = dfm.corr(numeric_only=True)['y'].abs().drop('y', errors='ignore').sort_values(ascending=False)\n",
    "    return cor.reset_index().rename(columns={'index':'feature'})\n",
    "\n",
    "# ææ¡ˆï¼ˆãƒ•ãƒ©ã‚°åˆ¥upliftï¼‰\n",
    "def uplift_by_flag(df_all, stores, flag_col, top_n=5):\n",
    "    if flag_col not in df_all.columns: return pd.DataFrame()\n",
    "    d = df_all.copy()\n",
    "    if stores: d = d[d['store_id'].isin(stores)]\n",
    "    if 'category_l' not in d.columns: return pd.DataFrame()\n",
    "    base = d.groupby(['date','store_id','category_l'], as_index=False)['sales_amt'].sum()\n",
    "    flags = d[['date','store_id','category_l', flag_col]].drop_duplicates()\n",
    "    m = base.merge(flags, on=['date','store_id','category_l'], how='left')\n",
    "    a = m[m[flag_col]==1].groupby('category_l', as_index=False)['sales_amt'].mean()\n",
    "    b = m[m[flag_col]!=1].groupby('category_l', as_index=False)['sales_amt'].mean()\n",
    "    if a.empty or b.empty: return pd.DataFrame()\n",
    "    u = a.merge(b, on='category_l', suffixes=('_flag1','_flag0'))\n",
    "    u['uplift'] = (u['sales_amt_flag1']-u['sales_amt_flag0'])/(u['sales_amt_flag0']+1e-6)\n",
    "    return u.sort_values('uplift', ascending=False).head(top_n)\n",
    "\n",
    "# å®Ÿè¡Œ\n",
    "fi = rank_features(df, selected_stores if 'selected_stores' in globals() else [])\n",
    "display(fi.head(20))\n",
    "print(\"\\n--- ææ¡ˆï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šä¸ŠæŒ¯ã‚ŒãŒå¤§ãã„é †ï¼‰---\")\n",
    "for f in [c for c in ['é™é›¨ãƒ•ãƒ©ã‚°','é€±æœ«ãƒ•ãƒ©ã‚°','çŒ›æš‘æ—¥','çœŸå¤æ—¥','å¤æ—¥','å†¬æ—¥','çœŸå†¬æ—¥','çµ¦æ–™æ—¥','çµ¦æ–™æ—¥ç›´å¾Œ','æœˆåˆ3æ—¥','æœˆæœ«3æ—¥'] if c in df.columns]:\n",
    "    top_u = uplift_by_flag(df, selected_stores if 'selected_stores' in globals() else [], f, top_n=5)\n",
    "    if not top_u.empty:\n",
    "        print(f\"[ææ¡ˆã‚­ãƒ¼: {f}]\")\n",
    "        display(top_u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆåº—èˆ—é¸æŠ + KPI/ABC/ç‰¹å¾´é‡/ææ¡ˆ/ã‚¢ãƒ©ãƒ¼ãƒˆï¼‰\n",
    "- åº—èˆ—ã®è¤‡æ•°é¸æŠã«å¯¾å¿œ\n",
    "- åœ¨åº«/åŸä¾¡ä¾å­˜ã®ãƒ“ãƒ¥ãƒ¼ã¯é™¤å¤–ï¼ˆæœªæä¾›ã®ãŸã‚ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# åº—èˆ—è¤‡æ•°é¸æŠ â†’ 5ãƒ“ãƒ¥ãƒ¼ã‚’åŒæ™‚å±•é–‹ï¼ˆKPI/ABC/ç‰¹å¾´é‡/ææ¡ˆ/ã‚¢ãƒ©ãƒ¼ãƒˆï¼‰\nif WIDGETS and (not sales.empty):\n    store_opts = sorted(sales['store_id'].dropna().unique().tolist())\n    stores_ms = widgets.SelectMultiple(\n        options=store_opts, \n        value=tuple(store_opts[:1]) if store_opts else tuple(), \n        description='åº—èˆ—(è¤‡æ•°)',\n        rows=min(10, len(store_opts))\n    )\n    out = widgets.Output()\n    \n    print('='*60)\n    print('ğŸª åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼šCtrl/Cmd + ã‚¯ãƒªãƒƒã‚¯ï¼‰')\n    print('='*60)\n    display(stores_ms)\n    display(out)\n\n    def render_all(sel):\n        with out:\n            clear_output(wait=True)\n            if not sel:\n                print('âš ï¸ åº—èˆ—ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šã®ãƒªã‚¹ãƒˆã‹ã‚‰åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚')\n                return\n            \n            print('='*60)\n            print(f\"ğŸ“Š é¸æŠåº—èˆ—: {', '.join(map(str, sel))}\")\n            print('='*60)\n            \n            ss = sales[sales['store_id'].isin(sel)].copy() if sel else sales.copy()\n            \n            # 1) KPI\n            print('\\n' + '='*60)\n            print('[ãƒ“ãƒ¥ãƒ¼ 1/5] KPIï¼ˆæ—¥æ¬¡å£²ä¸Šï¼‰')\n            print('='*60)\n            print('ğŸ“Œ ä½•ã‚’è¦‹ã‚‹: å£²ä¸Šãƒ»å®¢æ•°ãƒ»å®¢å˜ä¾¡ã®æ—¥æ¬¡æ¨ç§»')\n            print('ğŸ“Œ åˆ¤æ–­åŸºæº–: å‰æ—¥æ¯”ã§å¤§ããä¸‹æŒ¯ã‚Œã—ã¦ã„ãŸã‚‰ã€æ¬¡ã®ã€Œã‚¢ãƒ©ãƒ¼ãƒˆã€ã€Œææ¡ˆã€ã§åŸå› ã‚’ç¢ºèª')\n            print('-'*60)\n            kpi = compute_daily_kpi(ss, product)\n            if kpi is not None and not kpi.empty and PLOTLY:\n                fig = px.line(kpi, x='date', y='sales_amt', color='store_id', title='å£²ä¸Šé‡‘é¡(æ—¥æ¬¡)')\n                fig.show()\n            else:\n                display(kpi.head() if kpi is not None else 'KPIãƒ‡ãƒ¼ã‚¿ç„¡ã—')\n            \n            # 2) ABC\n            print('\\n' + '='*60)\n            print('[ãƒ“ãƒ¥ãƒ¼ 2/5] ABCï¼ˆSKUå¯„ä¸ï¼‰')\n            print('='*60)\n            print('ğŸ“Œ ä½•ã‚’è¦‹ã‚‹: Aï¼ˆå£²ä¸Š80%ï¼‰ã€Bï¼ˆ80-95%ï¼‰ã€Cï¼ˆ95-100%ï¼‰ã®SKUåˆ†é¡')\n            print('ğŸ“Œ åˆ¤æ–­åŸºæº–: Aã¯çµ¶å¯¾ã«æ¬ å“ã•ã›ãªã„ã€Cã¯ç¸®å°ãƒ»å…¥æ›¿å€™è£œ')\n            print('-'*60)\n            ab = abc_analysis(ss, product)\n            if not ab.empty:\n                print(f'âœ… A: {len(ab[ab[\"ABC\"]==\"A\"])} SKU, B: {len(ab[ab[\"ABC\"]==\"B\"])} SKU, C: {len(ab[ab[\"ABC\"]==\"C\"])} SKU')\n                display(ab.head(30))\n            else:\n                print('ãƒ‡ãƒ¼ã‚¿ç„¡ã—')\n            \n            # 3) ç‰¹å¾´é‡é‡è¦åº¦\n            print('\\n' + '='*60)\n            print('[ãƒ“ãƒ¥ãƒ¼ 3/5] ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆå£²ä¸Šé‡‘é¡ï¼‰')\n            print('='*60)\n            print('ğŸ“Œ ä½•ã‚’è¦‹ã‚‹: å£²ä¸Šã«å½±éŸ¿ã™ã‚‹è¦å› ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå¤©å€™ãƒ»æ›œæ—¥ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆç­‰ï¼‰')\n            print('ğŸ“Œ åˆ¤æ–­åŸºæº–: ä¸Šä½ã®è¦å› ã‚’ã€Œææ¡ˆã€ã¨çµ„ã¿åˆã‚ã›ã¦ã€é™³åˆ—ãƒ»å°ç·šã‚’èª¿æ•´')\n            print('-'*60)\n            fi = rank_features(df, sel)\n            if not fi.empty:\n                display(fi.head(20))\n            else:\n                print('ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ10è¡Œæœªæº€ï¼‰ã®ãŸã‚ã€ç‰¹å¾´é‡é‡è¦åº¦ã¯è¨ˆç®—ã§ãã¾ã›ã‚“')\n            \n            # 4) ææ¡ˆ\n            print('\\n' + '='*60)\n            print('[ãƒ“ãƒ¥ãƒ¼ 4/5] ææ¡ˆï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šä¸ŠæŒ¯ã‚Œå€™è£œï¼‰')\n            print('='*60)\n            print('ğŸ“Œ ä½•ã‚’è¦‹ã‚‹: å„ãƒ•ãƒ©ã‚°ï¼ˆé™é›¨/é€±æœ«/çŒ›æš‘/çµ¦æ–™æ—¥ç­‰ï¼‰ã§å£²ä¸ŠãŒä¼¸ã³ã‚‹ã‚«ãƒ†ã‚´ãƒª')\n            print('ğŸ“Œ åˆ¤æ–­åŸºæº–: ä»Šæ—¥è©²å½“ã™ã‚‹ãƒ•ãƒ©ã‚°ã®ä¸Šä½ã‚«ãƒ†ã‚´ãƒªã‚’ã€é–‹åº—å‰ãƒ»ãƒ”ãƒ¼ã‚¯å‰ã«å‰å‡ºã—/ãƒ•ã‚§ãƒ¼ã‚¹å¢—')\n            print('-'*60)\n            flag_found = False\n            for f in [c for c in ['é™é›¨ãƒ•ãƒ©ã‚°','é€±æœ«ãƒ•ãƒ©ã‚°','çŒ›æš‘æ—¥','çœŸå¤æ—¥','å¤æ—¥','å†¬æ—¥','çœŸå†¬æ—¥','çµ¦æ–™æ—¥','çµ¦æ–™æ—¥ç›´å¾Œ','æœˆåˆ3æ—¥','æœˆæœ«3æ—¥'] if c in df.columns]:\n                u = uplift_by_flag(df, sel, f, top_n=5)\n                if not u.empty:\n                    flag_found = True\n                    print(f\"\\nğŸ”‘ [ææ¡ˆã‚­ãƒ¼: {f}]\")\n                    display(u)\n            if not flag_found:\n                print('ææ¡ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆè©²å½“ãƒ•ãƒ©ã‚°åˆ—ãŒå­˜åœ¨ã—ãªã„ã€ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰')\n            \n            # 5) ã‚¢ãƒ©ãƒ¼ãƒˆ\n            print('\\n' + '='*60)\n            print('[ãƒ“ãƒ¥ãƒ¼ 5/5] ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆ3æ—¥MA vs 7æ—¥MAã®ä¹–é›¢ï¼‰')\n            print('='*60)\n            print('ğŸ“Œ ä½•ã‚’è¦‹ã‚‹: çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ3æ—¥ï¼‰ã¨ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ7æ—¥ï¼‰ã®å·®ãŒÂ±30%ã‚’è¶…ãˆãŸæ—¥')\n            print('ğŸ“Œ åˆ¤æ–­åŸºæº–: ä¸ŠæŒ¯ã‚Œâ†’è©²å½“ã‚«ãƒ†ã‚´ãƒªã®ãƒ•ã‚§ãƒ¼ã‚¹å¢—ã€ä¸‹æŒ¯ã‚Œâ†’é™³åˆ—ãƒ»å°ç·šãƒ»å€¤é ƒè¨´æ±‚ã®è¦‹ç›´ã—')\n            print('-'*60)\n            tmp = ss.groupby(['date','store_id'], as_index=False)['sales_amt'].sum().sort_values('date')\n            if tmp.empty:\n                print('ãƒ‡ãƒ¼ã‚¿ç„¡ã—')\n            else:\n                tmp['ma3'] = tmp.groupby('store_id')['sales_amt'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n                tmp['ma7'] = tmp.groupby('store_id')['sales_amt'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n                tmp['delta'] = (tmp['ma3'] - tmp['ma7'])/(tmp['ma7']+1e-6)\n                alert = tmp[tmp['delta'].abs()>0.3].copy()\n                if not alert.empty:\n                    print(f'âš ï¸ ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿ: {len(alert)} ä»¶ï¼ˆæœ€æ–°20ä»¶ã‚’è¡¨ç¤ºï¼‰')\n                    display(alert.tail(20))\n                else:\n                    print('âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—ï¼ˆä¹–é›¢ãŒ30%æœªæº€ï¼‰')\n            \n            print('\\n' + '='*60)\n            print('âœ… å…¨5ãƒ“ãƒ¥ãƒ¼ã®è¡¨ç¤ºå®Œäº†')\n            print('='*60)\n\n    def _on_change(change):\n        if change['name']=='value':\n            render_all(list(change['owner'].value))\n\n    stores_ms.observe(_on_change, names='value')\n    # åˆå›æç”»\n    render_all(list(stores_ms.value))\nelse:\n    print('âš ï¸ widgetsæœªåˆ©ç”¨ã€ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ç„¡ã—ã®ãŸã‚ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å±•é–‹ã¯ã‚¹ã‚­ãƒƒãƒ—')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}