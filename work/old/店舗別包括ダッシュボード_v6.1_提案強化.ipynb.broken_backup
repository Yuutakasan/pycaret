{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🏪 店舗別包括ダッシュボード v6.1 — 複数店舗選択・特徴量提案強化\n",
    "\n",
    "- 指定CSVを読み込み、売上に効く特徴量を特定し、店舗選択に応じた提案を自動生成\n",
    "- 在庫(on_hand)/原価(cost)/棚容量は未提供 → 依存分析は除外\n",
    "- ダッシュボードは KPI / ABC / 特徴量 / 提案 / アラート を切替\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 店長の使い方（意思決定ガイド)\n",
    "このダッシュボードは『見る→判断→即アクション』の順に作られています。毎日5〜10分で下記を実施してください。\n",
    "\n",
    "### 1) KPI（全体傾向の把握：1分）\n",
    "- チェック: 売上・客数・客単価の推移。昨日/一昨日と比べて大きく上下していないか。\n",
    "- 行動: 下振れ時は次の『アラート』『提案』で原因と打ち手を確認し、該当カテゴリの面出し/フェース増や前出し時間の前倒しを実施。\n",
    "\n",
    "### 2) アラート（急変の早期対応：1〜2分）\n",
    "- 定義: 売上の3日移動平均と7日移動平均の乖離が±30%を超えた店舗日。\n",
    "- 行動: 上振れ→該当カテゴリのフェース/在庫面（前出し）を増やす。下振れ→陳列場所や導線の見直し・値頃訴求（のちの見切り基準を調整）。\n",
    "\n",
    "### 3) 提案（今日の打ち手：2〜3分）\n",
    "- ロジック: 天候・曜日・イベント等のフラグごとに、売上が上振れしやすいカテゴリを提示。\n",
    "- 行動: 上位カテゴリに対して、時間帯別の前出し/フェース増/導線強化を実行。例:\n",
    "  - 降雨フラグ: 温かい総菜/カップ麺/ホット飲料/中華まん（入口側/レジ横の導線強化）\n",
    "  - 猛暑日/真夏日: 冷飲料/アイス/チルドデザート（冷ケースのフェース増、氷/保冷品の訴求）\n",
    "  - 週末: 弁当/麺/デザート（昼・夕ピーク前の前出し強化）\n",
    "  - 給料日/給料日直後: 高単価弁当/スイーツ（夕方手前での厚め陳列）\n",
    "  - 月初3日: 主力定番の面確保（発注強めの判断材料に）\n",
    "  - 月末3日: 値頃品/節約訴求（価格ポップ/クロスMD）\n",
    "\n",
    "### 4) ABC（棚の配分調整：2分）\n",
    "- A: 売上80%を作る主力。フェースを最優先で確保し、欠品させない（前出し時間を前倒し）。\n",
    "- B: 補完。ピーク前補充と見せ方で差を出す。\n",
    "- C: 圧縮/入替候補。売場スペースをA/Bへ寄せる。\n",
    "\n",
    "### 日次チェックリスト（例）\n",
    "- [ ] KPIで下振れはないか→ある場合は『アラート』『提案』を優先確認\n",
    "- [ ] 今日の提案キー（降雨/猛暑/週末/給料日など）と上位カテゴリをメモ\n",
    "- [ ] 開店前: 上位カテゴリの面出し/フェース増（入口/レジ横/端導線）\n",
    "- [ ] 昼ピーク前（〜11時）: 補充/前出し強化\n",
    "- [ ] 夕ピーク前（〜17時）: 補充/前出し強化\n",
    "- [ ] 閉店前: 値頃訴求/見切り（在庫連動は未実装のため判断基準を店舗運用で）\n",
    "\n",
    "### 補足\n",
    "- 本シートは在庫・原価なしの前提です。欠品/廃棄/粗利の最適化は別ノート（在庫連動）と連携を検討。\n",
    "- 特徴量（要因）の上位を『明日』の打ち手（陳列/販促/導線）へ反映し、翌日のKPI改善に繋げてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ",
    "import warnings; warnings.filterwarnings('ignore')",
    "import pandas as pd, numpy as np",
    "from pathlib import Path",
    "import font_setup  # 日本語フォント/Plotlyテンプレート",
    "",
    "try:",
    "    import plotly.express as px; import plotly.graph_objects as go",
    "    PLOTLY=True",
    "except Exception:",
    "    PLOTLY=False",
    "try:",
    "    import ipywidgets as widgets; from IPython.display import display, clear_output",
    "    WIDGETS=True",
    "except Exception:",
    "    WIDGETS=False",
    "try:",
    "    from sklearn.ensemble import RandomForestRegressor",
    "    SK_OK=True",
    "except Exception:",
    "    SK_OK=False",
    "",
    "# ========================================",
    "# 🚀 GPU検出と設定",
    "# ========================================",
    "print('='*60)",
    "print('🖥️ GPU検出')",
    "print('='*60)",
    "",
    "GPU_AVAILABLE = False",
    "GPU_DEVICE = 'cpu'",
    "",
    "try:",
    "    import torch",
    "    if torch.cuda.is_available():",
    "        GPU_AVAILABLE = True",
    "        GPU_DEVICE = 'cuda'",
    "        print(f'✅ NVIDIA GPU検出: {torch.cuda.get_device_name(0)}')",
    "        print(f'   CUDA Version: {torch.version.cuda}')",
    "        print(f'   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')",
    "    else:",
    "        print('⚠️ PyTorch installed but no CUDA GPU found')",
    "except ImportError:",
    "    print('ℹ️ PyTorch not installed (GPU detection skipped)')",
    "",
    "",
    "# cuDF (GPU-accelerated Pandas) チェック",
    "CUDF_AVAILABLE = False",
    "try:",
    "    import cudf",
    "    if GPU_AVAILABLE:",
    "        CUDF_AVAILABLE = True",
    "        print('✅ cuDF (GPU Pandas) 対応: 可能')",
    "        print('   💡 大規模データ処理が10～50倍高速化されます')",
    "    else:",
    "        print('ℹ️ cuDF: GPU未検出のためスキップ')",
    "except ImportError:",
    "    print('ℹ️ cuDF not installed (pip install cudf-cu12)')",
    "",
    "# GPU使用フラグ",
    "USE_GPU = GPU_AVAILABLE",
    "",
    "if USE_GPU:",
    "    print(f'🚀 GPU使用: 有効（データ処理高速化）')",
    "    print(f'   Device: {GPU_DEVICE}')",
    "else:",
    "    print(f'\\nℹ️ GPU使用: 無効（CPUモードで実行）')",
    "",
    "print('='*60)",
    "",
    "print(f\"\\nEnv: pandas={pd.__version__}, plotly={'OK' if PLOTLY else 'N/A'}, widgets={'OK' if WIDGETS else 'N/A'}, sklearn={'OK' if SK_OK else 'N/A'}, GPU={'YES' if GPU_AVAILABLE else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================",
    "# 🔧 GPU/CPU データフレーム変換ユーティリティ",
    "# ========================================",
    "",
    "def to_gpu(df):",
    "    \"\"\"pandasデータフレームをGPU (cuDF) に変換（USE_GPU=Trueの場合のみ）\"\"\"",
    "    if USE_GPU and CUDF_AVAILABLE and df is not None and not df.empty:",
    "        try:",
    "            import cudf",
    "            return cudf.from_pandas(df)",
    "        except Exception as e:",
    "            print(f'⚠️ GPU変換失敗、CPUモード継続: {e}')",
    "            return df",
    "    return df",
    "",
    "def to_cpu(df):",
    "    \"\"\"cuDFデータフレームをpandasに変換\"\"\"",
    "    if df is None:",
    "        return None",
    "    try:",
    "        import cudf",
    "        if isinstance(df, cudf.DataFrame):",
    "            return df.to_pandas()",
    "    except:",
    "        pass",
    "    return df",
    "",
    "# GPUメモリ使用状況表示",
    "def show_gpu_memory():",
    "    if GPU_AVAILABLE:",
    "        try:",
    "            import torch",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3",
    "            reserved = torch.cuda.memory_reserved(0) / 1024**3",
    "            print(f'📊 GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved')",
    "        except:",
    "            pass",
    "",
    "if USE_GPU and CUDF_AVAILABLE:",
    "    print('✅ GPU高速化ユーティリティ: 準備完了')",
    "    print('   to_gpu(df) でGPU処理、to_cpu(df) でCPU戻し')",
    "    show_gpu_memory()",
    "else:",
    "    print('ℹ️ CPU処理モード（GPUユーティリティは無効）')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. 指定CSV読み込みと整形\n",
    "- 生成: `sales`(必須), `product`(SKUマスタ), `df`(解析用ベース), `weather`(代表列)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# データ読み込み（環境変数優先→既定パス）\n",
    "import os\n",
    "cand_env = [os.environ.get('DATA_PATH'), os.environ.get('ENRICHED_CSV')]\n",
    "DATA_PATH = None\n",
    "for p in cand_env:\n",
    "    if p and Path(p).exists():\n",
    "        DATA_PATH = Path(p); break\n",
    "if DATA_PATH is None:\n",
    "    DATA_PATH = Path('output/06_final_enriched_20250701_20250930.csv')\n",
    "\n",
    "raw = pd.read_csv(DATA_PATH, encoding='utf-8-sig')\n",
    "df = raw.copy()\n",
    "# 列名正規化（存在すれば）\n",
    "rename_map = {\n",
    "    '店舗':'store_id','商品名':'sku_id','日付':'date','売上数量':'qty','売上金額':'sales_amt',\n",
    "    'フェイスくくり大分類':'category_l','フェイスくくり中分類':'category_m','フェイスくくり小分類':'category_s'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "if 'date' in df.columns: df['date'] = pd.to_datetime(df['date'])\n",
    "if 'qty' in df.columns: df['qty'] = pd.to_numeric(df['qty'], errors='coerce').fillna(0)\n",
    "if 'sales_amt' in df.columns: df['sales_amt'] = pd.to_numeric(df['sales_amt'], errors='coerce').fillna(0)\n",
    "if {'sales_amt','qty'}.issubset(df.columns): df['price'] = np.where(df['qty']>0, df['sales_amt']/df['qty'], np.nan)\n",
    "\n",
    "sales = df[[c for c in ['date','store_id','sku_id','qty','price','sales_amt','category_l','category_m','category_s'] if c in df.columns]].copy()\n",
    "product = df[[c for c in ['sku_id','category_l','category_m','category_s'] if c in df.columns]].drop_duplicates().copy() if 'sku_id' in df.columns else pd.DataFrame()\n",
    "\n",
    "# weather（代表列があれば集約）\n",
    "wcols = [c for c in ['天気','最高気温','最低気温','降水量','平均気温','気温差'] if c in df.columns]\n",
    "if wcols and {'date','store_id'}.issubset(df.columns):\n",
    "    wdf = df[['date','store_id']+wcols].copy()\n",
    "    num_cols = [c for c in wcols if c!='天気']\n",
    "    agg = {c:'mean' for c in num_cols}\n",
    "    if '天気' in wcols:\n",
    "        # 最頻値を代表とする\n",
    "        def _mode(x):\n",
    "            m = x.mode()\n",
    "            return m.iloc[0] if not m.empty else x.iloc[0]\n",
    "        agg['天気'] = _mode\n",
    "    weather = wdf.groupby(['date','store_id'], as_index=False).agg(agg)\n",
    "    if '天気' in weather.columns: weather = weather.rename(columns={'天気':'weather'})\n",
    "else:\n",
    "    weather = pd.DataFrame()\n",
    "\n",
    "print('読み込み:', {'raw': raw.shape, 'sales': sales.shape, 'product': product.shape, 'weather': getattr(weather,'shape',None)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KPI/ABC ユーティリティ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_daily_kpi(sales_df, prod_df):\n",
    "    if sales_df is None or sales_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df0 = sales_df.copy()\n",
    "    if 'sales_amt' not in df0.columns:\n",
    "        if {'price','qty'}.issubset(df0.columns):\n",
    "            df0['sales_amt'] = df0['price'] * df0['qty']\n",
    "        else:\n",
    "            df0['sales_amt'] = 0\n",
    "    if not prod_df.empty and 'cost' in prod_df.columns:\n",
    "        df0 = df0.merge(prod_df[['sku_id','cost']], on='sku_id', how='left')\n",
    "        df0['gross_profit'] = df0['sales_amt'] - df0['cost'].fillna(0) * df0['qty'].fillna(0)\n",
    "    agg_map = dict(sales_amt=('sales_amt','sum'), qty=('qty','sum'))\n",
    "    if 'gross_profit' in df0.columns:\n",
    "        agg_map['gross_profit'] = ('gross_profit','sum')\n",
    "    gp = df0.groupby(['date','store_id'], as_index=False).agg(**agg_map)\n",
    "    return gp\n",
    "\n",
    "def abc_analysis(sales_df, prod_df, top_ratio=(0.8,0.95)):\n",
    "    if sales_df is None or sales_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    d = sales_df.copy()\n",
    "    if 'sales_amt' not in d.columns:\n",
    "        if {'price','qty'}.issubset(d.columns):\n",
    "            d['sales_amt'] = d['price'] * d['qty']\n",
    "        else:\n",
    "            d['sales_amt'] = 0\n",
    "    by = d.groupby('sku_id', as_index=False)['sales_amt'].sum().sort_values('sales_amt', ascending=False)\n",
    "    if by['sales_amt'].sum() == 0:\n",
    "        by['cum_ratio'] = 0\n",
    "    else:\n",
    "        by['cum_ratio'] = by['sales_amt'].cumsum()/by['sales_amt'].sum()\n",
    "    a_th, b_th = top_ratio\n",
    "    by['ABC'] = np.where(by['cum_ratio']<=a_th, 'A', np.where(by['cum_ratio']<=b_th, 'B','C'))\n",
    "    if not prod_df.empty:\n",
    "        by = by.merge(prod_df, on='sku_id', how='left')\n",
    "    return by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 店舗選択（複数可）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 店舗選択ウィジェット（この時点では表示のみ、選択は cell-14 で行う）\nstore_opts = sorted(sales['store_id'].dropna().unique().tolist()) if not sales.empty and 'store_id' in sales.columns else []\nif WIDGETS and store_opts:\n    print(f'✅ 店舗選択ウィジェットを準備しました（{len(store_opts)}店舗）')\n    print('👉 下の「6. ダッシュボード」セクションで店舗を選択してください')\nelse:\n    print('⚠️ widgets無効、または店舗データなし')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. 需要予測（PyCaret）\n",
    "- Exogenous: 天候/カレンダー/プロモなど（本サンプルでは未結合）\n",
    "- SKU×店舗の単一系列サンプル予測\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    from pycaret.time_series import setup as ts_setup, compare_models as ts_compare, finalize_model as ts_finalize, predict_model as ts_predict\n    PYCaret_TS=True\nexcept Exception as e:\n    PYCaret_TS=False\n    print(f'PyCaret TS インポートエラー: {e}')\n\n# PyCaret TSは cell-14 のダッシュボードで実行（店舗選択後）\nif PYCaret_TS:\n    print('✅ PyCaret TS 利用可能（ダッシュボードで実行されます）')\nelif not PYCaret_TS:\n    print('⚠️ PyCaret TS 無効（このセクションはスキップされます）')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 特徴量重要度（売上金額）と提案の自動生成\n",
    "- 選択店舗の合算売上（売上金額）を目的変数に、提供特徴量から重要度を推定\n",
    "- sklearnが無い場合は相関係数で代替\n",
    "- 上位特徴量に応じてカテゴリ別の売上差分を算出し、実行提案を出力\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量作成\n",
    "def build_feature_dataset(df_all, stores):\n",
    "    d = df_all.copy()\n",
    "    if stores: d = d[d['store_id'].isin(stores)]\n",
    "    cand = [\n",
    "        '祝日フラグ','土曜フラグ','日曜フラグ','週末フラグ','平日フラグ','休日フラグ','降雨フラグ','弱雨','普通雨','強雨','豪雨',\n",
    "        '最高気温','最低気温','平均気温','気温差','降水量','最高気温_t-1','最高気温_t-7','最低気温_t-1','最低気温_t-7','平均気温_t-1','平均気温_t-7',\n",
    "        '最高気温_MA3','最高気温_MA7','平均気温_MA3','平均気温_MA7','気温トレンド_7d','季節変動指数_月','季節変動指数_週','週'\n",
    "    ]\n",
    "    present = [c for c in cand if c in d.columns]\n",
    "    keep = ['date','store_id','sales_amt'] + present\n",
    "    t = d[keep].copy()\n",
    "    # 日付×店舗で特徴量を代表化（数値は平均）、売上は合計\n",
    "    Xdf = t.groupby(['date','store_id'], as_index=False)[present].mean() if present else t[['date','store_id']].drop_duplicates()\n",
    "    ydf = t.groupby(['date','store_id'], as_index=False)['sales_amt'].sum().rename(columns={'sales_amt':'y'})\n",
    "    feat = Xdf.merge(ydf, on=['date','store_id'], how='inner')\n",
    "    return feat, present\n",
    "\n",
    "# 重要度\n",
    "def rank_features(df_all, stores):\n",
    "    feat, cols = build_feature_dataset(df_all, stores)\n",
    "    if len(feat)<10 or not cols:\n",
    "        return pd.DataFrame(columns=['feature','importance'])\n",
    "    if SK_OK:\n",
    "        try:\n",
    "            model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "            X = feat[cols].fillna(0).values\n",
    "            y = feat['y'].values\n",
    "            model.fit(X, y)\n",
    "            imp = model.feature_importances_\n",
    "            return pd.DataFrame({'feature': cols, 'importance': imp}).sort_values('importance', ascending=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # fallback: 相関\n",
    "    dfm = feat[cols+['y']].copy()\n",
    "    cor = dfm.corr(numeric_only=True)['y'].abs().drop('y', errors='ignore').sort_values(ascending=False)\n",
    "    return cor.reset_index().rename(columns={'index':'feature'})\n",
    "\n",
    "# 提案（フラグ別uplift）\n",
    "def uplift_by_flag(df_all, stores, flag_col, top_n=5):\n",
    "    if flag_col not in df_all.columns: return pd.DataFrame()\n",
    "    d = df_all.copy()\n",
    "    if stores: d = d[d['store_id'].isin(stores)]\n",
    "    if 'category_l' not in d.columns: return pd.DataFrame()\n",
    "    base = d.groupby(['date','store_id','category_l'], as_index=False)['sales_amt'].sum()\n",
    "    flags = d[['date','store_id','category_l', flag_col]].drop_duplicates()\n",
    "    m = base.merge(flags, on=['date','store_id','category_l'], how='left')\n",
    "    a = m[m[flag_col]==1].groupby('category_l', as_index=False)['sales_amt'].mean()\n",
    "    b = m[m[flag_col]!=1].groupby('category_l', as_index=False)['sales_amt'].mean()\n",
    "    if a.empty or b.empty: return pd.DataFrame()\n",
    "    u = a.merge(b, on='category_l', suffixes=('_flag1','_flag0'))\n",
    "    u['uplift'] = (u['sales_amt_flag1']-u['sales_amt_flag0'])/(u['sales_amt_flag0']+1e-6)\n",
    "    return u.sort_values('uplift', ascending=False).head(top_n)\n",
    "\n",
    "# 実行\n",
    "fi = rank_features(df, selected_stores if 'selected_stores' in globals() else [])\n",
    "display(fi.head(20))\n",
    "print(\"\\n--- 提案（カテゴリ別の売上上振れが大きい順）---\")\n",
    "for f in [c for c in ['降雨フラグ','週末フラグ','猛暑日','真夏日','夏日','冬日','真冬日','給料日','給料日直後','月初3日','月末3日'] if c in df.columns]:\n",
    "    top_u = uplift_by_flag(df, selected_stores if 'selected_stores' in globals() else [], f, top_n=5)\n",
    "    if not top_u.empty:\n",
    "        print(f\"[提案キー: {f}]\")\n",
    "        display(top_u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. ダッシュボード（店舗選択 + KPI/ABC/特徴量/提案/アラート）\n",
    "- 店舗の複数選択に対応\n",
    "- 在庫/原価依存のビューは除外（未提供のため）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 店舗複数選択 → 5ビューを同時展開（KPI/ABC/特徴量/提案/アラート）\nif WIDGETS and (not sales.empty):\n    store_opts = sorted(sales['store_id'].dropna().unique().tolist())\n    stores_ms = widgets.SelectMultiple(\n        options=store_opts, \n        value=tuple(store_opts[:1]) if store_opts else tuple(), \n        description='店舗(複数)',\n        rows=min(10, len(store_opts))\n    )\n    out = widgets.Output()\n    \n    print('='*60)\n    print('🏪 店舗を選択してください（複数選択可：Ctrl/Cmd + クリック）')\n    print('='*60)\n    display(stores_ms)\n    display(out)\n\n    def render_all(sel):\n        with out:\n            clear_output(wait=True)\n            if not sel:\n                print('⚠️ 店舗が選択されていません。上のリストから店舗を選択してください。')\n                return\n            \n            print('='*60)\n            print(f\"📊 選択店舗: {', '.join(map(str, sel))}\")\n            print('='*60)\n            \n            ss = sales[sales['store_id'].isin(sel)].copy() if sel else sales.copy()\n            \n            # 1) KPI\n            print('\\n' + '='*60)\n            print('[ビュー 1/5] KPI（日次売上）')\n            print('='*60)\n            print('📌 何を見る: 売上・客数・客単価の日次推移')\n            print('📌 判断基準: 前日比で大きく下振れしていたら、次の「アラート」「提案」で原因を確認')\n            print('-'*60)\n            kpi = compute_daily_kpi(ss, product)\n            if kpi is not None and not kpi.empty and PLOTLY:\n                fig = px.line(kpi, x='date', y='sales_amt', color='store_id', title='売上金額(日次)')\n                fig.show()\n            else:\n                display(kpi.head() if kpi is not None else 'KPIデータ無し')\n            \n            # 2) ABC\n            print('\\n' + '='*60)\n            print('[ビュー 2/5] ABC（SKU寄与）')\n            print('='*60)\n            print('📌 何を見る: A（売上80%）、B（80-95%）、C（95-100%）のSKU分類')\n            print('📌 判断基準: Aは絶対に欠品させない、Cは縮小・入替候補')\n            print('-'*60)\n            ab = abc_analysis(ss, product)\n            if not ab.empty:\n                print(f'✅ A: {len(ab[ab[\"ABC\"]==\"A\"])} SKU, B: {len(ab[ab[\"ABC\"]==\"B\"])} SKU, C: {len(ab[ab[\"ABC\"]==\"C\"])} SKU')\n                display(ab.head(30))\n            else:\n                print('データ無し')\n            \n            # 3) 特徴量重要度\n            print('\\n' + '='*60)\n            print('[ビュー 3/5] 特徴量重要度（売上金額）')\n            print('='*60)\n            print('📌 何を見る: 売上に影響する要因のランキング（天候・曜日・イベント等）')\n            print('📌 判断基準: 上位の要因を「提案」と組み合わせて、陳列・導線を調整')\n            print('-'*60)\n            fi = rank_features(df, sel)\n            if not fi.empty:\n                display(fi.head(20))\n            else:\n                print('データ不足（10行未満）のため、特徴量重要度は計算できません')\n            \n            # 4) 提案\n            print('\\n' + '='*60)\n            print('[ビュー 4/5] 提案（カテゴリ別の売上上振れ候補）')\n            print('='*60)\n            print('📌 何を見る: 各フラグ（降雨/週末/猛暑/給料日等）で売上が伸びるカテゴリ')\n            print('📌 判断基準: 今日該当するフラグの上位カテゴリを、開店前・ピーク前に前出し/フェース増')\n            print('-'*60)\n            flag_found = False\n            for f in [c for c in ['降雨フラグ','週末フラグ','猛暑日','真夏日','夏日','冬日','真冬日','給料日','給料日直後','月初3日','月末3日'] if c in df.columns]:\n                u = uplift_by_flag(df, sel, f, top_n=5)\n                if not u.empty:\n                    flag_found = True\n                    print(f\"\\n🔑 [提案キー: {f}]\")\n                    display(u)\n            if not flag_found:\n                print('提案データなし（該当フラグ列が存在しない、またはデータ不足）')\n            \n            # 5) アラート\n            print('\\n' + '='*60)\n            print('[ビュー 5/5] アラート（3日MA vs 7日MAの乖離）')\n            print('='*60)\n            print('📌 何を見る: 短期トレンド（3日）と中期トレンド（7日）の差が±30%を超えた日')\n            print('📌 判断基準: 上振れ→該当カテゴリのフェース増、下振れ→陳列・導線・値頃訴求の見直し')\n            print('-'*60)\n            tmp = ss.groupby(['date','store_id'], as_index=False)['sales_amt'].sum().sort_values('date')\n            if tmp.empty:\n                print('データ無し')\n            else:\n                tmp['ma3'] = tmp.groupby('store_id')['sales_amt'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n                tmp['ma7'] = tmp.groupby('store_id')['sales_amt'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n                tmp['delta'] = (tmp['ma3'] - tmp['ma7'])/(tmp['ma7']+1e-6)\n                alert = tmp[tmp['delta'].abs()>0.3].copy()\n                if not alert.empty:\n                    print(f'⚠️ アラート発生: {len(alert)} 件（最新20件を表示）')\n                    display(alert.tail(20))\n                else:\n                    print('✅ アラートなし（乖離が30%未満）')\n            \n            print('\\n' + '='*60)\n            print('✅ 全5ビューの表示完了')\n            print('='*60)\n\n    def _on_change(change):\n        if change['name']=='value':\n            render_all(list(change['owner'].value))\n\n    stores_ms.observe(_on_change, names='value')\n    # 初回描画\n    render_all(list(stores_ms.value))\nelse:\n    print('⚠️ widgets未利用、またはデータ無しのため、ダッシュボード展開はスキップ')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}