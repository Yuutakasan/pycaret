#!/usr/bin/env python3
"""
GPUç’°å¢ƒç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
PyCaret + RAPIDSç’°å¢ƒã®å‹•ä½œç¢ºèª
"""

import subprocess
import sys

print("=" * 80)
print("ğŸ” GPUç’°å¢ƒç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
print("=" * 80)

# 1. Pythonç’°å¢ƒç¢ºèª
print("\n1. Pythonç’°å¢ƒ:")
print(f"   Python version: {sys.version}")
print(f"   å®Ÿè¡Œãƒ‘ã‚¹: {sys.executable}")

# 2. CUDAç¢ºèª
print("\n2. CUDAç’°å¢ƒ:")
try:
    cuda_version = subprocess.check_output(["nvcc", "--version"]).decode("utf-8")
    print(f"   NVCC version: {cuda_version.splitlines()[3]}")
except:
    print("   âŒ NVCC not found")

try:
    nvidia_smi = subprocess.check_output(
        ["nvidia-smi"], stderr=subprocess.STDOUT
    ).decode("utf-8")
    print("   âœ… nvidia-smi å®Ÿè¡Œå¯èƒ½")
    # GPUã®ç°¡æ˜“æƒ…å ±ã‚’è¡¨ç¤º
    for line in nvidia_smi.splitlines():
        if "NVIDIA" in line and "Driver" in line:
            print(f"   {line.strip()}")
except:
    print("   âŒ nvidia-smi å®Ÿè¡Œä¸å¯")

# 3. å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª
print("\n3. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª:")

packages = {
    "numpy": "NumPy",
    "pandas": "Pandas",
    "sklearn": "Scikit-learn",
    "pycaret": "PyCaret",
    "cudf": "cuDF (RAPIDS)",
    "cuml": "cuML (RAPIDS)",
    "japanize_matplotlib": "æ—¥æœ¬èªMatplotlib",
    "matplotlib": "Matplotlib",
    "seaborn": "Seaborn",
    "explainerdashboard": "ExplainerDashboard",
    "shap": "SHAP",
}

import_results = {}

for module, name in packages.items():
    try:
        if module == "sklearn":
            import sklearn

            version = sklearn.__version__
        else:
            imported = __import__(module)
            version = (
                imported.__version__ if hasattr(imported, "__version__") else "unknown"
            )
        import_results[name] = f"âœ… {version}"
        print(f"   {name}: âœ… (version: {version})")
    except ImportError as e:
        import_results[name] = f"âŒ {str(e)}"
        print(f"   {name}: âŒ")

# 4. GPUåˆ©ç”¨å¯èƒ½æ€§ç¢ºèª
print("\n4. GPUåˆ©ç”¨å¯èƒ½æ€§:")

# PyTorch GPUç¢ºèª
try:
    import torch

    if torch.cuda.is_available():
        print(f"   PyTorch CUDA: âœ… (GPUæ•°: {torch.cuda.device_count()})")
        print(f"   GPUå: {torch.cuda.get_device_name(0)}")
    else:
        print("   PyTorch CUDA: âŒ")
except:
    print("   PyTorch: Not installed")

# cuML GPUç¢ºèª
try:
    import cuml

    print("   cuML: âœ… GPUå¯¾å¿œ")

    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
    import cudf
    import numpy as np
    from cuml.ensemble import RandomForestRegressor as cuRF

    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    n_samples = 1000
    n_features = 20
    X = np.random.rand(n_samples, n_features).astype(np.float32)
    y = np.random.rand(n_samples).astype(np.float32)

    # cuDFãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    X_cudf = cudf.DataFrame(X)
    y_cudf = cudf.Series(y)

    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    model = cuRF(n_estimators=10)
    model.fit(X_cudf, y_cudf)

    print("   cuML RandomForest: âœ… å‹•ä½œç¢ºèªOK")
except Exception as e:
    print(f"   cuML ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

# 5. PyCaret GPUè¨­å®šç¢ºèª
print("\n5. PyCaret GPUè¨­å®š:")
try:
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§è¨­å®šç¢ºèª
    import pandas as pd

    from pycaret.regression import setup
    from pycaret.utils import check_metric

    dummy_data = pd.DataFrame(
        {"x1": np.random.rand(100), "x2": np.random.rand(100), "y": np.random.rand(100)}
    )

    # GPUä½¿ç”¨ã‚’è©¦è¡Œ
    try:
        s = setup(
            dummy_data,
            target="y",
            session_id=123,
            use_gpu=True,
            html=False,
            verbose=False,
            silent=True,
        )
        print("   PyCaret GPUè¨­å®š: âœ… æœ‰åŠ¹")
    except:
        s = setup(
            dummy_data,
            target="y",
            session_id=123,
            use_gpu=False,
            html=False,
            verbose=False,
            silent=True,
        )
        print("   PyCaret GPUè¨­å®š: âš ï¸ GPUã¯ä½¿ç”¨ä¸å¯ã€CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œ")

except Exception as e:
    print(f"   PyCaretè¨­å®šã‚¨ãƒ©ãƒ¼: {str(e)}")

# 6. æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç¢ºèª
print("\n6. æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç¢ºèª:")
try:
    import matplotlib.font_manager as fm
    import matplotlib.pyplot as plt

    # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆç¢ºèª
    fonts = [f.name for f in fm.fontManager.ttflist]
    jp_fonts = [f for f in fonts if "IPA" in f or "Noto" in f or "æ—¥æœ¬" in f]

    if jp_fonts:
        print(f"   æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ: âœ… {len(jp_fonts)}å€‹æ¤œå‡º")
        print(f"   ä¾‹: {', '.join(jp_fonts[:3])}")
    else:
        print("   æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ: âŒ è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # japanize_matplotlibå‹•ä½œç¢ºèª
    import japanize_matplotlib

    plt.figure(figsize=(6, 4))
    plt.plot([1, 2, 3], [1, 4, 9])
    plt.title("æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ãƒ†ã‚¹ãƒˆ")
    plt.xlabel("æ¨ªè»¸")
    plt.ylabel("ç¸¦è»¸")
    plt.close()
    print("   japanize_matplotlib: âœ… å‹•ä½œç¢ºèªOK")

except Exception as e:
    print(f"   ãƒ•ã‚©ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

# 7. ãƒ¡ãƒ¢ãƒªæƒ…å ±
print("\n7. ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹:")
try:
    import psutil

    # CPUæƒ…å ±
    print(f"   CPUä½¿ç”¨ç‡: {psutil.cpu_percent()}%")
    print(f"   CPUã‚³ã‚¢æ•°: {psutil.cpu_count()}")

    # ãƒ¡ãƒ¢ãƒªæƒ…å ±
    memory = psutil.virtual_memory()
    print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory.percent}%")
    print(f"   åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {memory.available / (1024**3):.1f} GB")

    # GPU ãƒ¡ãƒ¢ãƒªï¼ˆnvidia-ml-pyçµŒç”±ï¼‰
    try:
        import pynvml

        pynvml.nvmlInit()
        device_count = pynvml.nvmlDeviceGetCount()
        for i in range(device_count):
            handle = pynvml.nvmlDeviceGetHandleByIndex(i)
            info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            print(
                f"   GPU {i} ãƒ¡ãƒ¢ãƒª: {info.used / (1024**3):.1f}/{info.total / (1024**3):.1f} GB"
            )
    except:
        pass

except:
    print("   ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼")

print("\n" + "=" * 80)
print("ç’°å¢ƒç¢ºèªå®Œäº†ï¼")

# ã‚µãƒãƒªãƒ¼
errors = [name for name, result in import_results.items() if "âŒ" in result]
if errors:
    print(f"\nâš ï¸ ä»¥ä¸‹ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“: {', '.join(errors)}")
    print("Dockerfileã®å†ãƒ“ãƒ«ãƒ‰ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
else:
    print("\nâœ… ã™ã¹ã¦ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã—ãŸï¼")
    print("PyCaret GPUç’°å¢ƒã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚")

print("=" * 80)
