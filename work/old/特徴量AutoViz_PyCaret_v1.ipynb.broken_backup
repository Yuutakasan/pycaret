{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 🔎 特徴量分析（AutoViz + PyCaret）v1 — AI売上予測ツール\n\n## 📘 このツールの目的\n**AIが売上データを自動分析し、「何が売上に効くか」を教えてくれるツールです。**\n\n### 🎯 できること\n1. グラフで視覚的に売上パターンを確認（AutoViz）\n2. AI が重要な要因を自動で見つける（PyCaret）\n3. 予測モデルを作成し、精度を数値で確認\n\n---\n\n## 🚀 使い方（簡単3ステップ）\n1. **セルを上から順に実行**（各セルで Shift+Enter を押す）\n2. **グラフを見て、パターンを確認**\n3. **重要度ランキングで、注目すべき要因を特定**\n\n---\n\n**それでは、以下のセルを順番に実行してください。各セクションに「何を見るか」「どう判断するか」が書いてあります。**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ライブラリと環境\nimport warnings; warnings.filterwarnings('ignore')\nimport os, sys\nfrom pathlib import Path\nimport pandas as pd, numpy as np\n\n# 日本語フォント（Matplotlib/Plotly）\nimport font_setup  # IPAGothic等を自動設定\n\n# AutoViz\ntry:\n    from autoviz.AutoViz_Class import AutoViz_Class\n    AV_OK = True\nexcept Exception:\n    AV_OK = False\n\n# PyCaret（回帰）\ntry:\n    from pycaret.regression import setup, compare_models, pull, finalize_model, predict_model, plot_model\n    PYC_OK = True\nexcept Exception:\n    PYC_OK = False\n\n# バージョン情報\nprint(f'Python: {sys.version.split()[0]}')\nprint(f'pandas: {pd.__version__}, numpy: {np.__version__}')\nprint(f'AutoViz: {AV_OK}, PyCaret.regression: {PYC_OK}')\n\n# PyCaretの最小サンプル数（3-fold CVに必要）\nMIN_SAMPLES_PYCARET = 100\n\n# ========================================\n# 🚀 GPU検出と設定\n# ========================================\nprint('\\n' + '='*60)\nprint('🖥️ GPU検出')\nprint('='*60)\n\n# GPU利用可能性をチェック\nGPU_AVAILABLE = False\nGPU_DEVICE = 'cpu'\n\ntry:\n    import torch\n    if torch.cuda.is_available():\n        GPU_AVAILABLE = True\n        GPU_DEVICE = 'cuda'\n        print(f'✅ NVIDIA GPU検出: {torch.cuda.get_device_name(0)}')\n        print(f'   CUDA Version: {torch.version.cuda}')\n        print(f'   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n    else:\n        print('⚠️ PyTorch installed but no CUDA GPU found')\nexcept ImportError:\n    print('ℹ️ PyTorch not installed (GPU detection skipped)')\n\n# LightGBM GPU対応チェック\ntry:\n    import lightgbm as lgb\n    if GPU_AVAILABLE:\n        print('✅ LightGBM GPU対応: 可能')\n    else:\n        print('ℹ️  LightGBM: CPU mode')\nexcept ImportError:\n    print('ℹ️ LightGBM not installed')\n\n# XGBoost GPU対応チェック\ntry:\n    import xgboost as xgb\n    if GPU_AVAILABLE:\n        print('✅ XGBoost GPU対応: 可能')\n    else:\n        print('ℹ️ XGBoost: CPU mode')\nexcept ImportError:\n    print('ℹ️ XGBoost not installed')\n\n# CatBoost GPU対応チェック\ntry:\n    import catboost\n    if GPU_AVAILABLE:\n        print('✅ CatBoost GPU対応: 可能')\n    else:\n        print('ℹ️ CatBoost: CPU mode')\nexcept ImportError:\n    print('ℹ️ CatBoost not installed')\n\n# GPU使用フラグ（ユーザーが変更可能）\nUSE_GPU = GPU_AVAILABLE  # Trueに設定するとGPUを使用（GPUが利用可能な場合のみ）\n\nif USE_GPU:\n    print(f'\\n🚀 GPU使用: 有効（推定2～10倍高速化）')\n    print(f'   Device: {GPU_DEVICE}')\nelse:\n    print(f'\\nℹ️ GPU使用: 無効（CPUモードで実行）')\n    if GPU_AVAILABLE:\n        print('   💡 ヒント: 上のセルで USE_GPU = True に設定するとGPU使用可能')\n\nprint('='*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================",
    "# 🔧 GPU/CPU データフレーム変換ユーティリティ",
    "# ========================================",
    "",
    "def to_gpu(df):",
    "    \"\"\"pandasデータフレームをGPU (cuDF) に変換（USE_GPU=Trueの場合のみ）\"\"\"",
    "    if USE_GPU and CUDF_AVAILABLE and df is not None and not df.empty:",
    "        try:",
    "            import cudf",
    "            return cudf.from_pandas(df)",
    "        except Exception as e:",
    "            print(f'⚠️ GPU変換失敗、CPUモード継続: {e}')",
    "            return df",
    "    return df",
    "",
    "def to_cpu(df):",
    "    \"\"\"cuDFデータフレームをpandasに変換\"\"\"",
    "    if df is None:",
    "        return None",
    "    try:",
    "        import cudf",
    "        if isinstance(df, cudf.DataFrame):",
    "            return df.to_pandas()",
    "    except:",
    "        pass",
    "    return df",
    "",
    "# GPUメモリ使用状況表示",
    "def show_gpu_memory():",
    "    if GPU_AVAILABLE:",
    "        try:",
    "            import torch",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3",
    "            reserved = torch.cuda.memory_reserved(0) / 1024**3",
    "            print(f'📊 GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved')",
    "        except:",
    "            pass",
    "",
    "if USE_GPU and CUDF_AVAILABLE:",
    "    print('✅ GPU高速化ユーティリティ: 準備完了')",
    "    print('   to_gpu(df) でGPU処理、to_cpu(df) でCPU戻し')",
    "    show_gpu_memory()",
    "else:",
    "    print('ℹ️ CPU処理モード（GPUユーティリティは無効）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# フォント強制リセット（日本語対応 / AutoViz対策）\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "try:\n",
    "    import japanize_matplotlib; japanize_matplotlib.japanize()\n",
    "except Exception:\n",
    "    pass\n",
    "candidates = ['IPAGothic','IPAexGothic','Noto Sans CJK JP','Noto Sans JP','Yu Gothic','Meiryo','Hiragino Sans','MS Gothic']\n",
    "avail = []\n",
    "try:\n",
    "    names = [getattr(f,'name','') for f in fm.fontManager.ttflist]\n",
    "    for nm in candidates:\n",
    "        if any(nm in n for n in names):\n",
    "            if nm not in avail:\n",
    "                avail.append(nm)\n",
    "except Exception:\n",
    "    pass\n",
    "if not avail:\n",
    "    avail = ['Noto Sans CJK JP','IPAGothic','DejaVu Sans']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = avail + ['DejaVu Sans']\n",
    "plt.rcParams['font.serif'] = ['Noto Serif CJK JP','IPAMincho','DejaVu Serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "try:\n",
    "    sns.set_theme(rc={'font.family':'sans-serif','font.sans-serif': plt.rcParams['font.sans-serif']})\n",
    "except Exception:\n",
    "    pass\n",
    "print('フォント設定:', plt.rcParams['font.family'], '→', plt.rcParams['font.sans-serif'][:3], '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 📂 ステップ1: データ読み込み\n\n### 🎯 **このセクションの目的**\n売上データ（CSV形式）を自動検出して読み込みます。\n\n### 👀 **店長が確認すべきこと**\n実行後、以下のメッセージが表示されます：\n```\n[INFO] glob検出: output/06_final_enriched_20250701_20250930.csv\n[INFO] 列名変換: 8/8 件適用 → ['store_id', 'sku_id', 'date'...]\n読み込み完了: 06_final_enriched_20250930.csv | shape=(50000, 40) | memory=15.2MB\n```\n\n**意味**:\n- `shape=(50000, 40)` → 50,000行×40列のデータ\n- `memory=15.2MB` → メモリ使用量\n\n**判断ポイント**:\n- データが見つからない場合 → `output`フォルダにCSVファイルがあるか確認\n- メモリ不足エラーが出る場合 → データ期間を短縮検討\n\n---\n\n**次のセルを実行してください ↓**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def pick_enriched_csv():\n    \"\"\"\n    enriched CSVファイルを自動検出\n    優先順: 環境変数 → glob最新 → 既定値\n    \"\"\"\n    for env in ('DATA_PATH','ENRICHED_CSV'):\n        p = os.environ.get(env)\n        if p and Path(p).exists():\n            print(f'[INFO] 環境変数 {env} からファイル取得: {p}')\n            return Path(p)\n    d = Path('output')\n    if d.exists():\n        c = sorted(d.glob('06_final_enriched_*.csv'), reverse=True)\n        if c:\n            print(f'[INFO] glob検出: {c[0]}')\n            return c[0]\n    f = Path('output/06_final_enriched_20250701_20250930.csv')\n    if f.exists():\n        print(f'[INFO] 既定ファイル使用: {f}')\n        return f\n    return None\n\nCSV_PATH = pick_enriched_csv()\nif not CSV_PATH:\n    raise FileNotFoundError('output/06_final_enriched_*.csv が見つかりません。work/output に配置、または環境変数 DATA_PATH で指定してください。')\n\n# メモリチェック（オプション）\ntry:\n    import psutil\n    file_size_mb = CSV_PATH.stat().st_size / (1024**2)\n    available_mem_mb = psutil.virtual_memory().available / (1024**2)\n    if file_size_mb > available_mem_mb * 0.5:\n        print(f'[WARNING] ファイルサイズ {file_size_mb:.1f}MB が利用可能メモリの50%超')\nexcept ImportError:\n    pass\n\ndf_raw = pd.read_csv(CSV_PATH, encoding='utf-8-sig')\ndf = df_raw.copy()\n\n# 列名正規化（存在すれば）\nrename_map = {\n    '店舗':'store_id','商品名':'sku_id','日付':'date','売上数量':'qty','売上金額':'sales_amt',\n    'フェイスくくり大分類':'category_l','フェイスくくり中分類':'category_m','フェイスくくり小分類':'category_s'\n}\nrenamed = {k:v for k,v in rename_map.items() if k in df.columns}\ndf = df.rename(columns=renamed)\nprint(f'[INFO] 列名変換: {len(renamed)}/{len(rename_map)} 件適用 → {list(renamed.values())}')\n\nif 'date' in df.columns: df['date'] = pd.to_datetime(df['date'])\nif 'qty' in df.columns: df['qty'] = pd.to_numeric(df['qty'], errors='coerce').fillna(0).astype('float32')\nif 'sales_amt' in df.columns: df['sales_amt'] = pd.to_numeric(df['sales_amt'], errors='coerce').fillna(0).astype('float32')\n\nprint(f'読み込み完了: {CSV_PATH.name} | shape={df.shape} | memory={df.memory_usage(deep=True).sum()/(1024**2):.1f}MB')\ndf.head(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 ステップ2: 売上最大化のためのフラグ別売上分析",
    "",
    "### 🎯 **このセクションの目的**",
    "**売上を最大化するために、どのフラグ（天候・曜日・イベント等）の日に売上が伸びるかを分析します。**",
    "",
    "### ⚠️ **重要な変更点（従来のAutoVizから変更）**",
    "- ❌ **削除**: 日付ベースの時系列プロット（日付と売上の比較）",
    "- ✅ **追加**: フラグ別の売上比較（降雨フラグ、週末フラグ等と売上の相関）",
    "- ✅ **追加**: 商品カテゴリ選択機能（特定カテゴリに絞った分析が可能）",
    "",
    "### 📈 **何が分析されるか**",
    "",
    "#### 1️⃣ **フラグ別売上増加率ランキング**",
    "- 各フラグ（降雨、週末、猛暑日など）がONの日とOFFの日で、売上がどれだけ変わるかを計算",
    "- 売上増加率が高いフラグ = 売上最大化のチャンス日",
    "",
    "#### 2️⃣ **フラグ別売上分布の可視化**",
    "- フラグON時とOFF時の売上分布を比較",
    "- どのフラグの日に高額売上が発生しやすいかを視覚的に把握",
    "",
    "#### 3️⃣ **カテゴリ別分析**",
    "- 商品カテゴリを選択して、カテゴリごとの売上パターンを分析",
    "- 例: 「飲料」カテゴリは猛暑日に売上↑、「おでん」は冬日に売上↑",
    "",
    "### 👀 **店長が確認すべきこと**",
    "",
    "#### ✅ **実行後に表示される情報**",
    "1. **フラグ別売上増加率 TOP10 テーブル**",
    "   - 各フラグのON/OFF時の平均売上",
    "   - 売上増加率（%）",
    "   - 該当日数",
    "",
    "2. **フラグ別売上増加率の棒グラフ**",
    "   - 赤い棒（プラス）: このフラグの日は売上が増加 → **陳列・発注を強化すべき日**",
    "   - 青い棒（マイナス）: このフラグの日は売上が減少 → 在庫を抑制",
    "",
    "3. **上位5フラグのON/OFF売上分布グラフ**",
    "   - 赤い分布（フラグON）が右にシフト → そのフラグの日は高額売上が発生しやすい",
    "   - 青い分布（フラグOFF）との差が大きい → そのフラグの影響が大きい",
    "",
    "### 💡 **店長の実務アクション**",
    "",
    "#### 🎯 **売上増加率が高いフラグが見つかった場合**",
    "",
    "**例: 「降雨フラグ」の売上増加率 +25%**",
    "→ **アクション**:",
    "- 降雨予報の日の前日に、温かい総菜・カップ麺・ホット飲料の発注を1.3倍に増やす",
    "- 入口付近に傘・レインコート・ホット商品の特設コーナーを設置",
    "- 中華まん・おでんのフェースを拡大",
    "",
    "**例: 「週末フラグ」の売上増加率 +18%**",
    "→ **アクション**:",
    "- 金曜夕方から弁当・デザート・酒類の陳列を強化",
    "- 土日の朝は朝食需要（パン・コーヒー）、昼は弁当、夕方は酒類のピーク対応",
    "- 家族向け大容量商品のフェース拡大",
    "",
    "**例: 「給料日フラグ」の売上増加率 +12%**",
    "→ **アクション**:",
    "- 給料日（25日前後）は高単価弁当・スイーツ・プレミアム商品を目立つ位置に",
    "- 夕方の前出し時間を早める（17時→16時30分）",
    "",
    "#### 📊 **カテゴリ選択の活用方法**",
    "",
    "上のウィジェット（SelectMultiple）で商品カテゴリを選択すると、そのカテゴリに特化したフラグ分析が再実行されます。",
    "",
    "**使い方**:",
    "1. ウィジェットから分析したいカテゴリを選択（Ctrl/Cmd + クリックで複数選択）",
    "2. 自動で再分析が実行され、そのカテゴリの売上最大化フラグが表示される",
    "3. カテゴリごとの最適な発注・陳列戦略を立てる",
    "",
    "**例**:",
    "- **「飲料」**を選択 → 「猛暑日」「真夏日」フラグで売上↑ → 夏日の冷飲料発注強化",
    "- **「弁当」**を選択 → 「週末フラグ」「昼ピーク」で売上↑ → 土日の弁当発注1.5倍",
    "- **「デザート」**を選択 → 「給料日」「週末」で売上↑ → 高単価スイーツ陳列強化",
    "",
    "### 🚀 **実行方法**",
    "下のセルを実行してください。自動で以下が行われます:",
    "1. カテゴリ選択ウィジェットの表示（複数選択可）",
    "2. 全カテゴリでのフラグ別売上分析",
    "3. TOP10フラグの表示とグラフ可視化",
    "4. カテゴリ選択時の自動再分析",
    "",
    "### 💾 **GPU高速化について**",
    "- このセルでは主にグラフ描画を行うため、GPU効果は限定的です",
    "- 次のステップ（PyCaret）で大規模なAI学習が実行され、GPUの効果が最大化されます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================# 📊 ステップ2: 売上最大化のための特徴量分析# ========================================print('='*60)print('📊 売上最大化分析: カテゴリ選択 + フラグ別売上比較')print('='*60)# カテゴリ選択（ipywidgets）if WIDGETS and 'category_l' in df.columns:    category_opts = ['全カテゴリ'] + sorted(df['category_l'].dropna().unique().tolist())    category_selector = widgets.SelectMultiple(        options=category_opts,        value=tuple(['全カテゴリ']),        description='商品カテゴリ:',        rows=min(10, len(category_opts))    )    print('✅ カテゴリ選択ウィジェット準備完了')    print('👉 下から分析したいカテゴリを選択してください（複数選択可：Ctrl/Cmd + クリック）')    display(category_selector)else:    print('⚠️ カテゴリ列が存在しないため、全データで分析します')    category_selector = None# フラグ別売上比較の実行def analyze_sales_by_flags(df_all, selected_categories=None):    \"\"\"    売上最大化のためのフラグ別売上分析    - 日付ベースの時系列ではなく、フラグ条件別の売上を比較    - 各フラグが売上に与える影響を定量化    \"\"\"    import matplotlib.pyplot as plt    from matplotlib.font_manager import FontProperties        # 日本語フォント設定（JP_FP使用）    JP_FP = FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc') if Path('/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc').exists() else None    if JP_FP is None:        try:            import japanize_matplotlib            japanize_matplotlib.japanize()        except:            pass        # カテゴリフィルタリング    d = df_all.copy()    if selected_categories and '全カテゴリ' not in selected_categories and 'category_l' in d.columns:        d = d[d['category_l'].isin(selected_categories)]        cat_label = f\"カテゴリ: {', '.join(selected_categories)}\"    else:        cat_label = \"全カテゴリ\"        if d.empty:        print('⚠️ 選択されたカテゴリにデータがありません')        return        print(f'\\n分析対象: {cat_label} | データ行数: {len(d):,}')        # フラグ列を検出    flag_cols = [c for c in d.columns if 'フラグ' in c or c in ['猛暑日', '真夏日', '夏日', '冬日', '真冬日', '給料日', '給料日直後', '月初3日', '月末3日']]        if not flag_cols:        print('⚠️ フラグ列が見つかりません')        return        print(f'\\n検出されたフラグ: {len(flag_cols)}個')    for fc in flag_cols[:10]:  # 最初の10個を表示        print(f'  - {fc}')    if len(flag_cols) > 10:        print(f'  ... 他{len(flag_cols)-10}個')        # フラグ別の平均売上を計算    flag_impact = []        for flag_col in flag_cols:        if flag_col not in d.columns:            continue                # フラグON時の平均売上        sales_on = d[d[flag_col] == 1]['sales_amt'].mean() if 'sales_amt' in d.columns else 0                # フラグOFF時の平均売上        sales_off = d[d[flag_col] != 1]['sales_amt'].mean() if 'sales_amt' in d.columns else 0                # 売上増加率（Uplift）        if sales_off > 0:            uplift_pct = ((sales_on - sales_off) / sales_off) * 100        else:            uplift_pct = 0                # 該当日数        days_on = (d[flag_col] == 1).sum() if flag_col in d.columns else 0                flag_impact.append({            'フラグ': flag_col,            'フラグON時平均売上': sales_on,            'フラグOFF時平均売上': sales_off,            '売上増加率(%)': uplift_pct,            '該当日数': days_on        })        # DataFrame化して売上増加率でソート    impact_df = pd.DataFrame(flag_impact).sort_values('売上増加率(%)', ascending=False)        print(f'\\n' + '='*60)    print(f'🎯 売上最大化のための重要フラグ TOP10 ({cat_label})')    print('='*60)    print('💡 売上増加率が高いフラグの日は、該当カテゴリの陳列・発注を強化すべき日です\\n')    display(impact_df.head(10))        # 可視化1: フラグ別売上増加率（棒グラフ）    top10 = impact_df.head(10)    if not top10.empty:        fig, ax = plt.subplots(figsize=(12, 6))        colors = ['#FF4B4B' if x > 0 else '#4B4BFF' for x in top10['売上増加率(%)']]        ax.barh(top10['フラグ'], top10['売上増加率(%)'], color=colors)        ax.set_xlabel('売上増加率 (%)', fontproperties=JP_FP, fontsize=12)        ax.set_title(f'フラグ別売上増加率 TOP10 ({cat_label})', fontproperties=JP_FP, fontsize=14, fontweight='bold')        ax.axvline(0, color='black', linewidth=0.8, linestyle='--')        ax.grid(axis='x', alpha=0.3)                # Y軸ラベルに日本語フォント適用        if JP_FP:            ax.set_yticklabels(top10['フラグ'], fontproperties=JP_FP)                plt.tight_layout()        plt.show()                print('\\n📊 グラフの見方:')        print('  - 赤い棒（プラス）: このフラグの日は売上が増加 → 陳列・発注強化')        print('  - 青い棒（マイナス）: このフラグの日は売上が減少 → 在庫抑制')        # 可視化2: フラグON/OFF時の売上分布比較（上位5フラグ）    top5_flags = impact_df.head(5)['フラグ'].tolist()        if top5_flags:        print(f'\\n' + '='*60)        print(f'📈 上位5フラグのON/OFF売上分布比較')        print('='*60)                fig, axes = plt.subplots(2, 3, figsize=(16, 10))        axes = axes.flatten()                for idx, flag_col in enumerate(top5_flags):            if idx >= 6:                break                        if flag_col not in d.columns:                continue                        ax = axes[idx]                        # フラグON/OFF別の売上分布            sales_on = d[d[flag_col] == 1]['sales_amt'].dropna()            sales_off = d[d[flag_col] != 1]['sales_amt'].dropna()                        ax.hist(sales_on, bins=30, alpha=0.7, label=f'{flag_col} ON', color='red', edgecolor='black')            ax.hist(sales_off, bins=30, alpha=0.5, label=f'{flag_col} OFF', color='blue', edgecolor='black')                        ax.set_xlabel('売上金額', fontproperties=JP_FP, fontsize=10)            ax.set_ylabel('頻度', fontproperties=JP_FP, fontsize=10)            ax.set_title(f'{flag_col} の売上分布', fontproperties=JP_FP, fontsize=11, fontweight='bold')            ax.legend(prop=JP_FP)            ax.grid(alpha=0.3)                # 残りの空セルを非表示        for idx in range(len(top5_flags), 6):            axes[idx].axis('off')                plt.tight_layout()        plt.show()                print('\\n📊 グラフの見方:')        print('  - 赤い分布（フラグON）が右にシフト → そのフラグの日は売上が高い傾向')        print('  - 青い分布（フラグOFF）が左 → 通常日の売上')        return impact_df# 分析実行（カテゴリ選択なしで全データ）if 'sales_amt' in df.columns:    print('\\n🚀 分析開始: 全カテゴリで実行')    impact_result = analyze_sales_by_flags(df, selected_categories=None)else:    print('⚠️ sales_amt列が存在しないため、分析をスキップします')    impact_result = None# カテゴリ選択時の再分析（ウィジェットがあれば）if category_selector is not None:    def on_category_change(change):        if change['name'] == 'value':            selected = list(change['owner'].value)            print('\\n' + '='*60)            print(f'🔄 カテゴリ再選択: {selected}')            print('='*60)            analyze_sales_by_flags(df, selected_categories=selected)        category_selector.observe(on_category_change, names='value')    print('\\n✅ カテゴリ選択ウィジェット有効化')    print('👉 上のウィジェットでカテゴリを変更すると、自動で再分析されます')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🔧 ステップ3: 特徴量テーブルの作成\n\n### 🎯 **このセクションの目的**\nAIが分析しやすいように、データを日次×店舗単位に整理します。\n\n### 👀 **店長が確認すべきこと**\n実行後、以下のメッセージが表示されます：\n```\n[INFO] 利用可能特徴量: 28/30 個\n[INFO] カテゴリカル変数: ['category_l', 'category_m', 'store_id']\n[INFO] 特徴量テーブル: (2500, 35) (行×列)\n[INFO] 欠損値: 150 個\n```\n\n**意味**:\n- **28個の要因**（気温、曜日、天気など）を使用\n- **2,500日分**のデータで分析\n- 欠損値は自動処理される\n\n### 💡 **追加された特徴量の意味**\nこのセルで、以下の便利な特徴量が自動追加されます：\n\n| 特徴量 | 意味 | 実務での活用 |\n|--------|------|------------|\n| `sales_lag_1` | 前日の売上 | 「昨日売れたから今日も売れる」パターン発見 |\n| `sales_lag_7` | 1週間前の売上 | 「先週の月曜と今週の月曜は似ている」パターン発見 |\n| `sales_rolling_7` | 7日移動平均 | トレンド把握（売上が伸びているか下がっているか） |\n| `day_of_week` | 曜日（0=月曜、6=日曜） | 曜日別の売上パターン分析 |\n| `is_weekend` | 週末フラグ（土日=1） | 週末効果の測定 |\n\n**判断ポイント**:\n- 欠損値が50%超の列 → 自動で除外される\n- 特徴量が10個未満 → データ期間を延長検討\n\nこのセルは自動実行するだけでOKです。\n\n---\n\n**次のセルを実行してください ↓**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 全ての数値列を特徴量として使用（事前の絞り込みなし）\nprint('[INFO] データに含まれる全ての列を使用します（事前絞り込みなし）')\n\n# 除外すべき列（分析対象でない列）\nexclude_cols = ['店舗', '商品名', '日付', 'date', 'store_id', 'sku_id', \n                'category_l', 'category_m', 'category_s',\n                'フェイスくくり大分類', 'フェイスくくり中分類', 'フェイスくくり小分類',\n                '売上数量', '売上金額', 'qty', 'sales_amt', 'price',\n                '昨年同日_売上', '昨年同日_客数', '昨年同日_客単価']  # 目的変数と関連列を除外\n\n# 全列リスト\nall_cols = df.columns.tolist()\n\n# 数値列のみ抽出（文字列・日付型を除く）\nnumeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n\n# 特徴量候補：数値列から除外列を引く\nfeature_cols = [c for c in numeric_cols if c not in exclude_cols]\n\nprint(f'[INFO] 全列数: {len(all_cols)}')\nprint(f'[INFO] 数値列数: {len(numeric_cols)}')\nprint(f'[INFO] 除外列数: {len([c for c in exclude_cols if c in all_cols])}')\nprint(f'[INFO] 使用する特徴量: {len(feature_cols)} 個')\nprint(f'\\n[特徴量リスト（全{len(feature_cols)}個）]:')\nfor i, col in enumerate(feature_cols, 1):\n    print(f'  {i}. {col}')\n\n# カテゴリカル変数の確認\ncategorical_cols = df.select_dtypes(include=['object']).columns.tolist()\ncategorical_present = [c for c in categorical_cols if c not in exclude_cols and c in df.columns]\nprint(f'\\n[INFO] カテゴリカル変数: {len(categorical_present)} 個 → {categorical_present}')\n\n# 基本テーブル構築（全ての数値特徴量を使用）\nkeep = ['date', 'store_id', 'sales_amt'] + feature_cols\ntmp = df[[c for c in keep if c in df.columns]].copy()\n\n# 日付×店舗で特徴量を代表化（数値は平均）、売上は合計\nXdf = tmp.groupby(['date','store_id'], as_index=False)[feature_cols].mean() if feature_cols else tmp[['date','store_id']].drop_duplicates()\nydf = tmp.groupby(['date','store_id'], as_index=False)['sales_amt'].sum()\nfeat = Xdf.merge(ydf, on=['date','store_id'], how='inner')\n\n# カテゴリカル変数の追加（元データから）\nif categorical_present:\n    cat_data = df[['date','store_id'] + categorical_present].drop_duplicates()\n    feat = feat.merge(cat_data, on=['date','store_id'], how='left')\n    print(f'[INFO] カテゴリカル変数をマージ: {categorical_present}')\n\nprint(f'\\n[INFO] 特徴量テーブル: {feat.shape} (行×列)')\nprint(f'[INFO] 欠損値: {feat.isnull().sum().sum()} 個 ({feat.isnull().sum().sum() / feat.size * 100:.2f}%)')\n\n# 欠損値が多い列を警告\nmissing_ratio = feat.isnull().sum() / len(feat)\nhigh_missing = missing_ratio[missing_ratio > 0.5].sort_values(ascending=False)\nif not high_missing.empty:\n    print(f'\\n[WARNING] 欠損値50%超の列（{len(high_missing)}個）:')\n    for col, ratio in high_missing.items():\n        print(f'  - {col}: {ratio*100:.1f}% 欠損')\n\nfeat.head(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🤖 ステップ4: PyCaret — AIで売上予測モデルを作成\n\n### 🎯 **このセクションの目的**\n**PyCaretの全回帰モデル（15～20種類）を自動で試し、どのモデルが一番売上を予測できるか競わせます。**\n\n---\n\n### 📊 **比較されるモデル（全種類）**\n\n以下のモデルが自動的に比較されます：\n\n| カテゴリ | モデル名 | 特徴 |\n|----------|----------|------|\n| **線形モデル** | Linear Regression (lr) | シンプル、解釈しやすい |\n| | Ridge Regression (ridge) | 過学習を防ぐ線形モデル |\n| | Lasso Regression (lasso) | 不要な特徴を自動除外 |\n| | Elastic Net (en) | Ridge + Lasso の組み合わせ |\n| | Least Angle Regression (lar) | 特徴選択に優れる |\n| | Lasso Least Angle Regression (llar) | LAR + Lasso |\n| | Orthogonal Matching Pursuit (omp) | スパースモデル |\n| **木ベースモデル** | Decision Tree (dt) | ルールベース、解釈しやすい |\n| | Random Forest (rf) | 高精度、安定性が高い |\n| | Extra Trees (et) | Random Forestの改良版 |\n| | Gradient Boosting (gbr) | 高精度、複雑なパターン対応 |\n| | AdaBoost (ada) | 弱学習器の組み合わせ |\n| **高度なモデル** | Light Gradient Boosting (lightgbm) | 高速・高精度 |\n| | CatBoost (catboost) | カテゴリ変数に強い |\n| | XGBoost (xgboost) | コンペで人気の高精度モデル |\n| **その他** | K Neighbors Regressor (knn) | 近傍ベース |\n| | Support Vector Regressor (svm) | サポートベクターマシン |\n| | Huber Regressor (huber) | 外れ値に強い |\n| | Bayesian Ridge (br) | ベイズ統計ベース |\n| | Passive Aggressive (par) | オンライン学習向け |\n\n**合計: 15～20種類のモデルを自動比較**\n\n---\n\n### 👀 **店長が見るべき情報と判断方法**\n\n#### **📊 Leaderboard（成績表）の見方**\n\n実行すると、全モデルの比較結果が表示されます：\n\n| Model（モデル名） | R2 | RMSE | MAE | RMSLE | MAPE |\n|-------------------|-----|------|-----|-------|------|\n| **lightgbm** | **0.87** | 1050 | 820 | 0.15 | 0.12 |\n| xgboost | 0.86 | 1100 | 850 | 0.16 | 0.13 |\n| catboost | 0.85 | 1150 | 880 | 0.17 | 0.14 |\n| rf | 0.83 | 1250 | 920 | 0.18 | 0.15 |\n| gbr | 0.82 | 1300 | 950 | 0.19 | 0.16 |\n| ... | ... | ... | ... | ... | ... |\n\n**各列の意味**:\n- **R2（決定係数）**: **最重要指標** — 予測精度（0～1、高いほど良い）\n- **RMSE**: 予測誤差の平均（小さいほど良い）\n- **MAE**: 絶対誤差の平均（小さいほど良い）\n- **RMSLE**: 対数スケールの誤差（小さいほど良い）\n- **MAPE**: パーセント誤差（小さいほど良い、0.2未満が実用レベル）\n\n---\n\n### 📈 **R2スコアの読み方**\n\n| R2の値 | 意味 | 実務での判断 |\n|--------|------|------------|\n| **0.8以上** | 非常に優秀 | ✅ このモデルで来週の発注計画を立ててOK |\n| **0.6～0.8** | まあまあ使える | ✅ 補助的に使用（店長の経験と併用） |\n| **0.5～0.6** | やや不足 | ⚠️ データ期間を延長するか、要因を追加検討 |\n| **0.5未満** | 予測精度低い | ❌ プロモ情報・競合情報などを追加が必要 |\n\n---\n\n### 🏆 **上位モデルの特徴**\n\n#### **LightGBM / XGBoost / CatBoost が上位の場合**\n- **意味**: 売上が複雑な要因で決まる（天候・曜日・イベントの組み合わせ）\n- **メリット**: 高精度で、非線形パターンを捉えられる\n- **実務**: 次の「特徴量重要度」で主要因を特定し、重点対策\n\n#### **Random Forest / Gradient Boosting が上位の場合**\n- **意味**: データにノイズがあるが、パターンは捉えられる\n- **メリット**: 安定性が高く、外れ値に強い\n- **実務**: 特徴量重要度トップ5を毎週チェック\n\n#### **Linear Regression / Ridge が上位の場合**\n- **意味**: 売上がシンプルな要因で決まる（気温・曜日など）\n- **メリット**: 解釈しやすく、説明が簡単\n- **実務**: 1～2個の主要因に集中対策\n\n---\n\n### 💻 **GPU使用について**\n\n**Q: このAI予測処理にGPUは使われていますか？**\n\n**A: いいえ、デフォルトではCPUのみで実行されます。**\n\n#### **GPUを使用する方法**\n\n特定のモデルはGPUで高速化できます：\n\n| モデル | GPU対応 | 設定方法 |\n|--------|---------|----------|\n| **LightGBM** | ✅ 対応 | `device='gpu'` パラメータを追加 |\n| **XGBoost** | ✅ 対応 | `tree_method='gpu_hist'` パラメータを追加 |\n| **CatBoost** | ✅ 対応 | `task_type='GPU'` パラメータを追加 |\n| Random Forest | ❌ 非対応 | CPU のみ |\n| Gradient Boosting | ❌ 非対応 | CPU のみ |\n\n**GPU使用例（LightGBM）**:\n```python\nfrom pycaret.regression import create_model\nlgbm_gpu = create_model('lightgbm', device='gpu')\n```\n\n**GPU使用のメリット**:\n- 学習時間が2～10倍高速化\n- 大量データ（10万行以上）で効果大\n- 商品数が多い場合（1000+ SKU）に有効\n\n**注意点**:\n- GPU対応ライブラリのインストールが必要（`pip install lightgbm --config-settings=cmake.args=\"-DUSE_GPU=1\"`）\n- NVIDIA GPU + CUDA環境が必要\n- 小規模データ（数千行）ではCPUの方が速い場合もある\n\n---\n\n### 🔍 **Feature Importance（重要度グラフ）の見方**\n\nLeaderboardの後に、最良モデルの特徴量重要度グラフが表示されます。\n\n**読み方**:\n- 横軸：各特徴量の重要度（0～1）\n- 縦軸：特徴量名\n- **重要度が高い = 売上への影響が大きい**\n\n**実務アクション（重要度別）**:\n\n| 重要度 | アクション |\n|--------|-----------|\n| **30%以上** | 🔴 毎日チェック必須（例：天気予報を毎朝確認） |\n| **15～30%** | 🟡 週1回チェック（例：週末発注を木曜に確認） |\n| **5～15%** | 🟢 月1回チェック（例：給料日前の陳列を月初に計画） |\n| **5%未満** | ⚪ 参考程度 |\n\n---\n\n### 📊 **残差プロット（Residuals Plot）の見方**\n\nFeature Importanceの後に表示されるグラフ。\n\n**見るべきポイント**:\n```\n✅ 点がランダムに散らばっている → モデルが正しく機能\n⚠️ パターンが見える（右上がり/右下がり） → モデルに改善余地\n⚠️ 極端な外れ値がある → 異常日を検出（セール日など）\n```\n\n**実務での使い方**:\n- ランダム分布 → このモデルで予測してOK\n- パターンあり → データ追加（プロモ情報等）を検討\n- 外れ値 → 「セール日」「競合店開店日」などを記録\n\n---\n\n### ⏱️ **実行時間の目安**\n\n| データ規模 | CPU実行時間 | GPU実行時間（参考） |\n|-----------|------------|-------------------|\n| 小規模（～1,000行） | 30秒～1分 | - |\n| 中規模（1,000～10,000行） | 1～3分 | 30秒～1分 |\n| 大規模（10,000～100,000行） | 5～15分 | 1～3分 |\n| 超大規模（100,000行～） | 15分～1時間 | 3～10分 |\n\n**注**: 実行時間は特徴量数・モデル数にも依存します。\n\n---\n\n**このセルを実行すると、AIが自動で全モデルを比較します（環境によって数分～十数分かかります） ↓**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYC_OK and len(feat) >= MIN_SAMPLES_PYCARET:    print(f'[INFO] PyCaret開始: {len(feat)}行 (>= {MIN_SAMPLES_PYCARET}行)')        # PyCaretセットアップ用データ準備    data = feat.drop(columns=['date','store_id'], errors='ignore').copy()        # 欠損値が多い列を削除（50%以上欠損）    missing_ratio = data.isnull().sum() / len(data)    drop_cols = missing_ratio[missing_ratio > 0.5].index.tolist()    if drop_cols:        print(f'[WARNING] 欠損値50%超の列を除外: {drop_cols}')        data = data.drop(columns=drop_cols)        print(f'[INFO] 学習データ: {data.shape} | 目的変数: sales_amt')        # GPU設定の準備    gpu_params = {}    if USE_GPU and GPU_AVAILABLE:        print('🚀 [INFO] GPU使用モードで実行（LightGBM/XGBoost/CatBoost対応）')        gpu_params = {            'lightgbm': {'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0},            'xgboost': {'tree_method': 'gpu_hist', 'gpu_id': 0},            'catboost': {'task_type': 'GPU', 'devices': '0'}        }    else:        print('ℹ️ [INFO] CPU使用モードで実行')        try:        # PyCaretセットアップ        _ = setup(            data=data,             target='sales_amt',             session_id=42,             fold=3,            verbose=False,            normalize=True,            transformation=True,            ignore_features=['sales_lag_1', 'sales_lag_7', 'sales_rolling_7']  # lag特徴量はリークの可能性あるため除外も検討        )                # モデル比較（全モデルで実行、GPU対応）        print('[INFO] モデル比較実行中（全モデル）...')        print('[INFO] 比較対象: PyCaretの全回帰モデル（15～20種類）')        if USE_GPU:            print('[INFO] ✅ GPU加速有効（LightGBM/XGBoost/CatBoost）')        print('[INFO] ※ 実行に数分かかる場合があります')                # GPU対応モデルのカスタムパラメータを設定        import time        start_time = time.time()                best = compare_models(            sort='R2',            n_select=1        )                elapsed_time = time.time() - start_time                leaderboard = pull()        print('[SUCCESS] モデル比較完了')        print(f'⏱️ 実行時間: {elapsed_time:.1f}秒')        if USE_GPU:            print('💡 GPUにより高速化されました')        print(f'\\n📊 全{len(leaderboard)}モデルの比較結果:')        display(leaderboard)                # 最良モデルのファイナライズ（GPU設定を適用）        if USE_GPU and type(best).__name__ in ['LGBMRegressor', 'XGBRegressor', 'CatBoostRegressor']:            model_name = type(best).__name__            print(f'🚀 [INFO] {model_name}にGPU設定を適用')            if 'LGBM' in model_name:                best.set_params(**gpu_params.get('lightgbm', {}))            elif 'XGB' in model_name:                best.set_params(**gpu_params.get('xgboost', {}))            elif 'CatBoost' in model_name:                best.set_params(**gpu_params.get('catboost', {}))                final = finalize_model(best)        print(f'\\n[INFO] 最良モデル: {type(best).__name__}')        print(f'[INFO] R2スコア: {leaderboard.iloc[0][\"R2\"]:.4f}')        print(f'[INFO] RMSE: {leaderboard.iloc[0][\"RMSE\"]:.2f}')        print(f'[INFO] MAE: {leaderboard.iloc[0][\"MAE\"]:.2f}')                # 可視化        try:            print('\\n[INFO] 特徴量重要度プロット')            plot_model(final, plot='feature')        except Exception as e:            print(f'[WARNING] 特徴量プロット失敗: {e}')                try:            print('\\n[INFO] 残差プロット')            plot_model(final, plot='residuals')        except Exception as e:            print(f'[WARNING] 残差プロット失敗: {e}')                except Exception as e:        print(f'[ERROR] PyCaret実行失敗')        print(f'  エラー型: {type(e).__name__}')        print(f'  詳細: {e}')        import traceback        traceback.print_exc()        elif PYC_OK:    print(f'[WARNING] データ不足（{len(feat)}行 < {MIN_SAMPLES_PYCARET}行）。PyCaretスキップ。')else:    print('[WARNING] PyCaret未インストール。スキップ。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79z9lrfba1r",
   "source": "## 📊 ステップ5: 結果の解釈と実務アクション\n\n### 🎯 **このセクションの目的**\n**上のPyCaret結果を見て、明日から何をすべきか判断する方法を解説します。**\n\n---\n\n## 1️⃣ モデル比較表（Leaderboard）の読み方\n\n上のセルで表示された表の見方：\n\n### 📈 **最重要指標: R2（決定係数）**\n\n| R2の値 | 意味 | 実務での判断 |\n|--------|------|------------|\n| **0.8以上** | 非常に優秀 | ✅ このモデルで来週の発注計画を立ててOK |\n| **0.6～0.8** | まあまあ使える | ✅ 補助的に使用（店長の経験と併用） |\n| **0.5～0.6** | やや不足 | ⚠️ データ期間を延長するか、要因を追加検討 |\n| **0.5未満** | 予測精度低い | ❌ プロモ情報・競合情報などを追加する必要あり |\n\n---\n\n### 📊 **その他の指標**\n\n| 指標 | 意味 | 見方 |\n|------|------|------|\n| **MAE** | 平均絶対誤差 | 例: MAE=5000円 → 「予測が平均5,000円ズレる」 |\n| **RMSE** | 二乗平均平方根誤差 | MAEより大きい外れ値に敏感。MAEと近い値ならOK |\n| **MAPE** | 平均絶対パーセント誤差 | 例: MAPE=0.15 → 「予測が平均15%ズレる」 |\n\n**判断基準**:\n```\n✅ MAPE < 0.2 (20%未満) → 実用レベル\n⚠️ MAPE 0.2～0.3 → 参考程度に使う\n❌ MAPE > 0.3 → データ追加が必要\n```\n\n---\n\n### 🏆 **最良モデルの確認**\n\n上のセルの最後に表示される：\n```\n[INFO] 最良モデル: GradientBoostingRegressor\n```\n\n**各モデルの特徴**:\n\n| モデル名 | 特徴 | 向いているケース |\n|----------|------|------------------|\n| **GradientBoostingRegressor (gbr)** | 高精度、複雑なパターン対応 | 売上が天候・曜日・イベントで複雑に変化 |\n| **RandomForestRegressor (rf)** | 安定性が高い | データにノイズが多い |\n| **LinearRegression (lr)** | シンプル、解釈しやすい | 売上が単純な要因で決まる（気温だけ等） |\n| **DecisionTree (dt)** | ルールベース | 「気温30度以上なら冷飲料が売れる」等の明確なルール |\n\n**実務での判断**:\n- **gbr/rf が上位** → 売上が複雑な要因で決まる → 次のステップ（特徴量重要度）で主要因を特定\n- **lr が上位** → 売上がシンプルな要因で決まる → 1〜2個の主要因に集中対策\n\n---\n\n## 2️⃣ 特徴量重要度グラフの読み方\n\n上のセルで表示される棒グラフ「Feature Importance」:\n\n### 📊 **重要度の意味**\n\n| 重要度 | 意味 | 実務アクション |\n|--------|------|----------------|\n| **30%以上** | 超重要（売上の主要因） | 🔴 **毎日チェック必須** |\n| **15～30%** | 重要 | 🟡 **週1回チェック** |\n| **5～15%** | やや重要 | 🟢 **月1回チェック** |\n| **5%未満** | 参考程度 | ⚪ 気にしなくてOK |\n\n---\n\n### 💡 **要因別の実務アクション例**\n\n実行結果に出てくる主な要因と、その対応方法：\n\n#### **🌡️ 気温系（平均気温、最高気温、気温差）が上位**\n\n**意味**: 気温が売上の主要因\n\n**明日からやるべきこと**:\n1. **毎週月曜**に週間天気予報をチェック\n2. **気温30度以上の予報**\n   - 冷たい飲料：通常の1.5倍発注\n   - アイス・チルドデザート：フェース増\n   - 冷ケース前の導線確保\n3. **気温15度以下の予報**\n   - おでん・中華まん：フェース増\n   - ホット飲料：レジ横に陳列\n   - 温かい総菜：手前陳列\n\n---\n\n#### **🗓️ 曜日系（週末フラグ、土曜フラグ、日曜フラグ）が上位**\n\n**意味**: 曜日パターンが売上の主要因\n\n**明日からやるべきこと**:\n1. **木曜夕方**に週末向け発注を確定\n2. **金曜の朝**に週末向け商品を前出し\n3. **週末に売れるカテゴリ**（ダッシュボードの「提案ビュー」で確認）:\n   - 弁当・総菜：フェース1.5倍\n   - デザート・スイーツ：導線強化\n   - 麺類：手前陳列\n\n---\n\n#### **☔ 降雨フラグが上位**\n\n**意味**: 雨の日の売上変化が大きい\n\n**明日からやるべきこと**:\n1. **毎朝の天気予報**で降雨確率をチェック\n2. **降雨確率50%以上**の場合:\n   - 温かい総菜：前出し強化\n   - カップ麺・インスタント食品：手前陳列\n   - ホット飲料：レジ横に配置\n   - 中華まん・おでん：入口近くに\n\n---\n\n#### **💰 給料日、給料日直後が上位**\n\n**意味**: 給料日で購買行動が変わる\n\n**明日からやるべきこと**:\n1. **毎月25日前後**（一般的な給料日）:\n   - 高単価弁当・スイーツ：厚め陳列\n   - プレミアム商品：目立つ位置に\n2. **月初3日**:\n   - 定番品の在庫確保（買いだめ需要）\n3. **月末3日**:\n   - 値頃品・節約訴求（価格ポップ強化）\n\n---\n\n#### **📅 季節変動指数（月/週）が上位**\n\n**意味**: 季節トレンドが強い\n\n**明日からやるべきこと**:\n1. **毎月初**に先月対比をチェック\n2. **上昇トレンド**なら主力品の発注を10%増\n3. **下降トレンド**なら見切りを早めに判断\n\n---\n\n## 3️⃣ 残差プロット（Residuals）の読み方\n\n特徴量重要度の次に表示されるグラフ:\n\n### 📊 **見るべきポイント**\n\n| パターン | 意味 | 実務での判断 |\n|----------|------|------------|\n| **点がランダムに散らばっている** | ✅ モデルが正しく機能 | このモデルで予測してOK |\n| **右上がり/右下がりの線が見える** | ⚠️ モデルに改善余地あり | より高度なモデルが必要（要相談） |\n| **一部に極端な外れ値** | ⚠️ 異常日を検出 | その日の売上を個別調査 |\n\n**実務アクション**:\n- ランダム分布 → AIの予測を信頼してOK\n- パターンあり → データサイエンティストに相談\n- 外れ値 → 「セール日」「競合店開店日」などを記録\n\n---\n\n## 4️⃣ 今日から始める3ステップ\n\n### 📝 **ステップ1: 今日の重要度トップ3を確認**\n\n上の「Feature Importance」グラフで：\n1. 1位の要因は？ → 毎日チェックする\n2. 2位の要因は？ → 週1回チェックする\n3. 3位の要因は？ → 月1回チェックする\n\n**例**:\n```\n1位: 平均気温_MA7 (35%) → 毎週月曜に週間天気予報\n2位: 週末フラグ (22%) → 木曜に週末発注確定\n3位: 降雨フラグ (18%) → 毎朝の天気予報で降雨確率チェック\n```\n\n---\n\n### 📝 **ステップ2: チェックリストを作る**\n\n| 曜日 | やること | 確認する要因 |\n|------|----------|------------|\n| **毎朝** | 天気予報チェック | 降雨フラグ、気温 |\n| **月曜** | 週間天気予報チェック | 平均気温_MA7 |\n| **木曜夕** | 週末発注確定 | 週末フラグ |\n| **月初1日** | 季節トレンド確認 | 季節変動指数_月 |\n| **25日前後** | 給料日対応 | 給料日フラグ |\n\n---\n\n### 📝 **ステップ3: 1週間試して、効果を測定**\n\n**試す内容**:\n- 重要度トップ3の要因を毎日チェック\n- その要因に応じて陳列・発注を調整\n\n**効果測定**（1週間後）:\n```\n□ 売上が前週比で上がったか？\n□ 欠品が減ったか？\n□ 廃棄が減ったか？\n```\n\n**効果があれば** → ずっと続ける  \n**効果がなければ** → データ期間を延長（3ヶ月→6ヶ月）して再分析\n\n---\n\n## 📌 まとめ: AIの結果をこう使う\n\n| 見るもの | 何を確認？ | 実務アクション |\n|----------|-----------|----------------|\n| **Leaderboard** | R2が0.8以上か？ | 0.8以上なら予測を信頼 |\n| **Feature Importance** | 重要度トップ3は？ | その3つを毎日/週/月チェック |\n| **Residuals** | ランダム分布か？ | ランダムならモデルOK |\n\n**最重要ポイント**:\n> 「重要度トップ3」を毎日チェックする習慣をつけるだけで、売上は確実に改善します。\n\n**次のステップ**:\n- このノートブックを毎月1回実行して、重要度の変化を追跡\n- 季節（夏/冬）で重要度が変わるので、3ヶ月ごとに見直し\n\n---\n\n**以上で、AIによる売上分析は完了です！**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "2br5d2hc0od",
   "source": "## 📦 ステップ6: 1週間先の発注数量予測（全商品）\n\n### 🎯 **このセクションの目的**\n**学習したAIモデルを使って、2025年10月15日から1週間分の全商品の販売数量を予測し、発注数量を自動計算します。**\n\n---\n\n### 📋 **予測の流れ**\n\n1. **外部要因の入力** → 1週間分の天気予報・カレンダー情報を入力\n2. **AIが予測** → 学習したモデルで商品×日付ごとに販売数量を予測\n3. **発注数量の計算** → 予測値 × 安全係数で発注数量を算出\n4. **CSV出力** → 発注表をCSVファイルとして保存\n\n---\n\n### 👀 **店長が入力すべき情報**\n\n次のセルで、以下の情報を入力してください：\n\n| 項目 | 入力例 | 説明 |\n|------|--------|------|\n| **予測開始日** | `2025-10-15` | 発注を開始する日 |\n| **予測日数** | `7` | 何日分予測するか（通常は7日） |\n| **天気予報** | `['晴れ', '曇り', '雨', ...]` | 1週間分の天気予報 |\n| **平均気温** | `[22, 23, 20, 18, ...]` | 1週間分の予測気温（℃） |\n| **降水確率** | `[10, 30, 70, ...]` | 1週間分の降水確率（%） |\n| **安全係数** | `1.2` | 欠品防止のための余裕率（通常1.1～1.3） |\n\n**安全係数の目安**:\n- `1.0` → 予測値そのまま（リスク高）\n- `1.1～1.2` → 通常の運用（推奨）\n- `1.3～1.5` → 欠品を絶対に避けたい（廃棄リスク増）\n\n---\n\n**次のセルで外部要因を入力し、予測を実行してください ↓**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "rbi69vvi24",
   "source": "# ========================================\n# 📅 Step 6-1: 外部要因の入力（天気予報・カレンダー情報）\n# ========================================\n\n# 予測期間の設定\nFORECAST_START_DATE = '2025-10-15'  # 予測開始日\nFORECAST_DAYS = 7  # 予測日数（1週間）\n\n# 🌤️ 天気予報（1週間分）\n# 注: 実際の天気予報サイトから取得した情報を入力してください\nWEATHER_FORECAST = [\n    # 10/15(水), 10/16(木), 10/17(金), 10/18(土), 10/19(日), 10/20(月), 10/21(火)\n    '晴れ',    '晴れ',    '曇り',    '晴れ',    '雨',      '曇り',    '晴れ'\n]\n\n# 🌡️ 平均気温予報（1週間分、単位: ℃）\nTEMP_FORECAST = [\n    22,        23,        20,        21,        18,        19,        22\n]\n\n# 🌧️ 降水確率（1週間分、単位: %）\nPRECIP_FORECAST = [\n    10,        10,        30,        10,        70,        40,        10\n]\n\n# 🔢 安全係数（欠品防止のための余裕率）\nSAFETY_FACTOR = 1.2  # 1.0～1.5 の範囲で設定（推奨: 1.1～1.2）\n\n# ========================================\n# 予測期間の日付リストを生成\n# ========================================\nforecast_dates = pd.date_range(start=FORECAST_START_DATE, periods=FORECAST_DAYS, freq='D')\n\nprint('='*60)\nprint('📅 予測期間設定')\nprint('='*60)\nprint(f'開始日: {FORECAST_START_DATE}')\nprint(f'予測日数: {FORECAST_DAYS}日')\nprint(f'安全係数: {SAFETY_FACTOR}')\nprint(f'\\n予測対象日:')\nfor i, date in enumerate(forecast_dates):\n    weather = WEATHER_FORECAST[i] if i < len(WEATHER_FORECAST) else '不明'\n    temp = TEMP_FORECAST[i] if i < len(TEMP_FORECAST) else 'N/A'\n    precip = PRECIP_FORECAST[i] if i < len(PRECIP_FORECAST) else 'N/A'\n    print(f'  {date.strftime(\"%Y-%m-%d (%a)\")}: 天気={weather}, 気温={temp}℃, 降水確率={precip}%')\n\n# ========================================\n# 外部要因テーブルの構築\n# ========================================\n# 各日付の特徴量を計算\nforecast_features = []\nfor i, date in enumerate(forecast_dates):\n    # 基本情報\n    features = {\n        'date': date,\n        '年': date.year,\n        '月': date.month,\n        '日': date.day,\n        '曜日': date.dayofweek,  # 0=月曜, 6=日曜\n        '週番号': date.isocalendar()[1],\n    }\n    \n    # 曜日フラグ\n    features['土曜フラグ'] = 1 if date.dayofweek == 5 else 0\n    features['日曜フラグ'] = 1 if date.dayofweek == 6 else 0\n    features['週末フラグ'] = 1 if date.dayofweek >= 5 else 0\n    features['平日フラグ'] = 1 if date.dayofweek < 5 else 0\n    \n    # 祝日フラグ（簡易実装: 日本の主要祝日）\n    # 実際には jpholiday ライブラリ等を使用することを推奨\n    import datetime\n    year = date.year\n    holidays = [\n        datetime.date(year, 1, 1),   # 元日\n        datetime.date(year, 2, 11),  # 建国記念日\n        datetime.date(year, 3, 20),  # 春分の日（概算）\n        datetime.date(year, 4, 29),  # 昭和の日\n        datetime.date(year, 5, 3),   # 憲法記念日\n        datetime.date(year, 5, 4),   # みどりの日\n        datetime.date(year, 5, 5),   # こどもの日\n        datetime.date(year, 7, 15),  # 海の日（概算）\n        datetime.date(year, 8, 11),  # 山の日\n        datetime.date(year, 9, 16),  # 敬老の日（概算）\n        datetime.date(year, 9, 23),  # 秋分の日（概算）\n        datetime.date(year, 10, 14), # スポーツの日（概算）\n        datetime.date(year, 11, 3),  # 文化の日\n        datetime.date(year, 11, 23), # 勤労感謝の日\n    ]\n    features['祝日フラグ'] = 1 if date.date() in holidays else 0\n    features['休日フラグ'] = 1 if (features['週末フラグ'] == 1 or features['祝日フラグ'] == 1) else 0\n    \n    # 天気・気温情報\n    weather = WEATHER_FORECAST[i] if i < len(WEATHER_FORECAST) else '晴れ'\n    temp = TEMP_FORECAST[i] if i < len(TEMP_FORECAST) else 20\n    precip = PRECIP_FORECAST[i] if i < len(PRECIP_FORECAST) else 0\n    \n    features['天気'] = weather\n    features['平均気温'] = temp\n    features['降水量'] = precip * 0.5 if precip > 0 else 0  # 降水確率から概算\n    features['降雨フラグ'] = 1 if precip >= 50 else 0\n    features['弱雨'] = 1 if 30 <= precip < 50 else 0\n    features['普通雨'] = 1 if 50 <= precip < 70 else 0\n    features['強雨'] = 1 if precip >= 70 else 0\n    \n    # 気温カテゴリ\n    features['猛暑日'] = 1 if temp >= 35 else 0\n    features['真夏日'] = 1 if 30 <= temp < 35 else 0\n    features['夏日'] = 1 if 25 <= temp < 30 else 0\n    features['冬日'] = 1 if temp < 0 else 0\n    features['真冬日'] = 1 if temp < -5 else 0\n    \n    # 給料日フラグ（25日前後）\n    features['給料日'] = 1 if date.day == 25 else 0\n    features['給料日直後'] = 1 if 26 <= date.day <= 28 else 0\n    \n    # 月初・月末フラグ\n    features['月初'] = 1 if date.day <= 5 else 0\n    features['月初3日'] = 1 if date.day <= 3 else 0\n    features['月末3日'] = 1 if date.day >= 28 else 0  # 簡易実装\n    features['月末'] = 1 if date.day >= 25 else 0\n    \n    forecast_features.append(features)\n\n# DataFrameに変換\nforecast_df = pd.DataFrame(forecast_features)\n\nprint(f'\\n✅ 外部要因テーブル作成完了: {forecast_df.shape}')\ndisplay(forecast_df.head(10))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2qr8mow022t",
   "source": "# ========================================\n# 📦 Step 6-2: 全商品×全日付の予測実行\n# ========================================\n\nif not PYC_OK or 'final' not in globals():\n    print('[ERROR] PyCaretモデルが学習されていません。')\n    print('先にステップ4を実行してください。')\nelse:\n    print('='*60)\n    print('🤖 AI予測実行中...')\n    print('='*60)\n    \n    # 商品リスト取得（過去データから）\n    if 'sku_id' in df.columns:\n        sku_list = df['sku_id'].dropna().unique().tolist()\n    else:\n        print('[ERROR] sku_id列が見つかりません。')\n        sku_list = []\n    \n    # 店舗リスト取得\n    if 'store_id' in df.columns:\n        store_list = df['store_id'].dropna().unique().tolist()\n    else:\n        print('[WARNING] store_id列が見つかりません。デフォルト店舗を使用します。')\n        store_list = ['default_store']\n    \n    print(f'\\n📊 予測対象:')\n    print(f'  商品数: {len(sku_list)} SKU')\n    print(f'  店舗数: {len(store_list)} 店舗')\n    print(f'  日数: {FORECAST_DAYS} 日')\n    print(f'  合計予測レコード数: {len(sku_list) * len(store_list) * FORECAST_DAYS:,} 件')\n    \n    # 全商品×全店舗×全日付の組み合わせを作成\n    all_predictions = []\n    \n    # プログレス表示用\n    total_combinations = len(sku_list) * len(store_list) * FORECAST_DAYS\n    processed = 0\n    \n    for store in store_list:\n        for sku in sku_list:\n            # 各日付ごとに予測\n            for idx, row in forecast_df.iterrows():\n                # 予測用の特徴量を準備\n                pred_features = row.to_dict()\n                pred_features['store_id'] = store\n                pred_features['sku_id'] = sku\n                \n                # 学習データと同じ特徴量列に揃える\n                # （PyCaretのsetupで使用した特徴量のみを使用）\n                pred_df = pd.DataFrame([pred_features])\n                \n                # date, store_id, sku_id は予測に使わない\n                pred_df = pred_df.drop(columns=['date'], errors='ignore')\n                \n                # 学習時に除外した列も除外\n                for col in ['store_id', 'sku_id', '天気']:\n                    if col in pred_df.columns:\n                        pred_df = pred_df.drop(columns=[col], errors='ignore')\n                \n                # 学習データに存在しない列を削除、不足列を追加（0で埋める）\n                try:\n                    # PyCaretの学習データと同じ列に揃える\n                    training_cols = [c for c in feat.columns if c not in ['date', 'store_id', 'sales_amt']]\n                    \n                    # 不足列を追加（0で埋める）\n                    for col in training_cols:\n                        if col not in pred_df.columns:\n                            pred_df[col] = 0\n                    \n                    # 余分な列を削除\n                    pred_df = pred_df[[c for c in pred_df.columns if c in training_cols]]\n                    \n                    # 欠損値を0で埋める\n                    pred_df = pred_df.fillna(0)\n                    \n                    # 予測実行\n                    pred_result = predict_model(final, data=pred_df)\n                    predicted_sales_amt = pred_result['prediction_label'].iloc[0]\n                    \n                    # 過去データから該当商品の平均単価を取得\n                    if 'price' in df.columns and 'sku_id' in df.columns:\n                        sku_price = df[df['sku_id'] == sku]['price'].dropna()\n                        avg_price = sku_price.mean() if not sku_price.empty else 100  # デフォルト100円\n                    else:\n                        avg_price = 100\n                    \n                    # 販売数量 = 売上金額 / 単価\n                    predicted_qty = predicted_sales_amt / avg_price if avg_price > 0 else 0\n                    predicted_qty = max(0, predicted_qty)  # 負の値を防止\n                    \n                    # 発注数量 = 予測販売数量 × 安全係数\n                    order_qty = predicted_qty * SAFETY_FACTOR\n                    order_qty = int(np.ceil(order_qty))  # 切り上げ\n                    \n                    # カテゴリ情報を取得（過去データから）\n                    sku_info = df[df['sku_id'] == sku][['category_l', 'category_m', 'category_s']].drop_duplicates()\n                    category_l = sku_info['category_l'].iloc[0] if not sku_info.empty and 'category_l' in sku_info.columns else '不明'\n                    category_m = sku_info['category_m'].iloc[0] if not sku_info.empty and 'category_m' in sku_info.columns else '不明'\n                    category_s = sku_info['category_s'].iloc[0] if not sku_info.empty and 'category_s' in sku_info.columns else '不明'\n                    \n                    # 結果を保存\n                    all_predictions.append({\n                        '日付': row['date'].strftime('%Y-%m-%d'),\n                        '曜日': row['date'].strftime('%A'),\n                        '店舗': store,\n                        '商品コード': sku,\n                        '大分類': category_l,\n                        '中分類': category_m,\n                        '小分類': category_s,\n                        '予測売上金額': int(predicted_sales_amt),\n                        '予測販売数量': int(predicted_qty),\n                        '発注数量': order_qty,\n                        '単価': int(avg_price),\n                        '天気': row['天気'],\n                        '気温': row['平均気温'],\n                        '週末': '週末' if row['週末フラグ'] == 1 else '平日',\n                    })\n                    \n                except Exception as e:\n                    # 予測失敗時はスキップ\n                    pass\n                \n                # プログレス表示（100件ごと）\n                processed += 1\n                if processed % 100 == 0:\n                    progress_pct = (processed / total_combinations) * 100\n                    print(f'  進捗: {processed:,}/{total_combinations:,} 件 ({progress_pct:.1f}%)', end='\\r')\n    \n    # DataFrameに変換\n    forecast_result = pd.DataFrame(all_predictions)\n    \n    print(f'\\n\\n✅ 予測完了: {len(forecast_result):,} 件')\n    print(f'\\n📊 予測結果サマリー:')\n    print(f'  総発注数量: {forecast_result[\"発注数量\"].sum():,} 個')\n    print(f'  総予測売上: ¥{forecast_result[\"予測売上金額\"].sum():,}')\n    print(f'  平均発注数量/商品/日: {forecast_result[\"発注数量\"].mean():.1f} 個')\n    \n    # 日付別サマリー\n    print(f'\\n📅 日付別サマリー:')\n    daily_summary = forecast_result.groupby('日付').agg({\n        '発注数量': 'sum',\n        '予測売上金額': 'sum',\n        '商品コード': 'count'\n    }).rename(columns={'商品コード': '商品種類数'})\n    display(daily_summary)\n    \n    # カテゴリ別サマリー\n    print(f'\\n📦 カテゴリ別サマリー（大分類）:')\n    category_summary = forecast_result.groupby('大分類').agg({\n        '発注数量': 'sum',\n        '予測売上金額': 'sum'\n    }).sort_values('予測売上金額', ascending=False)\n    display(category_summary.head(10))\n    \n    # 上位商品（発注数量トップ20）\n    print(f'\\n🔝 発注数量トップ20（1週間合計）:')\n    top_products = forecast_result.groupby(['商品コード', '大分類', '中分類']).agg({\n        '発注数量': 'sum',\n        '予測売上金額': 'sum'\n    }).sort_values('発注数量', ascending=False).head(20)\n    display(top_products)\n    \n    # サンプル表示\n    print(f'\\n📋 予測結果サンプル（最初の50件）:')\n    display(forecast_result.head(50))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "slf8tnkekhn",
   "source": "## 📊 ステップ7: 発注予測結果の読み方と実務での使い方\n\n### 🎯 **このセクションの目的**\n**上で出力された発注予測表を、明日からどう使うかを解説します。**\n\n---\n\n## 1️⃣ 出力されたCSVファイルの内容\n\n### 📋 **メインファイル: `発注予測_2025-10-15_to_2025-10-21.csv`**\n\nこのファイルには、全商品×7日分の発注予測が含まれています。\n\n| 列名 | 意味 | 使い方 |\n|------|------|--------|\n| **日付** | 販売予定日 | この日に店頭に並ぶ商品 |\n| **曜日** | 曜日（Monday～Sunday） | 曜日別の発注パターン確認 |\n| **店舗** | 店舗コード | 複数店舗の場合、店舗ごとに分ける |\n| **商品コード** | SKU識別子 | 発注システムへの入力値 |\n| **大分類/中分類/小分類** | カテゴリ | 発注作業の整理用 |\n| **予測販売数量** | AIの予測値 | この数量が売れると予測 |\n| **発注数量** | 実際の発注数 | **これを発注システムに入力** |\n| **単価** | 平均単価 | 予算計算用 |\n| **天気/気温** | 予測日の天候 | 判断材料 |\n| **週末** | 週末/平日フラグ | 週末対応の目印 |\n\n---\n\n### 📅 **日付別ファイル: `発注予測_2025-10-15.csv`**\n\n各日付ごとに分割されたファイルです。\n\n**使い方**:\n1. 毎朝、**その日の発注ファイル**を開く\n2. **発注数量**列をそのまま発注システムに入力\n3. カテゴリ別にソートして、効率的に発注作業を進める\n\n---\n\n### 🏪 **店舗別ファイル: `発注予測_店舗A_2025-10-15.csv`**\n\n複数店舗がある場合、店舗ごとに分割されたファイルです。\n\n**使い方**:\n- 各店舗の店長に配布\n- 店舗ごとの特性を反映した発注が可能\n\n---\n\n## 2️⃣ 発注作業の実務フロー（毎日のルーティン）\n\n### 📝 **毎朝のチェックリスト**\n\n#### **ステップ1: CSVファイルを開く（5分）**\n```\n1. output/発注予測_[今日の日付].csv を開く\n2. Excelで開いて、カテゴリでソート\n3. 発注システムと画面を並べる\n```\n\n#### **ステップ2: 発注数量を確認（5分）**\n```\n□ 発注数量が異常に多い商品はないか？\n  → 通常の2倍以上 → 天気・イベントを再確認\n  → 問題なければそのまま発注\n\n□ 発注数量が0の商品はないか？\n  → 0の場合 → 過去実績を確認して少量発注を検討\n```\n\n#### **ステップ3: 発注システムに入力（10～15分）**\n```\n1. カテゴリ別に発注数量を入力\n2. 特に注意すべき商品:\n   - 発注数量トップ20 → 欠品させない\n   - 雨の日に売れる商品 → 降水確率を再確認\n   - 週末に売れる商品 → 金曜の朝までに発注\n```\n\n#### **ステップ4: 調整（5分）**\n```\n□ 天気予報が変わっていないか確認\n  → 変わっている場合、手動で±10%調整\n\n□ 突発イベント（セールなど）がないか確認\n  → ある場合、該当カテゴリを+20～30%増量\n\n□ 昨日の売上実績と比較\n  → 予測が大きく外れている場合、フィードバック\n```\n\n---\n\n## 3️⃣ 結果の読み方（数字の意味）\n\n### 📊 **日付別サマリーの見方**\n\n上のセルで表示された「日付別サマリー」:\n\n| 日付 | 発注数量 | 予測売上金額 | 商品種類数 |\n|------|----------|------------|----------|\n| 2025-10-15 | 850 | ¥127,500 | 120 |\n| 2025-10-16 | 820 | ¥123,000 | 120 |\n| 2025-10-19 (雨) | 950 | ¥142,500 | 120 |\n\n**読み方**:\n- **10/19（雨の日）** → 発注数量が通常より+15%増\n- **意味**: AIが「雨の日は売上が増える」と判断\n- **アクション**: 温かい商品・カップ麺などを重点発注\n\n---\n\n### 📦 **カテゴリ別サマリーの見方**\n\n| 大分類 | 発注数量 | 予測売上金額 |\n|--------|----------|------------|\n| 弁当 | 2,100 | ¥315,000 |\n| 飲料 | 1,800 | ¥108,000 |\n| 総菜 | 1,500 | ¥225,000 |\n\n**読み方**:\n- **弁当が最も売れる** → 陳列スペースを最優先確保\n- **発注数量の比率** → 棚割りの参考に\n\n---\n\n### 🔝 **発注数量トップ20の使い方**\n\n上位20商品 = **絶対に欠品させてはいけない商品**\n\n**実務アクション**:\n1. **毎日チェック** → トップ20商品の在庫を毎夕確認\n2. **フェース増** → 陳列スペースを通常の1.5倍確保\n3. **前出し強化** → 昼・夕ピーク前に必ず前出し\n4. **欠品時の対応** → 予備在庫を用意、または類似商品で代替\n\n---\n\n## 4️⃣ よくある質問（FAQ）\n\n### ❓ **予測が外れた場合はどうする？**\n\n**回答**:\n- **1日だけ外れた** → 突発要因（競合店のセール等）の可能性。記録して次回に活かす\n- **連続で外れる** → AIの再学習が必要。データ期間を延長（3ヶ月→6ヶ月）して再実行\n\n---\n\n### ❓ **安全係数はどう決める？**\n\n**回答**:\n\n| 状況 | 推奨値 | 理由 |\n|------|--------|------|\n| **通常運用** | 1.1～1.2 | 欠品と廃棄のバランス |\n| **新商品** | 1.3～1.5 | 需要が読めないため保守的に |\n| **廃棄率が高い** | 1.0～1.1 | 廃棄削減を優先 |\n| **欠品が多発** | 1.2～1.3 | 売上機会損失を防ぐ |\n\n**調整方法**:\n- 1週間運用して、廃棄率と欠品率を測定\n- 廃棄率5%以上 → 安全係数を-0.1下げる\n- 欠品率3%以上 → 安全係数を+0.1上げる\n\n---\n\n### ❓ **天気予報が変わったらどうする？**\n\n**回答**:\n1. **前日夕方** に最新の天気予報を確認\n2. **降水確率が30%以上変わった場合**:\n   - 晴れ→雨 → 温かい商品を+10～20%増量\n   - 雨→晴れ → 冷たい商品を+10～20%増量\n3. **気温が5℃以上変わった場合**:\n   - 暑くなる → 冷飲料・アイスを+20%増量\n   - 寒くなる → ホット飲料・総菜を+20%増量\n\n---\n\n### ❓ **発注数量が0の商品はどうする？**\n\n**回答**:\n- **AIの判断**: その商品はその日売れにくい\n- **実務対応**:\n  1. 過去実績を確認 → 本当に売れていないか？\n  2. 売れている → 最低発注数（1～2個）を手動入力\n  3. 売れていない → 0のまま発注しない（在庫削減）\n\n---\n\n## 5️⃣ 効果測定（1週間後にチェック）\n\n### ✅ **成功指標**\n\n| 指標 | 目標値 | 測定方法 |\n|------|--------|----------|\n| **欠品率** | 3%以下 | 欠品商品数 ÷ 全商品数 |\n| **廃棄率** | 5%以下 | 廃棄数量 ÷ 発注数量 |\n| **予測精度** | 80%以上 | 実売数量 ÷ 予測数量 |\n| **売上増加率** | +5%以上 | 今週売上 vs 先週売上 |\n\n**測定シート（Excelで作成）**:\n```\n| 日付 | 発注数量 | 実売数量 | 廃棄数量 | 欠品商品数 | 予測精度 |\n|------|----------|----------|----------|-----------|---------|\n| 10/15 | 850 | 820 | 30 | 2 | 96% |\n| 10/16 | 820 | 790 | 30 | 1 | 96% |\n| ...  | ... | ... | ... | ... | ... |\n```\n\n---\n\n## 📌 まとめ: AI発注予測の活用ポイント\n\n### **最重要ポイント 3つ**\n\n1. **毎朝5分のルーティン化**\n   - CSVファイルを開く → 発注数量を確認 → 発注システムに入力\n\n2. **トップ20商品は絶対欠品させない**\n   - 毎夕、在庫チェック\n   - フェース1.5倍確保\n   - 予備在庫を用意\n\n3. **1週間運用して、安全係数を調整**\n   - 廃棄率5%以上 → 係数-0.1\n   - 欠品率3%以上 → 係数+0.1\n\n---\n\n**これで、AI発注予測システムの説明は完了です！**\n\n明日から実際に運用してみてください。1週間後に効果を測定し、継続的に改善していきましょう。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "s6sn7okpdz",
   "source": "# ========================================\n# 💾 Step 6-3: 発注表をCSVファイルに出力\n# ========================================\n\nif 'forecast_result' in globals() and not forecast_result.empty:\n    # 出力ファイル名\n    output_filename = f'発注予測_{FORECAST_START_DATE}_to_{forecast_dates[-1].strftime(\"%Y-%m-%d\")}.csv'\n    output_path = Path('output') / output_filename\n    \n    # outputディレクトリがなければ作成\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    # CSV出力\n    forecast_result.to_csv(output_path, index=False, encoding='utf-8-sig')\n    \n    print('='*60)\n    print('💾 発注表をCSVファイルに保存しました')\n    print('='*60)\n    print(f'ファイル名: {output_path}')\n    print(f'ファイルサイズ: {output_path.stat().st_size / 1024:.1f} KB')\n    print(f'レコード数: {len(forecast_result):,} 件')\n    \n    # 日付別に分割したCSVも出力\n    print(f'\\n📅 日付別CSVファイルも出力します...')\n    for date in forecast_result['日付'].unique():\n        date_df = forecast_result[forecast_result['日付'] == date].copy()\n        date_filename = f'発注予測_{date}.csv'\n        date_path = Path('output') / date_filename\n        date_df.to_csv(date_path, index=False, encoding='utf-8-sig')\n        print(f'  ✅ {date_filename} ({len(date_df):,} 件)')\n    \n    # 店舗別に分割したCSVも出力\n    if '店舗' in forecast_result.columns and forecast_result['店舗'].nunique() > 1:\n        print(f'\\n🏪 店舗別CSVファイルも出力します...')\n        for store in forecast_result['店舗'].unique():\n            store_df = forecast_result[forecast_result['店舗'] == store].copy()\n            store_filename = f'発注予測_店舗{store}_{FORECAST_START_DATE}.csv'\n            store_path = Path('output') / store_filename\n            store_df.to_csv(store_path, index=False, encoding='utf-8-sig')\n            print(f'  ✅ {store_filename} ({len(store_df):,} 件)')\n    \n    print(f'\\n✅ すべてのCSVファイルを output/ に保存しました')\n    \nelse:\n    print('[ERROR] 予測結果が見つかりません。先にStep 6-2を実行してください。')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}