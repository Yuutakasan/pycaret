{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f37912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆå…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ã‚ˆãä½¿ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å…ˆã«èª­ã¿è¾¼ã‚€\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®æœ‰ç„¡ã‚’é€šçŸ¥ãƒ»ãƒ•ãƒ©ã‚°åŒ–\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    WIDGETS_AVAILABLE = True\n",
    "    print('âœ… ipywidgetsåˆ©ç”¨å¯èƒ½')\n",
    "except Exception:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "    print('âš ï¸ ipywidgetsæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - ä¸€éƒ¨æ©Ÿèƒ½åˆ¶é™')\n",
    "\n",
    "import font_setup\n",
    "JP_FP = font_setup.setup_fonts(show_test=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e95fa8-0821-4e6e-8e71-5d2977044f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...\n",
      "âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸï¼ˆUTF-8ï¼‰: 13,344è¡Œ\n",
      "ğŸ“Š GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³: 4.0/12.9 GB\n",
      "âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ: 13,318è¡Œ\n",
      "   åº—èˆ—æ•°: 3\n",
      "   å•†å“æ•°: 1112\n",
      "   æœŸé–“: 2025-07-09 00:00:00 ï½ 2025-07-22 00:00:00\n",
      "ğŸ“Š æ´¾ç”Ÿå¤‰æ•°ä½œæˆä¸­...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMixedTypeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:996\u001b[39m, in \u001b[36m_fast_slow_function_call\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m nvtx.annotate(\n\u001b[32m    992\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEXECUTE_FAST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    993\u001b[39m     color=_CUDF_PANDAS_NVTX_COLORS[\u001b[33m\"\u001b[39m\u001b[33mEXECUTE_FAST\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    994\u001b[39m     domain=\u001b[33m\"\u001b[39m\u001b[33mcudf_pandas\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    995\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     fast_args, fast_kwargs = \u001b[43m_fast_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, _fast_arg(kwargs)\n\u001b[32m    997\u001b[39m     result = func(*fast_args, **fast_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1183\u001b[39m, in \u001b[36m_fast_arg\u001b[39m\u001b[34m(arg)\u001b[39m\n\u001b[32m   1182\u001b[39m seen: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m-> \u001b[39m\u001b[32m1183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_transform_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_fsproxy_fast\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseen\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1108\u001b[39m, in \u001b[36m_transform_arg\u001b[39m\u001b[34m(arg, attribute_name, seen)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m   1109\u001b[39m             _transform_arg(a, attribute_name, seen) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arg\n\u001b[32m   1110\u001b[39m         )\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[33m\"\u001b[39m\u001b[33m__getnewargs_ex__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1112\u001b[39m     \u001b[38;5;66;03m# Partial implementation of to reconstruct with\u001b[39;00m\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# transformed pieces\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# This handles scipy._lib._bunch._make_tuple_bunch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1109\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m             \u001b[43m_transform_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattribute_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseen\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arg\n\u001b[32m   1110\u001b[39m         )\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[33m\"\u001b[39m\u001b[33m__getnewargs_ex__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1112\u001b[39m     \u001b[38;5;66;03m# Partial implementation of to reconstruct with\u001b[39;00m\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# transformed pieces\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# This handles scipy._lib._bunch._make_tuple_bunch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1108\u001b[39m, in \u001b[36m_transform_arg\u001b[39m\u001b[34m(arg, attribute_name, seen)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m   1109\u001b[39m             _transform_arg(a, attribute_name, seen) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arg\n\u001b[32m   1110\u001b[39m         )\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[33m\"\u001b[39m\u001b[33m__getnewargs_ex__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1112\u001b[39m     \u001b[38;5;66;03m# Partial implementation of to reconstruct with\u001b[39;00m\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# transformed pieces\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# This handles scipy._lib._bunch._make_tuple_bunch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1109\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m             \u001b[43m_transform_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattribute_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseen\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arg\n\u001b[32m   1110\u001b[39m         )\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[33m\"\u001b[39m\u001b[33m__getnewargs_ex__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1112\u001b[39m     \u001b[38;5;66;03m# Partial implementation of to reconstruct with\u001b[39;00m\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# transformed pieces\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# This handles scipy._lib._bunch._make_tuple_bunch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1064\u001b[39m, in \u001b[36m_transform_arg\u001b[39m\u001b[34m(arg, attribute_name, seen)\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (_FastSlowProxy, _FastSlowProxyMeta, _FunctionProxy)):\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     typ = \u001b[38;5;28mgetattr\u001b[39m(arg, attribute_name)\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m _Unusable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:530\u001b[39m, in \u001b[36m_FastSlowProxy._fsproxy_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    526\u001b[39m \u001b[33;03mReturns the wrapped object. If the wrapped object is of \"slow\"\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[33;03mtype, replaces it with the corresponding \"fast\" object before\u001b[39;00m\n\u001b[32m    528\u001b[39m \u001b[33;03mreturning it.\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m \u001b[38;5;28mself\u001b[39m._fsproxy_wrapped = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fsproxy_slow_to_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fsproxy_wrapped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:192\u001b[39m, in \u001b[36mmake_final_proxy_type.<locals>._fsproxy_slow_to_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fsproxy_state \u001b[38;5;129;01mis\u001b[39;00m _State.SLOW:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mslow_to_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fsproxy_wrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fsproxy_wrapped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/utils/performance_tracking.py:51\u001b[39m, in \u001b[36m_performance_tracking.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m     stack.enter_context(\n\u001b[32m     45\u001b[39m         nvtx.annotate(\n\u001b[32m     46\u001b[39m             message=func.\u001b[34m__qualname__\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m         )\n\u001b[32m     50\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/core/dataframe.py:8689\u001b[39m, in \u001b[36mfrom_pandas\u001b[39m\u001b[34m(obj, nan_as_null)\u001b[39m\n\u001b[32m   8688\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pd.Series):\n\u001b[32m-> \u001b[39m\u001b[32m8689\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   8690\u001b[39m \u001b[38;5;66;03m# This carveout for cudf.pandas is undesirable, but fixes crucial issues\u001b[39;00m\n\u001b[32m   8691\u001b[39m \u001b[38;5;66;03m# for core RAPIDS projects like cuML and cuGraph that rely on\u001b[39;00m\n\u001b[32m   8692\u001b[39m \u001b[38;5;66;03m# `cudf.from_pandas`, so we allow it for now.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/_wrappers/pandas.py:2022\u001b[39m, in \u001b[36mwrap_from_pandas_series.<locals>.wrapped_from_pandas_series\u001b[39m\u001b[34m(s, *args, **kwargs)\u001b[39m\n\u001b[32m   2021\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m s\n\u001b[32m-> \u001b[39m\u001b[32m2022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/utils/performance_tracking.py:51\u001b[39m, in \u001b[36m_performance_tracking.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m     stack.enter_context(\n\u001b[32m     45\u001b[39m         nvtx.annotate(\n\u001b[32m     46\u001b[39m             message=func.\u001b[34m__qualname__\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m         )\n\u001b[32m     50\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/core/series.py:658\u001b[39m, in \u001b[36mSeries.from_pandas\u001b[39m\u001b[34m(cls, s, nan_as_null)\u001b[39m\n\u001b[32m    657\u001b[39m     warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m     result = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/_wrappers/pandas.py:1977\u001b[39m, in \u001b[36mwrap_init.<locals>.wrapped_init\u001b[39m\u001b[34m(self, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1976\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1977\u001b[39m \u001b[43moriginal_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/utils/performance_tracking.py:51\u001b[39m, in \u001b[36m_performance_tracking.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m     stack.enter_context(\n\u001b[32m     45\u001b[39m         nvtx.annotate(\n\u001b[32m     46\u001b[39m             message=func.\u001b[34m__qualname__\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m         )\n\u001b[32m     50\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/core/series.py:504\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, nan_as_null)\u001b[39m\n\u001b[32m    503\u001b[39m name_from_data = data.name\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m column = \u001b[43mas_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (pd.Series, Series)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/core/column/column.py:3033\u001b[39m, in \u001b[36mas_column\u001b[39m\u001b[34m(arbitrary, nan_as_null, dtype, length)\u001b[39m\n\u001b[32m   3026\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   3027\u001b[39m     nan_as_null \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3028\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mdecimal\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mempty\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m   3031\u001b[39m     \u001b[38;5;66;03m# Decimal can hold float(\"nan\")\u001b[39;00m\n\u001b[32m   3032\u001b[39m     \u001b[38;5;66;03m# All np.nan is not restricted by type\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3033\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MixedTypeError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot have NaN with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   3035\u001b[39m pyarrow_array = pa.array(\n\u001b[32m   3036\u001b[39m     arbitrary,\n\u001b[32m   3037\u001b[39m     from_pandas=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   3038\u001b[39m )\n",
      "\u001b[31mMixedTypeError\u001b[39m: Cannot have NaN with mixed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“Š æ´¾ç”Ÿå¤‰æ•°ä½œæˆä¸­...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# å˜ä¾¡ã®è¨ˆç®—\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33må˜ä¾¡\u001b[39m\u001b[33m'\u001b[39m] = np.where(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43må£²ä¸Šæ•°é‡\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m, df[\u001b[33m'\u001b[39m\u001b[33må£²ä¸Šé‡‘é¡\u001b[39m\u001b[33m'\u001b[39m] / df[\u001b[33m'\u001b[39m\u001b[33må£²ä¸Šæ•°é‡\u001b[39m\u001b[33m'\u001b[39m], \u001b[32m0\u001b[39m)\n\u001b[32m     57\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33må˜ä¾¡\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33må˜ä¾¡\u001b[39m\u001b[33m'\u001b[39m].replace([np.inf, -np.inf], np.nan).fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# è²©å£²ç‡ã®è¨ˆç®—\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:722\u001b[39m, in \u001b[36m_CallableProxyMixin.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     result, _ = \u001b[43m_fast_slow_function_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# We cannot directly call self here because we need it to be\u001b[39;49;00m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# converted into either the fast or slow object (by\u001b[39;49;00m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# _fast_slow_function_call) to avoid infinite recursion.\u001b[39;49;00m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# TODO: When Python 3.11 is the minimum supported Python version\u001b[39;49;00m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# this can use operator.call\u001b[39;49;00m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcall_operator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:1049\u001b[39m, in \u001b[36m_fast_slow_function_call\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m   1047\u001b[39m         _slow_function_call()\n\u001b[32m   1048\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m disable_module_accelerator():\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m             result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mslow_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mslow_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_wrap_result(result, func, *args, **kwargs), fast\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:28\u001b[39m, in \u001b[36mcall_operator\u001b[39m\u001b[34m(fn, args, kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_operator\u001b[39m(fn, args, kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:56\u001b[39m, in \u001b[36mOpsMixin.__gt__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__gt__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:5803\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   5800\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   5801\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m5803\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5805\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:346\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    343\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m lvalues.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     res_values = \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    349\u001b[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:131\u001b[39m, in \u001b[36mcomp_method_OBJECT_ARRAY\u001b[39m\u001b[34m(op, x, y)\u001b[39m\n\u001b[32m    129\u001b[39m     result = libops.vec_compare(x.ravel(), y.ravel(), op)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mops.pyx:107\u001b[39m, in \u001b[36mpandas._libs.ops.scalar_compare\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ï¼ˆGPUé«˜é€ŸåŒ–ï¼‰\n",
    "\n",
    "# %%\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®è¨­å®š\n",
    "file_path = 'output/06_ã€POSæƒ…å ±ã€‘åº—åˆ¥ï¼å•†å“åˆ¥å®Ÿç¸¾_TXç§‹è‘‰åŸé§…_TXå…­ç”ºé§…_TXã¤ãã°é§…_20250709_20250722.csv'\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆcudf.pandasã«ã‚ˆã‚Šè‡ªå‹•çš„ã«GPUåŠ é€Ÿï¼‰\n",
    "print(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...\")\n",
    "try:\n",
    "    # UTF-8ã§è©¦è¡Œ\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    print(f\"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸï¼ˆUTF-8ï¼‰: {len(df):,}è¡Œ\")\n",
    "except:\n",
    "    try:\n",
    "        # CP932ã§è©¦è¡Œ\n",
    "        df = pd.read_csv(file_path, encoding='cp932')\n",
    "        print(f\"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸï¼ˆCP932ï¼‰: {len(df):,}è¡Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        raise\n",
    "\n",
    "# GPUä½¿ç”¨æ™‚ã®ãƒ¡ãƒ¢ãƒªæƒ…å ±è¡¨ç¤º\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        import pynvml\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"ğŸ“Š GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³: {info.used/1e9:.1f}/{info.total/1e9:.1f} GB\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# %%\n",
    "# åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "# æ—¥ä»˜å‹ã«å¤‰æ›\n",
    "df['æ—¥ä»˜'] = pd.to_datetime(df['æ—¥ä»˜'])\n",
    "\n",
    "# åº—èˆ—åã®æ­£è¦åŒ–\n",
    "df['åº—èˆ—'] = df['åº—èˆ—'].str.replace('ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒãƒ¼ãƒˆã€€', '').str.replace('åº—', '')\n",
    "\n",
    "# ä¸è¦ãƒ‡ãƒ¼ã‚¿ã®é™¤å¤–\n",
    "df = df[df['å•†å“å'].notna() & (df['å•†å“å'] != 'ä¸æ˜') & (df['å•†å“å'].str.strip() != '')]\n",
    "df = df[~df['åº—èˆ—'].str.contains('åˆè¨ˆ|å°è¨ˆ', na=False)]\n",
    "\n",
    "print(f\"âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ: {len(df):,}è¡Œ\")\n",
    "print(f\"   åº—èˆ—æ•°: {df['åº—èˆ—'].nunique()}\")\n",
    "print(f\"   å•†å“æ•°: {df['å•†å“å'].nunique()}\")\n",
    "print(f\"   æœŸé–“: {df['æ—¥ä»˜'].min()} ï½ {df['æ—¥ä»˜'].max()}\")\n",
    "\n",
    "# %%\n",
    "# æ´¾ç”Ÿå¤‰æ•°ã®ä½œæˆï¼ˆGPUåŠ é€Ÿã«ã‚ˆã‚Šé«˜é€ŸåŒ–ï¼‰\n",
    "print(\"ğŸ“Š æ´¾ç”Ÿå¤‰æ•°ä½œæˆä¸­...\")\n",
    "\n",
    "# å˜ä¾¡ã®è¨ˆç®—\n",
    "df['å˜ä¾¡'] = np.where(df['å£²ä¸Šæ•°é‡'] > 0, df['å£²ä¸Šé‡‘é¡'] / df['å£²ä¸Šæ•°é‡'], 0)\n",
    "df['å˜ä¾¡'] = df['å˜ä¾¡'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# è²©å£²ç‡ã®è¨ˆç®—\n",
    "df['è²©å£²ç‡'] = np.where(df['ç´å“æ•°é‡'] > 0, df['å£²ä¸Šæ•°é‡'] / df['ç´å“æ•°é‡'], 0)\n",
    "df['è²©å£²ç‡'] = df['è²©å£²ç‡'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# åœ¨åº«å›è»¢æ—¥æ•°ã®è¨ˆç®—\n",
    "df['åœ¨åº«å›è»¢æ—¥æ•°'] = np.where(\n",
    "    df['å£²ä¸Šæ•°é‡'] > 0,\n",
    "    df['ç´å“æ•°é‡'] / df['å£²ä¸Šæ•°é‡'],\n",
    "    30  # å£²ä¸ŠãŒãªã„å ´åˆã¯30æ—¥ã¨ã™ã‚‹\n",
    ")\n",
    "df['åœ¨åº«å›è»¢æ—¥æ•°'] = df['åœ¨åº«å›è»¢æ—¥æ•°'].clip(upper=30)\n",
    "\n",
    "# å»ƒæ£„ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ï¼ˆè²©å£²ç‡ãŒä½ãã€åœ¨åº«å›è»¢æ—¥æ•°ãŒé•·ã„ï¼‰\n",
    "df['å»ƒæ£„ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢'] = (1 - df['è²©å£²ç‡']) * df['åœ¨åº«å›è»¢æ—¥æ•°'] / 30\n",
    "\n",
    "print(\"âœ… æ´¾ç”Ÿå¤‰æ•°ä½œæˆå®Œäº†\")\n",
    "print(f\"   å¹³å‡å˜ä¾¡: {df['å˜ä¾¡'].mean():.0f}å††\")\n",
    "print(f\"   å¹³å‡è²©å£²ç‡: {df['è²©å£²ç‡'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c81cf9-6644-4238-b481-77dbeaf80469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 3. åŸºæœ¬çµ±è¨ˆåˆ†æï¼ˆGPUåŠ é€Ÿï¼‰\n",
    "\n",
    "# %%\n",
    "# åº—èˆ—åˆ¥åŸºæœ¬çµ±è¨ˆï¼ˆgroupbyæ“ä½œãŒGPUåŠ é€Ÿã•ã‚Œã‚‹ï¼‰\n",
    "print(\"ğŸ“Š åº—èˆ—åˆ¥çµ±è¨ˆã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "store_stats = df.groupby('åº—èˆ—').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': ['sum', 'mean', 'std'],\n",
    "    'å£²ä¸Šæ•°é‡': ['sum', 'mean'],\n",
    "    'ç´å“æ•°é‡': ['sum', 'mean'],\n",
    "    'å•†å“å': 'nunique',\n",
    "    'æ—¥ä»˜': 'nunique',\n",
    "    'è²©å£²ç‡': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# ã‚«ãƒ©ãƒ åã‚’æ•´ç†\n",
    "store_stats.columns = ['_'.join(col).strip() for col in store_stats.columns.values]\n",
    "store_stats = store_stats.reset_index()\n",
    "\n",
    "# æ—¥è²©ã®è¨ˆç®—\n",
    "store_stats['æ—¥è²©'] = store_stats['å£²ä¸Šé‡‘é¡_sum'] / store_stats['æ—¥ä»˜_nunique']\n",
    "\n",
    "print(\"ğŸ“Š åº—èˆ—åˆ¥åŸºæœ¬çµ±è¨ˆ:\")\n",
    "print(store_stats[['åº—èˆ—', 'æ—¥è²©', 'å£²ä¸Šé‡‘é¡_sum', 'è²©å£²ç‡_mean', 'å•†å“å_nunique']])\n",
    "\n",
    "# %%\n",
    "# å•†å“åˆ¥åŸºæœ¬çµ±è¨ˆï¼ˆä¸Šä½å•†å“ï¼‰\n",
    "print(\"\\nğŸ“Š å•†å“åˆ¥çµ±è¨ˆã‚’è¨ˆç®—ä¸­...\")\n",
    "\n",
    "product_stats = df.groupby('å•†å“å').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': 'sum',\n",
    "    'å£²ä¸Šæ•°é‡': 'sum',\n",
    "    'ç´å“æ•°é‡': 'sum',\n",
    "    'è²©å£²ç‡': 'mean',\n",
    "    'åœ¨åº«å›è»¢æ—¥æ•°': 'mean',\n",
    "    'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡': 'first',\n",
    "    'PB/NBãƒ•ãƒ©ã‚°': 'first'\n",
    "}).round(2)\n",
    "\n",
    "# å£²ä¸Šé †ã«ã‚½ãƒ¼ãƒˆ\n",
    "product_stats = product_stats.sort_values('å£²ä¸Šé‡‘é¡', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ“Š å£²ä¸Šä¸Šä½10å•†å“:\")\n",
    "print(product_stats.head(10)[['å£²ä¸Šé‡‘é¡', 'è²©å£²ç‡', 'åœ¨åº«å›è»¢æ—¥æ•°']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855dc27-90c6-4de6-a120-86708532f9c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 4. å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆGPUé«˜é€ŸåŒ–ï¼‰\n",
    "\n",
    "# %%\n",
    "# æ›œæ—¥åˆ¥å£²ä¸Šåˆ†æï¼ˆå¤§è¦æ¨¡é›†è¨ˆã‚‚GPUåŠ é€Ÿã§é«˜é€Ÿï¼‰\n",
    "print(\"ğŸ“Š æ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æä¸­...\")\n",
    "\n",
    "weekday_analysis = df.groupby(['åº—èˆ—', 'æ›œæ—¥']).agg({\n",
    "    'å£²ä¸Šé‡‘é¡': ['sum', 'mean', 'count']\n",
    "}).round(0)\n",
    "\n",
    "# æ›œæ—¥é †åºã‚’å®šç¾©\n",
    "weekday_order = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# åº—èˆ—åˆ¥æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "for store in df['åº—èˆ—'].unique():\n",
    "    store_weekday = weekday_analysis.loc[store]['å£²ä¸Šé‡‘é¡']['mean']\n",
    "    store_weekday = store_weekday.reindex(weekday_order)\n",
    "    axes[0].plot(weekday_order, store_weekday, marker='o', label=store, linewidth=2)\n",
    "\n",
    "axes[0].set_title('åº—èˆ—åˆ¥æ›œæ—¥å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³', fontsize=14, fontproperties=JP_FP)\n",
    "axes[0].set_xlabel('æ›œæ—¥', fontproperties=JP_FP)\n",
    "axes[0].set_ylabel('å¹³å‡å£²ä¸Šé‡‘é¡', fontproperties=JP_FP)\n",
    "axes[0].legend(prop=JP_FP)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# å…¨ä½“ã®æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "overall_weekday = df.groupby('æ›œæ—¥')['å£²ä¸Šé‡‘é¡'].mean().reindex(weekday_order)\n",
    "bars = axes[1].bar(weekday_order, overall_weekday, color=COLORS[0])\n",
    "\n",
    "# ãƒ”ãƒ¼ã‚¯ã¨è°·ã‚’ç‰¹å®š\n",
    "peak_day = overall_weekday.idxmax()\n",
    "low_day = overall_weekday.idxmin()\n",
    "\n",
    "# è‰²ã‚’å¤‰æ›´\n",
    "for i, day in enumerate(weekday_order):\n",
    "    if day == peak_day:\n",
    "        bars[i].set_color('#2ECC71')\n",
    "    elif day == low_day:\n",
    "        bars[i].set_color('#E74C3C')\n",
    "\n",
    "axes[1].set_title('å…¨ä½“æ›œæ—¥åˆ¥å£²ä¸Šï¼ˆãƒ”ãƒ¼ã‚¯:ç·‘ã€è°·:èµ¤ï¼‰', fontsize=14, fontproperties=JP_FP)\n",
    "axes[1].set_xlabel('æ›œæ—¥', fontproperties=JP_FP)\n",
    "axes[1].set_ylabel('å¹³å‡å£²ä¸Šé‡‘é¡', fontproperties=JP_FP)\n",
    "axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/10000):.0f}ä¸‡'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# åˆ†æçµæœã‚’è¾æ›¸ã«ä¿å­˜\n",
    "weekday_insights = {\n",
    "    'peak_day': peak_day,\n",
    "    'low_day': low_day,\n",
    "    'peak_to_low_ratio': float(overall_weekday.max() / overall_weekday.min()),\n",
    "    'pattern': overall_weekday.to_dict()\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“Š æ›œæ—¥åˆ†æçµæœ:\")\n",
    "print(f\"   ãƒ”ãƒ¼ã‚¯æ›œæ—¥: {peak_day}\")\n",
    "print(f\"   æœ€ä½æ›œæ—¥: {low_day}\")\n",
    "print(f\"   ãƒ”ãƒ¼ã‚¯/æœ€ä½æ¯”: {weekday_insights['peak_to_low_ratio']:.2f}å€\")\n",
    "\n",
    "# %%\n",
    "# æ™‚é–“çš„ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ\n",
    "daily_trend = df.groupby('æ—¥ä»˜')['å£²ä¸Šé‡‘é¡'].sum()\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ\n",
    "x = np.arange(len(daily_trend))\n",
    "y = daily_trend.values\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(daily_trend.index, daily_trend.values, alpha=0.7, label='æ—¥æ¬¡å£²ä¸Š')\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³\n",
    "trend_line = slope * x + intercept\n",
    "plt.plot(daily_trend.index, trend_line, 'r--', linewidth=2, \n",
    "         label=f'ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå‚¾ã: {slope:.0f}å††/æ—¥ï¼‰')\n",
    "\n",
    "# ç§»å‹•å¹³å‡\n",
    "ma7 = daily_trend.rolling(window=7, center=True).mean()\n",
    "plt.plot(daily_trend.index, ma7, 'g-', linewidth=2, label='7æ—¥ç§»å‹•å¹³å‡')\n",
    "\n",
    "plt.title('å£²ä¸Šã®æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰', fontsize=14, fontproperties=JP_FP)\n",
    "plt.xlabel('æ—¥ä»˜', fontproperties=JP_FP)\n",
    "plt.ylabel('å£²ä¸Šé‡‘é¡', fontproperties=JP_FP)\n",
    "plt.legend(prop=JP_FP)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "trend_insights = {\n",
    "    'direction': 'increasing' if slope > 0 else 'decreasing',\n",
    "    'daily_change': float(slope),\n",
    "    'statistical_significance': p_value < 0.05,\n",
    "    'r_squared': float(r_value ** 2)\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“Š ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æçµæœ:\")\n",
    "print(f\"   æ–¹å‘: {trend_insights['direction']}\")\n",
    "print(f\"   æ—¥æ¬¡å¤‰åŒ–: {trend_insights['daily_change']:.0f}å††/æ—¥\")\n",
    "print(f\"   çµ±è¨ˆçš„æœ‰æ„æ€§: {trend_insights['statistical_significance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049122e2-a1be-46a6-8f41-b97fc96b31ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 5. åœ¨åº«åŠ¹ç‡åˆ†æï¼ˆGPUå¯¾å¿œï¼‰\n",
    "\n",
    "# %%\n",
    "# å•†å“åŠ¹ç‡æ€§ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆï¼ˆå¤§è¦æ¨¡é›†è¨ˆã‚‚GPUåŠ é€Ÿï¼‰\n",
    "print(\"ğŸ“Š åœ¨åº«åŠ¹ç‡åˆ†æä¸­...\")\n",
    "\n",
    "efficiency_data = df.groupby('å•†å“å').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': 'sum',\n",
    "    'å£²ä¸Šæ•°é‡': 'sum',\n",
    "    'ç´å“æ•°é‡': 'sum',\n",
    "    'è²©å£²ç‡': 'mean',\n",
    "    'åœ¨åº«å›è»¢æ—¥æ•°': 'mean',\n",
    "    'å»ƒæ£„ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢': 'mean',\n",
    "    'ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡': 'first',\n",
    "    'PB/NBãƒ•ãƒ©ã‚°': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# åŠ¹ç‡ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆå£²ä¸Šè²¢çŒ®åº¦ Ã— å›è»¢ç‡ï¼‰\n",
    "efficiency_data['å£²ä¸Šè²¢çŒ®åº¦'] = efficiency_data['å£²ä¸Šé‡‘é¡'] / efficiency_data['å£²ä¸Šé‡‘é¡'].sum()\n",
    "efficiency_data['åŠ¹ç‡ã‚¹ã‚³ã‚¢'] = (\n",
    "    efficiency_data['å£²ä¸Šè²¢çŒ®åº¦'] * 1000 * \n",
    "    (1 / (efficiency_data['åœ¨åº«å›è»¢æ—¥æ•°'] + 1))\n",
    ")\n",
    "\n",
    "# %%\n",
    "# å•†å“åˆ†é¡ï¼ˆ4è±¡é™åˆ†æï¼‰\n",
    "# è²©å£²ç‡ã¨å£²ä¸Šé‡‘é¡ã§åˆ†é¡\n",
    "median_rate = efficiency_data['è²©å£²ç‡'].median()\n",
    "median_sales = efficiency_data['å£²ä¸Šé‡‘é¡'].median()\n",
    "\n",
    "efficiency_data['å•†å“åˆ†é¡'] = ''\n",
    "efficiency_data.loc[\n",
    "    (efficiency_data['è²©å£²ç‡'] >= median_rate) & \n",
    "    (efficiency_data['å£²ä¸Šé‡‘é¡'] >= median_sales), 'å•†å“åˆ†é¡'\n",
    "] = 'ã‚¹ã‚¿ãƒ¼å•†å“'\n",
    "\n",
    "efficiency_data.loc[\n",
    "    (efficiency_data['è²©å£²ç‡'] < median_rate) & \n",
    "    (efficiency_data['å£²ä¸Šé‡‘é¡'] >= median_sales), 'å•†å“åˆ†é¡'\n",
    "] = 'è¦æ”¹å–„å•†å“'\n",
    "\n",
    "efficiency_data.loc[\n",
    "    (efficiency_data['è²©å£²ç‡'] >= median_rate) & \n",
    "    (efficiency_data['å£²ä¸Šé‡‘é¡'] < median_sales), 'å•†å“åˆ†é¡'\n",
    "] = 'ãƒ‹ãƒƒãƒå•†å“'\n",
    "\n",
    "efficiency_data.loc[\n",
    "    (efficiency_data['è²©å£²ç‡'] < median_rate) & \n",
    "    (efficiency_data['å£²ä¸Šé‡‘é¡'] < median_sales), 'å•†å“åˆ†é¡'\n",
    "] = 'å‰Šæ¸›å€™è£œ'\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors_map = {\n",
    "    'ã‚¹ã‚¿ãƒ¼å•†å“': '#2ECC71',\n",
    "    'è¦æ”¹å–„å•†å“': '#F39C12',\n",
    "    'ãƒ‹ãƒƒãƒå•†å“': '#3498DB',\n",
    "    'å‰Šæ¸›å€™è£œ': '#E74C3C'\n",
    "}\n",
    "\n",
    "for category, color in colors_map.items():\n",
    "    data = efficiency_data[efficiency_data['å•†å“åˆ†é¡'] == category]\n",
    "    plt.scatter(data['è²©å£²ç‡'] * 100, data['å£²ä¸Šé‡‘é¡'] / 10000,\n",
    "                s=50, alpha=0.6, c=color, label=f'{category}ï¼ˆ{len(data)}å“ï¼‰')\n",
    "\n",
    "plt.axvline(x=median_rate * 100, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=median_sales / 10000, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlabel('è²©å£²ç‡ï¼ˆ%ï¼‰', fontproperties=JP_FP)\n",
    "plt.ylabel('å£²ä¸Šé‡‘é¡ï¼ˆä¸‡å††ï¼‰', fontproperties=JP_FP)\n",
    "plt.title('å•†å“åŠ¹ç‡æ€§ãƒãƒˆãƒªãƒƒã‚¯ã‚¹', fontsize=14, fontproperties=JP_FP)\n",
    "plt.legend(prop=JP_FP)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# åˆ†é¡åˆ¥çµ±è¨ˆ\n",
    "classification_stats = efficiency_data.groupby('å•†å“åˆ†é¡').agg({\n",
    "    'å•†å“å': 'count',\n",
    "    'å£²ä¸Šé‡‘é¡': 'sum',\n",
    "    'è²©å£²ç‡': 'mean',\n",
    "    'åœ¨åº«å›è»¢æ—¥æ•°': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"ğŸ“Š å•†å“åˆ†é¡åˆ¥çµ±è¨ˆ:\")\n",
    "print(classification_stats)\n",
    "\n",
    "# %%\n",
    "# å‰Šæ¸›å€™è£œå•†å“ã®è©³ç´°åˆ†æ\n",
    "reduction_candidates = efficiency_data[\n",
    "    efficiency_data['å•†å“åˆ†é¡'] == 'å‰Šæ¸›å€™è£œ'\n",
    "].sort_values('åŠ¹ç‡ã‚¹ã‚³ã‚¢')\n",
    "\n",
    "# å‰Šæ¸›ã«ã‚ˆã‚‹å½±éŸ¿åˆ†æ\n",
    "total_reduction_sales = reduction_candidates['å£²ä¸Šé‡‘é¡'].sum()\n",
    "total_reduction_items = len(reduction_candidates)\n",
    "\n",
    "print(f\"\\nğŸ“Š å‰Šæ¸›å€™è£œåˆ†æ:\")\n",
    "print(f\"   å¯¾è±¡å•†å“æ•°: {total_reduction_items}å“\")\n",
    "print(f\"   å½±éŸ¿å£²ä¸Šé¡: {total_reduction_sales/10000:.0f}ä¸‡å††\")\n",
    "print(f\"   å…¨ä½“ã«å ã‚ã‚‹å‰²åˆ: {total_reduction_sales/efficiency_data['å£²ä¸Šé‡‘é¡'].sum()*100:.1f}%\")\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥å‰Šæ¸›å€™è£œ\n",
    "reduction_by_category = reduction_candidates.groupby('ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡').agg({\n",
    "    'å•†å“å': 'count',\n",
    "    'å£²ä¸Šé‡‘é¡': 'sum'\n",
    "}).sort_values('å•†å“å', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥å‰Šæ¸›å€™è£œ:\")\n",
    "print(reduction_by_category.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3f90d-7314-409e-a8cd-c1f3873a4d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 6. æ°—è±¡å½±éŸ¿åˆ†æï¼ˆGPUåŠ é€Ÿï¼‰\n",
    "\n",
    "# %%\n",
    "# å¤©å€™åˆ¥å£²ä¸Šåˆ†æ\n",
    "print(\"ğŸ“Š æ°—è±¡å½±éŸ¿åˆ†æä¸­...\")\n",
    "\n",
    "weather_analysis = df.groupby('å¤©æ°—').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': ['sum', 'mean', 'count'],\n",
    "    'å£²ä¸Šæ•°é‡': 'mean',\n",
    "    'å•†å“å': 'nunique'\n",
    "}).round(0)\n",
    "\n",
    "weather_analysis.columns = ['_'.join(col).strip() for col in weather_analysis.columns.values]\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# å¤©å€™åˆ¥å¹³å‡å£²ä¸Š\n",
    "weather_avg = weather_analysis['å£²ä¸Šé‡‘é¡_mean'].sort_values(ascending=False)\n",
    "bars1 = axes[0].bar(weather_avg.index, weather_avg.values, color=COLORS[:len(weather_avg)])\n",
    "axes[0].set_title('å¤©å€™åˆ¥å¹³å‡å£²ä¸Š', fontsize=14, fontproperties=JP_FP)\n",
    "axes[0].set_ylabel('å¹³å‡å£²ä¸Šé‡‘é¡', fontproperties=JP_FP)\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/10000):.0f}ä¸‡'))\n",
    "\n",
    "# æ•°å€¤è¡¨ç¤º\n",
    "for i, (weather, value) in enumerate(weather_avg.items()):\n",
    "    axes[0].text(i, value + value * 0.02, f'{int(value/10000, fontproperties=JP_FP)}ä¸‡', ha='center')\n",
    "\n",
    "# æ°—æ¸©ã¨å£²ä¸Šã®ç›¸é–¢\n",
    "temp_corr_data = df.groupby('æ—¥ä»˜').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': 'sum',\n",
    "    'æœ€é«˜æ°—æ¸©': 'first',\n",
    "    'æœ€ä½æ°—æ¸©': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "temp_corr_data['å¹³å‡æ°—æ¸©'] = (temp_corr_data['æœ€é«˜æ°—æ¸©'] + temp_corr_data['æœ€ä½æ°—æ¸©']) / 2\n",
    "\n",
    "# æ•£å¸ƒå›³\n",
    "scatter = axes[1].scatter(temp_corr_data['å¹³å‡æ°—æ¸©'], \n",
    "                         temp_corr_data['å£²ä¸Šé‡‘é¡'] / 10000,\n",
    "                         c=temp_corr_data.index, cmap='coolwarm', s=50, alpha=0.7)\n",
    "\n",
    "# ç›¸é–¢ä¿‚æ•°\n",
    "corr_coef = temp_corr_data['å¹³å‡æ°—æ¸©'].corr(temp_corr_data['å£²ä¸Šé‡‘é¡'])\n",
    "\n",
    "axes[1].set_title(f'æ°—æ¸©ã¨å£²ä¸Šã®é–¢ä¿‚ï¼ˆç›¸é–¢: {corr_coef:.3f}ï¼‰', fontsize=14, fontproperties=JP_FP)\n",
    "axes[1].set_xlabel('å¹³å‡æ°—æ¸©ï¼ˆâ„ƒï¼‰', fontproperties=JP_FP)\n",
    "axes[1].set_ylabel('å£²ä¸Šé‡‘é¡ï¼ˆä¸‡å††ï¼‰', fontproperties=JP_FP)\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³\n",
    "z = np.polyfit(temp_corr_data['å¹³å‡æ°—æ¸©'], temp_corr_data['å£²ä¸Šé‡‘é¡'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1].plot(temp_corr_data['å¹³å‡æ°—æ¸©'].sort_values(), \n",
    "             p(temp_corr_data['å¹³å‡æ°—æ¸©'].sort_values()) / 10000,\n",
    "             \"r--\", linewidth=2, alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# æ°—æ¸©æ„Ÿå¿œå•†å“ã®ç‰¹å®šï¼ˆä¸¦åˆ—å‡¦ç†ã§GPUé«˜é€ŸåŒ–ï¼‰\n",
    "print(\"ğŸ“Š æ°—æ¸©æ„Ÿå¿œå•†å“ã®ç‰¹å®šä¸­...\")\n",
    "\n",
    "temp_sensitive_products = {}\n",
    "\n",
    "# å£²ä¸Šä¸Šä½100å•†å“ã«ã¤ã„ã¦æ°—æ¸©ç›¸é–¢ã‚’è¨ˆç®—\n",
    "top_products = product_stats.head(100).index\n",
    "\n",
    "for product in top_products:\n",
    "    product_data = df[df['å•†å“å'] == product].groupby('æ—¥ä»˜').agg({\n",
    "        'å£²ä¸Šé‡‘é¡': 'sum',\n",
    "        'æœ€é«˜æ°—æ¸©': 'first'\n",
    "    })\n",
    "    \n",
    "    if len(product_data) >= 5:\n",
    "        corr = product_data['å£²ä¸Šé‡‘é¡'].corr(product_data['æœ€é«˜æ°—æ¸©'])\n",
    "        if abs(corr) > 0.5:  # ç›¸é–¢ãŒå¼·ã„å•†å“ã®ã¿\n",
    "            temp_sensitive_products[product] = float(corr)\n",
    "\n",
    "# ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤º\n",
    "temp_sensitive_sorted = sorted(temp_sensitive_products.items(), \n",
    "                              key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"ğŸ“Š æ°—æ¸©æ„Ÿå¿œå•†å“TOP10:\")\n",
    "for i, (product, corr) in enumerate(temp_sensitive_sorted[:10]):\n",
    "    direction = \"é«˜æ¸©ã§å£²ã‚Œã‚‹\" if corr > 0 else \"ä½æ¸©ã§å£²ã‚Œã‚‹\"\n",
    "    print(f\"{i+1}. {product}: {corr:.3f} ({direction})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf18397-c562-425e-9a59-8bb051284757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 7. ã‚«ãƒ†ã‚´ãƒªãƒ»PB/NBåˆ†æï¼ˆGPUé«˜é€ŸåŒ–ï¼‰\n",
    "\n",
    "# %%\n",
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆå¤§è¦æ¨¡é›†è¨ˆã‚‚GPUåŠ é€Ÿï¼‰\n",
    "print(\"ğŸ“Š ã‚«ãƒ†ã‚´ãƒªãƒ»PB/NBåˆ†æä¸­...\")\n",
    "\n",
    "category_performance = df.groupby('ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': 'sum',\n",
    "    'å£²ä¸Šæ•°é‡': 'sum',\n",
    "    'è²©å£²ç‡': 'mean',\n",
    "    'å•†å“å': 'nunique',\n",
    "    'åœ¨åº«å›è»¢æ—¥æ•°': 'mean'\n",
    "}).sort_values('å£²ä¸Šé‡‘é¡', ascending=False)\n",
    "\n",
    "# PB/NBåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n",
    "pb_nb_performance = df.groupby('PB/NBãƒ•ãƒ©ã‚°').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': 'sum',\n",
    "    'å£²ä¸Šæ•°é‡': 'sum',\n",
    "    'è²©å£²ç‡': 'mean',\n",
    "    'å˜ä¾¡': 'mean',\n",
    "    'å•†å“å': 'nunique'\n",
    "})\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šæ§‹æˆ\n",
    "top_categories = category_performance.head(10)\n",
    "axes[0, 0].pie(top_categories['å£²ä¸Šé‡‘é¡'], labels=top_categories.index, \n",
    "               autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šæ§‹æˆï¼ˆä¸Šä½10ï¼‰', fontsize=14, fontproperties=JP_FP)\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥åŠ¹ç‡æ€§\n",
    "axes[0, 1].scatter(top_categories['è²©å£²ç‡'] * 100, \n",
    "                   top_categories['åœ¨åº«å›è»¢æ—¥æ•°'],\n",
    "                   s=top_categories['å£²ä¸Šé‡‘é¡'] / 10000,\n",
    "                   alpha=0.6, c=range(len(top_categories)), cmap='viridis')\n",
    "\n",
    "for i, (idx, row) in enumerate(top_categories.iterrows()):\n",
    "    axes[0, 1].annotate(idx[:10], \n",
    "                        (row['è²©å£²ç‡'] * 100, row['åœ¨åº«å›è»¢æ—¥æ•°'], fontproperties=JP_FP),\n",
    "                        fontsize=8, alpha=0.7)\n",
    "\n",
    "axes[0, 1].set_xlabel('è²©å£²ç‡ï¼ˆ%ï¼‰', fontproperties=JP_FP)\n",
    "axes[0, 1].set_ylabel('åœ¨åº«å›è»¢æ—¥æ•°', fontproperties=JP_FP)\n",
    "axes[0, 1].set_title('ã‚«ãƒ†ã‚´ãƒªåˆ¥åŠ¹ç‡æ€§ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚º=å£²ä¸Šï¼‰', fontsize=14, fontproperties=JP_FP)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# PB/NBæ¯”è¼ƒ\n",
    "pb_nb_data = pb_nb_performance.reset_index()\n",
    "x = np.arange(len(pb_nb_data))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[1, 0].bar(x - width/2, pb_nb_data['å£²ä¸Šé‡‘é¡'] / 10000, \n",
    "                       width, label='å£²ä¸Šï¼ˆä¸‡å††ï¼‰', color=COLORS[0])\n",
    "bars2 = axes[1, 0].bar(x + width/2, pb_nb_data['è²©å£²ç‡'] * 100, \n",
    "                       width, label='è²©å£²ç‡ï¼ˆ%ï¼‰', color=COLORS[1])\n",
    "\n",
    "axes[1, 0].set_xlabel('å•†å“ã‚¿ã‚¤ãƒ—', fontproperties=JP_FP)\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(pb_nb_data['PB/NBãƒ•ãƒ©ã‚°'])\n",
    "axes[1, 0].set_title('PB/NBæ¯”è¼ƒ', fontsize=14, fontproperties=JP_FP)\n",
    "axes[1, 0].legend(prop=JP_FP)\n",
    "\n",
    "# PB/NBå˜ä¾¡æ¯”è¼ƒ\n",
    "axes[1, 1].bar(pb_nb_data['PB/NBãƒ•ãƒ©ã‚°'], pb_nb_data['å˜ä¾¡'], color=COLORS[2])\n",
    "axes[1, 1].set_ylabel('å¹³å‡å˜ä¾¡ï¼ˆå††ï¼‰', fontproperties=JP_FP)\n",
    "axes[1, 1].set_title('PB/NBå¹³å‡å˜ä¾¡æ¯”è¼ƒ', fontsize=14, fontproperties=JP_FP)\n",
    "\n",
    "for i, (idx, row) in enumerate(pb_nb_data.iterrows()):\n",
    "    axes[1, 1].text(i, row['å˜ä¾¡'] + 5, f\"{row['å˜ä¾¡']:.0f}å††\", ha='center', fontproperties=JP_FP)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f0102-22d7-4d9d-9a3f-74b5d41ea67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 8. æ©Ÿä¼šæå¤±åˆ†æï¼ˆGPUä¸¦åˆ—å‡¦ç†ï¼‰\n",
    "\n",
    "# %%\n",
    "# å“è–„ã«ã‚ˆã‚‹æ©Ÿä¼šæå¤±\n",
    "print(\"ğŸ“Š æ©Ÿä¼šæå¤±åˆ†æä¸­...\")\n",
    "\n",
    "shortage_products = efficiency_data[efficiency_data['è²©å£²ç‡'] >= 0.9].copy()\n",
    "shortage_products['æ¨å®šæå¤±é¡'] = shortage_products['å£²ä¸Šé‡‘é¡'] * 0.1  # 10%ã®è¿½åŠ å£²ä¸Šå¯èƒ½ã¨ä»®å®š\n",
    "\n",
    "total_shortage_loss = shortage_products['æ¨å®šæå¤±é¡'].sum()\n",
    "\n",
    "# éå‰°åœ¨åº«ã‚³ã‚¹ãƒˆ\n",
    "excess_products = efficiency_data[efficiency_data['è²©å£²ç‡'] < 0.3].copy()\n",
    "excess_products['éå‰°åœ¨åº«æ•°'] = excess_products['ç´å“æ•°é‡'] - excess_products['å£²ä¸Šæ•°é‡']\n",
    "excess_products['æ¨å®šã‚³ã‚¹ãƒˆ'] = excess_products['éå‰°åœ¨åº«æ•°'] * excess_products['å£²ä¸Šé‡‘é¡'] / excess_products['å£²ä¸Šæ•°é‡'] * 0.3\n",
    "\n",
    "total_excess_cost = excess_products['æ¨å®šã‚³ã‚¹ãƒˆ'].sum()\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# æ©Ÿä¼šæå¤±ã‚µãƒãƒªãƒ¼\n",
    "loss_data = {\n",
    "    'å“è–„ã«ã‚ˆã‚‹æ©Ÿä¼šæå¤±': total_shortage_loss / 10000,\n",
    "    'éå‰°åœ¨åº«ã‚³ã‚¹ãƒˆ': total_excess_cost / 10000\n",
    "}\n",
    "\n",
    "bars = axes[0].bar(loss_data.keys(), loss_data.values(), color=['#E74C3C', '#F39C12'])\n",
    "axes[0].set_ylabel('é‡‘é¡ï¼ˆä¸‡å††ï¼‰', fontproperties=JP_FP)\n",
    "axes[0].set_title('æ”¹å–„å¯èƒ½ãªæå¤±é¡', fontsize=14, fontproperties=JP_FP)\n",
    "\n",
    "for i, (key, value) in enumerate(loss_data.items()):\n",
    "    axes[0].text(i, value + value * 0.05, f'{value:.0f}ä¸‡å††', ha='center', fontproperties=JP_FP)\n",
    "\n",
    "total_opportunity = sum(loss_data.values())\n",
    "axes[0].text(0.5, 0.95, f'åˆè¨ˆæ”¹å–„æ©Ÿä¼š: {total_opportunity:.0f}ä¸‡å††', \n",
    "             transform=axes[0].transAxes, ha='center', fontsize=12,\n",
    "             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5, fontproperties=JP_FP))\n",
    "\n",
    "# å•†å“æ•°ã®å†…è¨³\n",
    "opportunity_breakdown = {\n",
    "    'å“è–„å•†å“': len(shortage_products),\n",
    "    'éå‰°åœ¨åº«å•†å“': len(excess_products),\n",
    "    'é©æ­£å•†å“': len(efficiency_data) - len(shortage_products) - len(excess_products)\n",
    "}\n",
    "\n",
    "axes[1].pie(opportunity_breakdown.values(), labels=opportunity_breakdown.keys(),\n",
    "            autopct='%1.0f%%', startangle=90, colors=['#E74C3C', '#F39C12', '#2ECC71'])\n",
    "axes[1].set_title('å•†å“åœ¨åº«çŠ¶æ³ã®å†…è¨³', fontsize=14, fontproperties=JP_FP)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ“Š æ©Ÿä¼šæå¤±åˆ†æçµæœ:\")\n",
    "print(f\"   å“è–„ã«ã‚ˆã‚‹æå¤±: {total_shortage_loss/10000:.0f}ä¸‡å††ï¼ˆ{len(shortage_products)}å•†å“ï¼‰\")\n",
    "print(f\"   éå‰°åœ¨åº«ã‚³ã‚¹ãƒˆ: {total_excess_cost/10000:.0f}ä¸‡å††ï¼ˆ{len(excess_products)}å•†å“ï¼‰\")\n",
    "print(f\"   åˆè¨ˆæ”¹å–„æ©Ÿä¼š: {(total_shortage_loss + total_excess_cost)/10000:.0f}ä¸‡å††\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73e157-177d-4c3a-a61b-5d836e4d50e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 9. å‹•çš„ãªç™ºæ³¨æœ€é©åŒ–ææ¡ˆï¼ˆGPUå¯¾å¿œï¼‰\n",
    "\n",
    "# %%\n",
    "# å•†å“ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆç™ºæ³¨æˆ¦ç•¥ç”¨ï¼‰\n",
    "print(\"ğŸ“Š ç™ºæ³¨æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¸­...\")\n",
    "\n",
    "# ç‰¹å¾´é‡ã®æº–å‚™\n",
    "cluster_features = efficiency_data[['è²©å£²ç‡', 'åœ¨åº«å›è»¢æ—¥æ•°', 'å£²ä¸Šè²¢çŒ®åº¦', 'åŠ¹ç‡ã‚¹ã‚³ã‚¢']].copy()\n",
    "\n",
    "# æ¬ æå€¤å‡¦ç†\n",
    "cluster_features = cluster_features.fillna(cluster_features.median())\n",
    "\n",
    "# GPUå¯¾å¿œã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆcuMLãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        from cuml.preprocessing import StandardScaler as cuStandardScaler\n",
    "        from cuml.cluster import KMeans as cuKMeans\n",
    "        \n",
    "        # æ¨™æº–åŒ–\n",
    "        scaler = cuStandardScaler()\n",
    "        features_scaled = scaler.fit_transform(cluster_features)\n",
    "        \n",
    "        # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆGPUï¼‰\n",
    "        n_clusters = 5\n",
    "        kmeans = cuKMeans(n_clusters=n_clusters, random_state=42)\n",
    "        efficiency_data['ç™ºæ³¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'] = kmeans.fit_predict(features_scaled)\n",
    "        \n",
    "        print(\"âœ… GPUç‰ˆK-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Œäº†\")\n",
    "    except:\n",
    "        # CPUç‰ˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.cluster import KMeans\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(cluster_features)\n",
    "        \n",
    "        n_clusters = 5\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        efficiency_data['ç™ºæ³¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'] = kmeans.fit_predict(features_scaled)\n",
    "        \n",
    "        print(\"âš ï¸ CPUç‰ˆK-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Œäº†\")\n",
    "else:\n",
    "    # CPUç‰ˆã‚’ä½¿ç”¨\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(cluster_features)\n",
    "    \n",
    "    n_clusters = 5\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    efficiency_data['ç™ºæ³¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'] = kmeans.fit_predict(features_scaled)\n",
    "\n",
    "# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥ç‰¹æ€§åˆ†æ\n",
    "cluster_profiles = efficiency_data.groupby('ç™ºæ³¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼').agg({\n",
    "    'å£²ä¸Šé‡‘é¡': ['mean', 'sum'],\n",
    "    'è²©å£²ç‡': 'mean',\n",
    "    'åœ¨åº«å›è»¢æ—¥æ•°': 'mean',\n",
    "    'å•†å“å': 'count'\n",
    "}).round(2)\n",
    "\n",
    "# %%\n",
    "# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã”ã¨ã®ç™ºæ³¨æˆ¦ç•¥ã‚’å‹•çš„ã«æ±ºå®š\n",
    "ordering_strategies = {}\n",
    "\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = cluster_profiles.loc[cluster]\n",
    "    \n",
    "    # å„æŒ‡æ¨™ã‚’å–å¾—\n",
    "    avg_sales = cluster_data[('å£²ä¸Šé‡‘é¡', 'mean')]\n",
    "    avg_rate = cluster_data[('è²©å£²ç‡', 'mean')]\n",
    "    avg_turnover = cluster_data[('åœ¨åº«å›è»¢æ—¥æ•°', 'mean')]\n",
    "    item_count = cluster_data[('å•†å“å', 'count')]\n",
    "    \n",
    "    # å‹•çš„ã«æˆ¦ç•¥ã‚’æ±ºå®š\n",
    "    if avg_rate > 0.8 and avg_turnover < 3:\n",
    "        strategy = \"ç™ºæ³¨é‡20-30%å¢—åŠ \"\n",
    "        reason = \"é«˜å›è»¢ãƒ»é«˜è²©å£²ç‡\"\n",
    "        priority = \"é«˜\"\n",
    "    elif avg_rate > 0.6 and avg_sales > cluster_profiles[('å£²ä¸Šé‡‘é¡', 'mean')].median():\n",
    "        strategy = \"ç¾çŠ¶ç¶­æŒãƒ»å¾®èª¿æ•´\"\n",
    "        reason = \"å®‰å®šçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\"\n",
    "        priority = \"ä¸­\"\n",
    "    elif avg_rate < 0.3:\n",
    "        strategy = \"ç™ºæ³¨é‡50%å‰Šæ¸›ã¾ãŸã¯å»ƒæ­¢\"\n",
    "        reason = \"ä½è²©å£²ç‡\"\n",
    "        priority = \"é«˜\"\n",
    "    elif avg_turnover > 7:\n",
    "        strategy = \"ç™ºæ³¨é‡30%å‰Šæ¸›\"\n",
    "        reason = \"åœ¨åº«æ»ç•™\"\n",
    "        priority = \"é«˜\"\n",
    "    else:\n",
    "        strategy = \"è²©ä¿ƒå¼·åŒ–å¾Œã«å†è©•ä¾¡\"\n",
    "        reason = \"æ”¹å–„ä½™åœ°ã‚ã‚Š\"\n",
    "        priority = \"ä¸­\"\n",
    "    \n",
    "    ordering_strategies[f'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼{cluster}'] = {\n",
    "        'å•†å“æ•°': int(item_count),\n",
    "        'å¹³å‡è²©å£²ç‡': float(avg_rate),\n",
    "        'å¹³å‡å›è»¢æ—¥æ•°': float(avg_turnover),\n",
    "        'æˆ¦ç•¥': strategy,\n",
    "        'ç†ç”±': reason,\n",
    "        'å„ªå…ˆåº¦': priority\n",
    "    }\n",
    "\n",
    "# æˆ¦ç•¥ã®è¡¨ç¤º\n",
    "print(\"ğŸ“Š å‹•çš„ç™ºæ³¨æˆ¦ç•¥ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã«åŸºã¥ãï¼‰:\")\n",
    "for cluster, strategy in ordering_strategies.items():\n",
    "    print(f\"\\n{cluster}ï¼ˆ{strategy['å•†å“æ•°']}å•†å“ï¼‰:\")\n",
    "    print(f\"  è²©å£²ç‡: {strategy['å¹³å‡è²©å£²ç‡']:.1%}\")\n",
    "    print(f\"  å›è»¢æ—¥æ•°: {strategy['å¹³å‡å›è»¢æ—¥æ•°']:.1f}æ—¥\")\n",
    "    print(f\"  æˆ¦ç•¥: {strategy['æˆ¦ç•¥']}\")\n",
    "    print(f\"  ç†ç”±: {strategy['ç†ç”±']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f795e-182b-473c-9863-374338d868be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 10. çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆGPUæœ€é©åŒ–ï¼‰\n",
    "\n",
    "# %%\n",
    "# çµ±åˆKPIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ\n",
    "print(\"ğŸ“Š çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆä¸­...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. åº—èˆ—åˆ¥KPI\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "store_kpi_data = store_stats[['åº—èˆ—', 'æ—¥è²©', 'è²©å£²ç‡_mean']]\n",
    "x = np.arange(len(store_kpi_data))\n",
    "width = 0.35\n",
    "\n",
    "ax1_twin = ax1.twinx()\n",
    "bars1 = ax1.bar(x, store_kpi_data['æ—¥è²©'] / 10000, width, label='æ—¥è²©ï¼ˆä¸‡å††ï¼‰', color=COLORS[0])\n",
    "line1 = ax1_twin.plot(x, store_kpi_data['è²©å£²ç‡_mean'] * 100, 'o-', \n",
    "                      color=COLORS[1], linewidth=2, markersize=10, label='è²©å£²ç‡ï¼ˆ%ï¼‰')\n",
    "\n",
    "ax1.set_xlabel('åº—èˆ—', fontproperties=JP_FP)\n",
    "ax1.set_ylabel('æ—¥è²©ï¼ˆä¸‡å††ï¼‰', color=COLORS[0], fontproperties=JP_FP)\n",
    "ax1_twin.set_ylabel('è²©å£²ç‡ï¼ˆ%ï¼‰', color=COLORS[1], fontproperties=JP_FP)\n",
    "ax1.set_title('åº—èˆ—åˆ¥KPI', fontsize=16, fontproperties=JP_FP)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(store_kpi_data['åº—èˆ—'])\n",
    "\n",
    "# 2. æ©Ÿä¼šæå¤±åˆ†æ\n",
    "ax2 = fig.add_subplot(gs[0, 2:])\n",
    "loss_values = list(loss_data.values())\n",
    "loss_labels = [f'{k}\\n{v:.0f}ä¸‡å††' for k, v in loss_data.items()]\n",
    "bars2 = ax2.bar(range(len(loss_values)), loss_values, color=['#E74C3C', '#F39C12'])\n",
    "ax2.set_ylabel('é‡‘é¡ï¼ˆä¸‡å††ï¼‰', fontproperties=JP_FP)\n",
    "ax2.set_title(f'æ”¹å–„æ©Ÿä¼š: åˆè¨ˆ{sum(loss_values, fontproperties=JP_FP):.0f}ä¸‡å††', fontsize=16)\n",
    "ax2.set_xticks(range(len(loss_values)))\n",
    "ax2.set_xticklabels(loss_labels)\n",
    "\n",
    "# 3. å•†å“åŠ¹ç‡ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆç°¡ç•¥ç‰ˆï¼‰\n",
    "ax3 = fig.add_subplot(gs[1, :2])\n",
    "for category, color in colors_map.items():\n",
    "    data = efficiency_data[efficiency_data['å•†å“åˆ†é¡'] == category]\n",
    "    if len(data) > 0:\n",
    "        ax3.scatter(data['è²©å£²ç‡'].head(50) * 100, \n",
    "                   data['å£²ä¸Šé‡‘é¡'].head(50) / 10000,\n",
    "                   s=30, alpha=0.6, c=color, label=category)\n",
    "\n",
    "ax3.set_xlabel('è²©å£²ç‡ï¼ˆ%ï¼‰', fontproperties=JP_FP)\n",
    "ax3.set_ylabel('å£²ä¸Šé‡‘é¡ï¼ˆä¸‡å††ï¼‰', fontproperties=JP_FP)\n",
    "ax3.set_title('å•†å“åˆ†é¡ãƒãƒˆãƒªãƒƒã‚¯ã‚¹', fontsize=16, fontproperties=JP_FP)\n",
    "ax3.legend(loc='best', fontsize=8, prop=JP_FP)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "ax4 = fig.add_subplot(gs[1, 2:])\n",
    "weekly_values = [weekday_insights['pattern'][day] for day in weekday_order]\n",
    "bars4 = ax4.bar(weekday_order, weekly_values, color=COLORS[2])\n",
    "\n",
    "# ãƒ”ãƒ¼ã‚¯ã¨è°·ã‚’å¼·èª¿\n",
    "for i, day in enumerate(weekday_order):\n",
    "    if day == weekday_insights['peak_day']:\n",
    "        bars4[i].set_color('#2ECC71')\n",
    "    elif day == weekday_insights['low_day']:\n",
    "        bars4[i].set_color('#E74C3C')\n",
    "\n",
    "ax4.set_xlabel('æ›œæ—¥', fontproperties=JP_FP)\n",
    "ax4.set_ylabel('å¹³å‡å£²ä¸Š', fontproperties=JP_FP)\n",
    "ax4.set_title('æ›œæ—¥åˆ¥å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³', fontsize=16, fontproperties=JP_FP)\n",
    "ax4.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/10000):.0f}ä¸‡'))\n",
    "\n",
    "# 5. å‹•çš„æ¨å¥¨äº‹é …\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "ax5.axis('off')\n",
    "\n",
    "# æ¨å¥¨äº‹é …ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "recommendations_text = \"ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã«åŸºã¥ãå‹•çš„æ¨å¥¨äº‹é …ã€‘\\n\\n\"\n",
    "\n",
    "# å„ªå…ˆåº¦ã®é«˜ã„æ–½ç­–ã‚’æŠ½å‡º\n",
    "high_priority_actions = []\n",
    "\n",
    "# 1. å“è–„å¯¾ç­–\n",
    "if total_shortage_loss > 100000:\n",
    "    high_priority_actions.append({\n",
    "        'action': f'{len(shortage_products)}å•†å“ã®ç™ºæ³¨é‡ã‚’20-30%å¢—åŠ ',\n",
    "        'impact': f'{total_shortage_loss/10000:.0f}ä¸‡å††ã®æ©Ÿä¼šæå¤±å‰Šæ¸›',\n",
    "        'priority': 'é«˜'\n",
    "    })\n",
    "\n",
    "# 2. éå‰°åœ¨åº«å¯¾ç­–\n",
    "if total_excess_cost > 50000:\n",
    "    high_priority_actions.append({\n",
    "        'action': f'{len(excess_products)}å•†å“ã®ç™ºæ³¨é‡ã‚’æ®µéšçš„ã«å‰Šæ¸›',\n",
    "        'impact': f'{total_excess_cost/10000:.0f}ä¸‡å††ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›',\n",
    "        'priority': 'é«˜'\n",
    "    })\n",
    "\n",
    "# 3. æ›œæ—¥å¯¾ç­–\n",
    "if weekday_insights['peak_to_low_ratio'] > 1.5:\n",
    "    high_priority_actions.append({\n",
    "        'action': f\"{weekday_insights['peak_day']}ã®ç™ºæ³¨ã‚’{(weekday_insights['peak_to_low_ratio']-1)*100:.0f}%å¢—åŠ \",\n",
    "        'impact': 'å£²ä¸Šæ©Ÿä¼šã®æœ€å¤§åŒ–',\n",
    "        'priority': 'ä¸­'\n",
    "    })\n",
    "\n",
    "# 4. ãƒˆãƒ¬ãƒ³ãƒ‰å¯¾ç­–\n",
    "if trend_insights['direction'] == 'decreasing' and trend_insights['statistical_significance']:\n",
    "    high_priority_actions.append({\n",
    "        'action': 'å£²ä¸Šæ¸›å°‘ãƒˆãƒ¬ãƒ³ãƒ‰ã¸ã®å¯¾ç­–ï¼ˆå“æƒãˆãƒ»ä¾¡æ ¼è¦‹ç›´ã—ï¼‰',\n",
    "        'impact': f'æ—¥æ¬¡{abs(trend_insights[\"daily_change\"]):.0f}å††ã®æ¸›å°‘ã‚’é£Ÿã„æ­¢ã‚ã‚‹',\n",
    "        'priority': 'é«˜'\n",
    "    })\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ\n",
    "for i, action in enumerate(high_priority_actions[:5], 1):\n",
    "    recommendations_text += f\"{i}. {action['action']}\\n\"\n",
    "    recommendations_text += f\"   æœŸå¾…åŠ¹æœ: {action['impact']}\\n\"\n",
    "    recommendations_text += f\"   å„ªå…ˆåº¦: {action['priority']}\\n\\n\"\n",
    "\n",
    "ax5.text(0.05, 0.95, recommendations_text, transform=ax5.transAxes,\n",
    "         fontsize=12, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3, fontproperties=JP_FP))\n",
    "\n",
    "plt.suptitle('å‹•çš„ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆçµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆGPUåŠ é€Ÿï¼‰', fontsize=20, fontproperties=JP_FP)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã®è¡¨ç¤º\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"\\nğŸ“Š GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ï¼ˆå‡¦ç†å¾Œï¼‰: {info.used/1e9:.1f}/{info.total/1e9:.1f} GB\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a70725-0693-4693-8d92-f2dd3d5e20da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 11. LLMç”¨æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›\n",
    "\n",
    "# %%\n",
    "# å…¨ã¦ã®åˆ†æçµæœã‚’çµ±åˆ\n",
    "print(\"ğŸ“Š åˆ†æçµæœã‚’æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ä¸­...\")\n",
    "\n",
    "integrated_insights = {\n",
    "    \"analysis_metadata\": {\n",
    "        \"analysis_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"gpu_enabled\": GPU_AVAILABLE,\n",
    "        \"data_period\": {\n",
    "            \"start\": df['æ—¥ä»˜'].min().strftime(\"%Y-%m-%d\"),\n",
    "            \"end\": df['æ—¥ä»˜'].max().strftime(\"%Y-%m-%d\"),\n",
    "            \"days\": int((df['æ—¥ä»˜'].max() - df['æ—¥ä»˜'].min()).days) + 1\n",
    "        },\n",
    "        \"data_scope\": {\n",
    "            \"total_records\": int(len(df)),\n",
    "            \"stores\": int(df['åº—èˆ—'].nunique()),\n",
    "            \"products\": int(df['å•†å“å'].nunique()),\n",
    "            \"categories\": int(df['ãƒ•ã‚§ã‚¤ã‚¹ããã‚Šå¤§åˆ†é¡'].nunique())\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"key_metrics\": {\n",
    "        \"store_performance\": store_stats[['åº—èˆ—', 'æ—¥è²©', 'è²©å£²ç‡_mean']].to_dict('records'),\n",
    "        \"total_daily_sales\": float(store_stats['æ—¥è²©'].sum()),\n",
    "        \"average_sales_rate\": float(df['è²©å£²ç‡'].mean()),\n",
    "        \"opportunity_analysis\": {\n",
    "            \"shortage_loss\": float(total_shortage_loss),\n",
    "            \"excess_cost\": float(total_excess_cost),\n",
    "            \"total_opportunity\": float(total_shortage_loss + total_excess_cost),\n",
    "            \"shortage_products_count\": int(len(shortage_products)),\n",
    "            \"excess_products_count\": int(len(excess_products))\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"patterns_discovered\": {\n",
    "        \"weekly_pattern\": weekday_insights,\n",
    "        \"time_trend\": trend_insights,\n",
    "        \"weather_impact\": {\n",
    "            \"temperature_correlation\": float(corr_coef),\n",
    "            \"best_weather\": weather_avg.index[0],\n",
    "            \"weather_sales_impact\": float(weather_avg.iloc[0] / weather_avg.iloc[-1])\n",
    "        },\n",
    "        \"temperature_sensitive_products\": temp_sensitive_products\n",
    "    },\n",
    "    \n",
    "    \"product_insights\": {\n",
    "        \"classification_summary\": classification_stats.to_dict(),\n",
    "        \"reduction_candidates\": {\n",
    "            \"count\": int(total_reduction_items),\n",
    "            \"impact_sales\": float(total_reduction_sales),\n",
    "            \"percentage_of_total\": float(total_reduction_sales/efficiency_data['å£²ä¸Šé‡‘é¡'].sum()*100)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"category_insights\": {\n",
    "        \"top_categories\": category_performance.head(5)['å£²ä¸Šé‡‘é¡'].to_dict(),\n",
    "        \"pb_nb_comparison\": pb_nb_performance.to_dict()\n",
    "    },\n",
    "    \n",
    "    \"ordering_strategies\": ordering_strategies,\n",
    "    \n",
    "    \"priority_actions\": [\n",
    "        {\n",
    "            \"action\": action['action'],\n",
    "            \"expected_impact\": action['impact'],\n",
    "            \"priority\": action['priority']\n",
    "        }\n",
    "        for action in high_priority_actions\n",
    "    ],\n",
    "    \n",
    "    \"processing_info\": {\n",
    "        \"gpu_used\": GPU_AVAILABLE,\n",
    "        \"processing_time\": \"æœ€é©åŒ–æ¸ˆã¿ï¼ˆGPUåŠ é€Ÿï¼‰\" if GPU_AVAILABLE else \"æ¨™æº–å‡¦ç†\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSONå½¢å¼ã§ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "output_path = Path('analysis_results_gpu.json')\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(integrated_insights, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "print(\"âœ… åˆ†æçµæœã‚’JSONå½¢å¼ã§ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "print(f\"   ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}\")\n",
    "\n",
    "# %%\n",
    "# åˆ†æã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼ï¼ˆLLMè§£é‡ˆç”¨ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. åŸºæœ¬æƒ…å ±:\")\n",
    "print(f\"   åˆ†ææœŸé–“: {integrated_insights['analysis_metadata']['data_period']['days']}æ—¥é–“\")\n",
    "print(f\"   ç·å£²ä¸Š: {integrated_insights['key_metrics']['total_daily_sales']/10000:.0f}ä¸‡å††/æ—¥\")\n",
    "print(f\"   å¹³å‡è²©å£²ç‡: {integrated_insights['key_metrics']['average_sales_rate']:.1%}\")\n",
    "print(f\"   GPUä½¿ç”¨: {'âœ… æœ‰åŠ¹' if GPU_AVAILABLE else 'âŒ ç„¡åŠ¹'}\")\n",
    "\n",
    "print(f\"\\n2. æ”¹å–„æ©Ÿä¼š:\")\n",
    "print(f\"   åˆè¨ˆ: {integrated_insights['key_metrics']['opportunity_analysis']['total_opportunity']/10000:.0f}ä¸‡å††\")\n",
    "print(f\"   å“è–„å•†å“: {integrated_insights['key_metrics']['opportunity_analysis']['shortage_products_count']}å“\")\n",
    "print(f\"   éå‰°åœ¨åº«: {integrated_insights['key_metrics']['opportunity_analysis']['excess_products_count']}å“\")\n",
    "\n",
    "print(f\"\\n3. ç™ºè¦‹ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³:\")\n",
    "print(f\"   æ›œæ—¥ãƒ”ãƒ¼ã‚¯: {integrated_insights['patterns_discovered']['weekly_pattern']['peak_day']}\")\n",
    "print(f\"   å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰: {integrated_insights['patterns_discovered']['time_trend']['direction']}\")\n",
    "print(f\"   æ°—æ¸©ç›¸é–¢: {integrated_insights['patterns_discovered']['weather_impact']['temperature_correlation']:.3f}\")\n",
    "\n",
    "print(f\"\\n4. å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(integrated_insights['priority_actions'])}\")\n",
    "\n",
    "print(\"\\nâ€»ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’LLMã«å…¥åŠ›ã™ã‚‹ã“ã¨ã§ã€ã•ã‚‰ã«è©³ç´°ãªåˆ†æã¨ææ¡ˆãŒå¯èƒ½ã§ã™\")\n",
    "\n",
    "# %%\n",
    "# åˆ†æå®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… å‹•çš„æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆGPUæœ€é©åŒ–ç‰ˆï¼‰\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nå‡¦ç†ã®ç‰¹å¾´:\")\n",
    "print(\"- cudf.pandasã«ã‚ˆã‚‹é€éçš„ãªGPUåŠ é€Ÿ\")\n",
    "print(\"- å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®é«˜é€Ÿé›†è¨ˆãƒ»åˆ†æ\")\n",
    "print(\"- æ—¥æœ¬èªå¯¾å¿œã®å¯è¦–åŒ–\")\n",
    "print(\"- LLMå‘ã‘æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›\")\n",
    "print(\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "print(\"1. analysis_results_gpu.jsonã‚’LLMã«å…¥åŠ›ã—ã¦è©³ç´°ãªè§£é‡ˆã‚’å¾—ã‚‹\")\n",
    "print(\"2. äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«é€²ã‚€\")\n",
    "print(\"3. ç‰¹å®šã®å•†å“ã‚„åº—èˆ—ã®æ·±å €ã‚Šåˆ†æã‚’å®Ÿæ–½\")\n",
    "print(\"\\nGPUç’°å¢ƒã«ã‚ˆã‚Šã€ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã§ã‚‚é«˜é€Ÿãªåˆ†æãŒå¯èƒ½ã§ã™ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16326c-2171-4ced-bb83-6481e6dbd731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
