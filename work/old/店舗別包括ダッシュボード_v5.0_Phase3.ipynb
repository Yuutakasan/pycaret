{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏪 店舗別包括ダッシュボード v5.0 - Phase 3実装版\n",
    "\n",
    "## 📋 Phase 3で実装する5つの高度な分析機能\n",
    "\n",
    "### 🎯 **AI/機械学習で売上を最大化する**\n",
    "\n",
    "1. **I1. PyCaret自動特徴量選択** - SHAP値で重要特徴量を自動抽出\n",
    "2. **F2. トレンド検知・成長率分析** - Mann-Kendall検定で統計的にトレンドを検証\n",
    "3. **D2. 欠品検知・機会損失定量化** - 過去の欠品パターンから損失額を推定\n",
    "4. **B2. ベストプラクティス抽出** - トップ店舗の成功要因を自動分析\n",
    "5. **C3. マーケットバスケット分析** - Aprioriアルゴリズムで商品間の関連性を発見\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Phase 3の設計思想\n",
    "\n",
    "### Phase 1・2との違い\n",
    "- **Phase 1**: 「現状を把握する」（見える化）\n",
    "- **Phase 2**: 「問題を予防し、最適行動を導く」（最適化）\n",
    "- **Phase 3**: 「AIで売上を最大化する」（自動化・高度化）\n",
    "\n",
    "### 3つの柱\n",
    "1. **解釈可能なAI**: ブラックボックスではなく、なぜそう予測したかを説明\n",
    "2. **パターン発見**: 人間では気づけない商品間の関連性を発見\n",
    "3. **ベンチマーク学習**: トップ店舗の成功要因を他店に横展開\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語フォント設定\n",
    "import font_setup\n",
    "JP_FP = font_setup.setup_fonts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリ先読み\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotly（利用可能な場合）\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    import plotly.io as pio\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "\n",
    "# ipywidgets\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "\n",
    "# matplotlib共通設定\n",
    "plt.rcParams['figure.figsize'] = (18, 12)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# seaborn\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# pandas\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('🏪 店舗別包括ダッシュボード v5.0'.center(80))\n",
    "print('='*80)\n",
    "print(f'\\n✅ 環境設定完了')\n",
    "print(f'   実行日時: {datetime.now().strftime(\"%Y年%m月%d日 %H:%M:%S\")}')\n",
    "print(f'   pandas: {pd.__version__}')\n",
    "print(f'   matplotlib: {plt.matplotlib.__version__}')\n",
    "print(f'   Plotly: {\"利用可能\" if PLOTLY_AVAILABLE else \"未インストール\"}')\n",
    "print(f'   ipywidgets: {\"利用可能\" if WIDGETS_AVAILABLE else \"未インストール\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリ先読み\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotly（利用可能な場合）\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    import plotly.io as pio\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "\n",
    "# ipywidgets\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "\n",
    "# matplotlib共通設定\n",
    "plt.rcParams['figure.figsize'] = (18, 12)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# seaborn\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# pandas\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('🏪 店舗別包括ダッシュボード v5.0'.center(80))\n",
    "print('='*80)\n",
    "print(f'\\n✅ 環境設定完了')\n",
    "print(f'   実行日時: {datetime.now().strftime(\"%Y年%m月%d日 %H:%M:%S\")}')\n",
    "print(f'   pandas: {pd.__version__}')\n",
    "print(f'   matplotlib: {plt.matplotlib.__version__}')\n",
    "print(f'   Plotly: {\"利用可能\" if PLOTLY_AVAILABLE else \"未インストール\"}')\n",
    "print(f'   ipywidgets: {\"利用可能\" if WIDGETS_AVAILABLE else \"未インストール\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリ先読み\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotly（利用可能な場合）\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    import plotly.io as pio\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "\n",
    "# ipywidgets\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "\n",
    "# matplotlib共通設定\n",
    "plt.rcParams['figure.figsize'] = (18, 12)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# seaborn\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# pandas\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('🏪 店舗別包括ダッシュボード v5.0'.center(80))\n",
    "print('='*80)\n",
    "print(f'\\n✅ 環境設定完了')\n",
    "print(f'   実行日時: {datetime.now().strftime(\"%Y年%m月%d日 %H:%M:%S\")}')\n",
    "print(f'   pandas: {pd.__version__}')\n",
    "print(f'   matplotlib: {plt.matplotlib.__version__}')\n",
    "print(f'   Plotly: {\"利用可能\" if PLOTLY_AVAILABLE else \"未インストール\"}')\n",
    "print(f'   ipywidgets: {\"利用可能\" if WIDGETS_AVAILABLE else \"未インストール\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display\n    WIDGETS_AVAILABLE = True\nexcept:\n    WIDGETS_AVAILABLE = False\nplt.rcParams['figure.figsize'] = (18, 12)\nplt.rcParams['axes.unicode_minus'] = False\nsns.set_style('whitegrid')\npd.set_option('display.max_columns', 50)\nprint('\\n' + '='*80)\nprint('🏪 店舗別包括ダッシュボード v5.0'.center(80))\nprint('='*80)\nprint(f'\\n✅ 環境設定完了 {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 データ読み込み\n",
    "print(\"\\n📂 データ読み込み中...\")\n",
    "\n",
    "df_enriched = pd.read_csv('output/06_final_enriched_20250701_20250930.csv')\n",
    "df_enriched['日付'] = pd.to_datetime(df_enriched['日付'])\n",
    "\n",
    "print(f\"✅ データ読み込み完了\")\n",
    "print(f\"   行数: {len(df_enriched):,}\")\n",
    "print(f\"   列数: {len(df_enriched.columns)}\")\n",
    "print(f\"   期間: {df_enriched['日付'].min()} ~ {df_enriched['日付'].max()}\")\n",
    "print(f\"   店舗数: {df_enriched['店舗'].nunique()}\")\n",
    "print(f\"   商品数: {df_enriched['商品名'].nunique():,}\")\n",
    "\n",
    "stores = df_enriched['店舗'].unique()\n",
    "print(f\"\\n🏪 店舗一覧:\")\n",
    "for i, store in enumerate(stores, 1):\n",
    "    print(f\"   {i}. {store}\")\n",
    "\n",
    "DEFAULT_STORE = stores[0]\n",
    "try:\n",
    "    MY_STORE\n",
    "except NameError:\n",
    "    MY_STORE = DEFAULT_STORE\n",
    "print(f\"\\n🎯 分析対象店舗: {MY_STORE}\")\n",
    "\n",
    "my_df = df_enriched[df_enriched['店舗'] == MY_STORE].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 店舗選択ウィジェット\n",
    "\n",
    "# 店舗一覧\n",
    "stores = sorted(df_enriched['店舗'].unique())\n",
    "DEFAULT_STORE = stores[0]\n",
    "\n",
    "print(f\"\\n🏪 利用可能な店舗 ({len(stores)}店舗):\")\n",
    "for i, store in enumerate(stores, 1):\n",
    "    print(f\"   {i}. {store}\")\n",
    "\n",
    "# 店舗選択ウィジェット\n",
    "if WIDGETS_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🎯 以下のドロップダウンから分析対象店舗を選択してください\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    store_dropdown = widgets.Dropdown(\n",
    "        options=stores,\n",
    "        value=DEFAULT_STORE,\n",
    "        description='分析対象店舗:',\n",
    "        disabled=False,\n",
    "        style={'description_width': '120px'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "    \n",
    "    info_label = widgets.HTML(\n",
    "        value=\"<b>💡 ヒント:</b> 店舗を変更すると、以降のすべての分析が選択した店舗で再計算されます。\"\n",
    "    )\n",
    "    \n",
    "    display(widgets.VBox([store_dropdown, info_label]))\n",
    "    \n",
    "    # 選択された店舗\n",
    "    MY_STORE = store_dropdown.value\n",
    "else:\n",
    "    pass\n",
    "    # ウィジェットが使えない場合\n",
    "    print(f\"\\n🎯 分析対象店舗: {MY_STORE} (デフォルト)\")\n",
    "\n",
    "# 店舗データフィルタリング\n",
    "my_df = df_enriched[df_enriched['店舗'] == MY_STORE].copy()\n",
    "\n",
    "print(f\"\\n✅ 選択された店舗: {MY_STORE}\")\n",
    "print(f\"   対象データ: {len(my_df):,}行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 データ検証（存在チェック）\n",
    "\n",
    "def validate_data_column(df, col_name, analysis_name=\"分析\"):\n",
    "    \"\"\"データカラムの存在と有効性をチェック\"\"\"\n",
    "    if col_name not in df.columns:\n",
    "        print(f\"⚠️ {analysis_name}: '{col_name}' カラムが存在しません\")\n",
    "        return False\n",
    "    \n",
    "    non_null_count = df[col_name].notna().sum()\n",
    "    coverage = non_null_count / len(df) * 100\n",
    "    \n",
    "    if coverage < 50:\n",
    "        print(f\"⚠️ {analysis_name}: '{col_name}' のカバレッジが低い ({coverage:.1f}%)\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"\\n🔍 データ検証中...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 必須カラムチェック\n",
    "required_cols = ['日付', '売上金額', '店舗']\n",
    "for col in required_cols:\n",
    "    if col in df_enriched.columns:\n",
    "        print(f\"✅ 必須カラム '{col}' - 存在\")\n",
    "    else:\n",
    "        print(f\"❌ 必須カラム '{col}' - 不足\")\n",
    "        print(f\"❌ 必須カラム '{col}' - 不足\")\n",
    "\n",
    "# オプションカラムチェック\n",
    "optional_cols = {\n",
    "    '気象データ': ['最高気温', '降水量'],\n",
    "    '前年データ': ['昨年同日_売上', '昨年同日_客数'],\n",
    "    '時間帯データ': ['時刻', '時間']\n",
    "}\n",
    "\n",
    "for category, cols in optional_cols.items():\n",
    "    has_any = any(col in df_enriched.columns for col in cols)\n",
    "    if has_any:\n",
    "        available_cols = [col for col in cols if col in df_enriched.columns]\n",
    "        print(f\"✅ {category}: {', '.join(available_cols)}\")\n",
    "    else:\n",
    "        print(f\"❌ 必須カラム '{col}' - 不足\")\n",
    "        print(f\"⚠️ {category}: 利用不可（代替ロジック使用）\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✅ データ検証完了\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🤖 【機能1】PyCaret自動特徴量選択・重要度分析\n",
    "\n",
    "## SHAP値で「なぜその予測になったか」を説明\n",
    "\n",
    "### SHAP (SHapley Additive exPlanations) とは\n",
    "- ゲーム理論に基づく特徴量の貢献度分析\n",
    "- 各特徴量が予測にどれだけ寄与したかを定量化\n",
    "- ポジティブ/ネガティブの影響を可視化\n",
    "\n",
    "### 分析内容\n",
    "1. **グローバル特徴量重要度** - 全体で最も重要な特徴量TOP 20\n",
    "2. **SHAP Summary Plot** - 各特徴量の影響の分布\n",
    "3. **SHAP Dependence Plot** - 特定特徴量と予測の関係\n",
    "4. **特徴量の自動削減** - 重要度が低い特徴量を除外\n",
    "5. **予測精度の比較** - 削減前後のパフォーマンス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n# 📊 グラフの見方ガイド\n#\n# 【特徴量重要度グラフ】\n#   ・棒が長い項目 → 売上予測に大きく影響する要素\n#   ・上位3つの要素に注目して施策を考える\n#\n#   例）「最高気温」が上位 → 気温による商品入替が効果的\n#       「曜日」が上位 → 曜日別の品揃え変更が重要\n#       「昨年同日_売上」が上位 → 前年データを参考にした発注が有効\n#\n#   ✅ 判断基準: 重要度0.1以上の要素に集中して対策を打つ\n\n\n",
    "# 🤖 PyCaret自動特徴量選択エンジン\n",
    "\n",
    "if PYCARET_AVAILABLE:\n",
    "    print(\"\\n🤖 PyCaret自動特徴量選択・重要度分析\\n\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # モデリング用データ準備\n",
    "    print(\"\\n📊 特徴量準備中...\")\n",
    "    \n",
    "    # 特徴量候補（Phase 1よりも拡張）\n",
    "    feature_candidates = [\n",
    "        # 基本時間\n",
    "        '曜日', '月', '日', '週番号',\n",
    "        # フラグ\n",
    "        '祝日フラグ', '週末フラグ', '平日フラグ',\n",
    "        # イベント\n",
    "        '給料日', '連休フラグ', '連休日数', '連休初日', '連休最終日',\n",
    "        'GW', '盆休み', '年末年始',\n",
    "        # 学校\n",
    "        '夏休み', '冬休み',\n",
    "        # 季節変動\n",
    "        '季節変動指数_月', '季節変動指数_週', '季節_ピーク期',\n",
    "        # 前年比較\n",
    "        '昨年同日_売上', '昨年同日_客数', '昨年同日_客単価',\n",
    "        '昨年同日比_売上_変化率', '昨年同日比_客数_変化率',\n",
    "    ]\n",
    "    \n",
    "    # 気象特徴量\n",
    "    weather_candidates = [\n",
    "        '最高気温', '最低気温', '降水量', '降雨フラグ',\n",
    "        '最高気温_MA7', '最高気温_MA14', '最高気温_MA30',\n",
    "        '気温トレンド_7d', '気温トレンド_14d',\n",
    "        '気温変化_前日比', '降水量_累積7d'\n",
    "    ]\n",
    "    \n",
    "    # 利用可能な列のみ選択\n",
    "    available_features = [col for col in feature_candidates if col in my_df.columns]\n",
    "    available_weather = [col for col in weather_candidates if col in my_df.columns and my_df[col].notna().sum() > 0]\n",
    "    \n",
    "    all_features = available_features + available_weather\n",
    "    \n",
    "    print(f\"   基本特徴量: {len(available_features)}個\")\n",
    "    print(f\"   気象特徴量: {len(available_weather)}個\")\n",
    "    print(f\"   合計: {len(all_features)}個\")\n",
    "    \n",
    "    # 商品別日次データ\n",
    "    product_daily = my_df.groupby(['商品名', '日付']).agg({\n",
    "        '売上金額': 'sum',\n",
    "        **{col: 'first' for col in all_features}\n",
    "    }).reset_index()\n",
    "    \n",
    "    # TOP 50商品のみ（計算時間短縮）\n",
    "    top_products = my_df.groupby('商品名')['売上金額'].sum().nlargest(50).index\n",
    "    product_daily = product_daily[product_daily['商品名'].isin(top_products)]\n",
    "    \n",
    "    # 欠損値削除\n",
    "    product_daily = product_daily.dropna(subset=['売上金額'] + all_features)\n",
    "    \n",
    "    print(f\"\\n   モデリングデータ: {len(product_daily):,}行\")\n",
    "    \n",
    "    if len(product_daily) >= 100:\n",
    "        print(\"\\n⏳ PyCaretセットアップ中...（数分かかります）\")\n",
    "        \n",
    "        # PyCaretセットアップ\n",
    "        reg = setup(\n",
    "            data=product_daily,\n",
    "            target='売上金額',\n",
    "            categorical_features=['商品名'] if '商品名' in all_features else None,\n",
    "            numeric_features=[col for col in all_features if col != '商品名'],\n",
    "            fold_strategy='timeseries',\n",
    "            fold=3,\n",
    "            normalize=True,\n",
    "            feature_selection=True,\n",
    "            feature_selection_threshold=0.8,\n",
    "            remove_multicollinearity=True,\n",
    "            multicollinearity_threshold=0.9,\n",
    "            session_id=42,\n",
    "            verbose=False,\n",
    "            html=False\n",
    "        )\n",
    "        \n",
    "        print(\"✅ セットアップ完了\")\n",
    "        \n",
    "        # モデル学習\n",
    "        print(\"\\n⏳ LightGBMモデル学習中...\")\n",
    "        model = create_model('lightgbm', verbose=False)\n",
    "        \n",
    "        print(\"✅ モデル学習完了\")\n",
    "        \n",
    "        # モデル評価\n",
    "        results = pull()\n",
    "        \n",
    "        print(f\"\\n📈 モデル性能（3分割時系列CV）\")\n",
    "        print(\"=\" * 120)\n",
    "        print(f\"   MAE:  ¥{results['平均絶対誤差'].mean():,.0f}\")\n",
    "        print(f\"   RMSE: ¥{results['二乗平均平方根誤差'].mean():,.0f}\")\n",
    "        print(f\"   R2:   {results['R2'].mean():.4f}\")\n",
    "        print(f\"   MAPE: {results['平均絶対パーセント誤差'].mean():.2f}%\")\n",
    "        \n",
    "        # 特徴量重要度（LightGBM組み込み）\n",
    "        print(f\"\\n\\n🔍 特徴量重要度分析（LightGBM）\")\n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_names = get_config('X_train').columns\n",
    "            importance_df = pd.DataFrame({\n",
    "                '特徴量': feature_names,\n",
    "                '重要度': model.feature_importances_\n",
    "            }).sort_values('重要度', ascending=False)\n",
    "            \n",
    "            print(f\"\\n特徴量重要度 TOP 20:\")\n",
    "            print(\"-\" * 120)\n",
    "            for idx, row in importance_df.head(20).iterrows():\n",
    "                feature = row['特徴量']\n",
    "                importance = row['重要度']\n",
    "                bar = \"█\" * int(importance * 50)\n",
    "                print(f\"   {feature:<40} {bar:<50} {importance:.4f}\")\n",
    "            \n",
    "            # 可視化\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "            \n",
    "            # 1. TOP 20特徴量重要度\n",
    "            ax1 = axes[0]\n",
    "            top20 = importance_df.head(20)\n",
    "            ax1.barh(range(len(top20)), top20['重要度'], color='#4ECDC4', edgecolor='black')\n",
    "            ax1.set_yticks(range(len(top20)))\n",
    "            ax1.set_yticklabels(top20['特徴量'], fontsize=10)\n",
    "            ax1.set_xlabel('重要度スコア', fontsize=12, fontproperties=JP_FP)\n",
    "            ax1.set_title('Feature Importance TOP 20 (LightGBM)', fontsize=14, fontproperties=JP_FP)\n",
    "            ax1.invert_yaxis()\n",
    "            ax1.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            # 2. カテゴリ別の重要度集計\n",
    "            ax2 = axes[1]\n",
    "            \n",
    "            def categorize_feature(feature):\n",
    "                if any(x in feature for x in ['曜日', '月', '日', '週']):\n",
    "                    return '時間'\n",
    "                elif any(x in feature for x in ['祝日', '週末', '平日']):\n",
    "                    return 'フラグ'\n",
    "                elif any(x in feature for x in ['給料', '連休', 'GW', '盆', '年末', '夏休', '冬休']):\n",
    "                    return 'イベント'\n",
    "                elif any(x in feature for x in ['気温', '降水', '降雨']):\n",
    "                    return '気象'\n",
    "                elif any(x in feature for x in ['昨年', '前年']):\n",
    "                    return '前年比較'\n",
    "                elif any(x in feature for x in ['季節']):\n",
    "                    return '季節性'\n",
    "                else:\n",
    "                    pass\n",
    "                    return 'その他'\n",
    "            \n",
    "            importance_df['カテゴリ'] = importance_df['特徴量'].apply(categorize_feature)\n",
    "            category_importance = importance_df.groupby('カテゴリ')['重要度'].sum().sort_values(ascending=False)\n",
    "            \n",
    "            colors_cat = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F', '#BB8FCE']\n",
    "            category_importance.plot(kind='pie', ax=ax2, autopct='%1.1f%%', \n",
    "                                     colors=colors_cat[:len(category_importance)],\n",
    "                                     startangle=90)\n",
    "            ax2.set_ylabel('', fontproperties=JP_FP)\n",
    "            ax2.set_title('カテゴリ別特徴量重要度', fontsize=14, fontproperties=JP_FP)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # SHAP値分析（時間がかかるため簡易版）\n",
    "            print(f\"\\n\\n🔬 SHAP値分析（解釈可能性）\")\n",
    "            print(\"=\" * 120)\n",
    "            print(\"   ⏳ SHAP値計算中...（数分かかります）\")\n",
    "            \n",
    "            try:\n",
    "                # サンプリング（計算時間短縮）\n",
    "                X_sample = get_config('X_train').sample(min(500, len(get_config('X_train'))), random_state=42)\n",
    "                \n",
    "                # TreeExplainer（LightGBM用）\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                shap_values = explainer.shap_values(X_sample)\n",
    "                \n",
    "                print(\"   ✅ SHAP値計算完了\")\n",
    "                \n",
    "                # SHAP Summary Plot\n",
    "                fig, ax = plt.subplots(figsize=(14, 10))\n",
    "                shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False, max_display=20)\n",
    "                plt.title('SHAP特徴量重要度', fontsize=16, fontproperties=JP_FP)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # 解釈\n",
    "                print(f\"\\n💡 SHAP値による解釈\")\n",
    "                print(\"-\" * 120)\n",
    "                print(f\"   SHAP値は各特徴量が予測にどれだけ貢献したかを示します\")\n",
    "                print(f\"   プラス値 = 売上を押し上げる要因\")\n",
    "                print(f\"   マイナス値 = 売上を押し下げる要因\")\n",
    "                print(f\"   絶対値が大きい = 影響力が大きい\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ SHAP値計算エラー: {str(e)}\")\n",
    "                print(f\"   通常の特徴量重要度のみ使用します\")\n",
    "        \n",
    "        # 特徴量削減の効果検証\n",
    "        print(f\"\\n\\n🔧 特徴量削減の効果検証\")\n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        # 重要度の低い特徴量を削除\n",
    "        threshold = importance_df['重要度'].quantile(0.2)  # 下位20%を削除\n",
    "        low_importance_features = importance_df[importance_df['重要度'] < threshold]['特徴量'].tolist()\n",
    "        \n",
    "        print(f\"   削減候補特徴量: {len(low_importance_features)}個（下位20%）\")\n",
    "        print(f\"   削減後特徴量数: {len(feature_names) - len(low_importance_features)}個\")\n",
    "        \n",
    "        if len(low_importance_features) > 0:\n",
    "            print(f\"\\n   削減する特徴量:\")\n",
    "            for feat in low_importance_features[:10]:\n",
    "                print(f\"      - {feat}\")\n",
    "            if len(low_importance_features) > 10:\n",
    "                print(f\"      ... 他{len(low_importance_features)-10}個\")\n",
    "            \n",
    "            print(f\"\\n   💡 推奨:\")\n",
    "            print(f\"      これらの特徴量を削除することで:\")\n",
    "            print(f\"      - 学習時間が約{(len(low_importance_features)/len(feature_names))*100:.0f}%短縮\")\n",
    "            print(f\"      - モデルの解釈性が向上\")\n",
    "            print(f\"      - 過学習のリスクが低減\")\n",
    "            print(f\"      - 予測精度への影響は最小（重要度が低いため）\")\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "        print(f\"   ⚠️ データ不足: {len(product_daily)}行（最低100行必要）\")\n",
    "\n",
    "else:\n",
    "    pass\n",
    "    print(\"\\n⚠️ PyCaretがインストールされていないため、この機能はスキップされます\")\n",
    "    print(\"   pip install pycaret shap でインストールしてください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📈 【機能2】トレンド検知・成長率分析\n",
    "\n",
    "## Mann-Kendall検定で統計的にトレンドを検証\n",
    "\n",
    "### Mann-Kendall検定とは\n",
    "- ノンパラメトリック検定（正規分布を仮定しない）\n",
    "- 時系列データのトレンド（単調増加/減少）を検出\n",
    "- p値 < 0.05 で統計的に有意なトレンドと判定\n",
    "\n",
    "### 分析内容\n",
    "1. **商品別トレンド検定** - 各商品の売上トレンドを統計的に検証\n",
    "2. **成長率の計算** - CAGR（年平均成長率）の算出\n",
    "3. **トレンド分類** - 成長商品/衰退商品/安定商品\n",
    "4. **季節調整トレンド** - 季節性を除去した真のトレンド\n",
    "5. **将来予測** - 線形トレンドによる外挿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 トレンド検知・成長率分析エンジン\n",
    "\n",
    "print(\"\\n📈 トレンド検知・成長率分析\\n\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "def mann_kendall_test(data):\n",
    "    \"\"\"\n",
    "    Mann-Kendall検定\n",
    "    Returns: (trend, p_value, tau)\n",
    "        trend: 'increasing', 'decreasing', 'no trend'\n",
    "        p_value: 有意確率\n",
    "        tau: Kendallのタウ（-1 ~ 1）\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    if n < 3:\n",
    "        return 'insufficient data', 1.0, 0.0\n",
    "    \n",
    "    # Kendallのタウ計算\n",
    "    s = 0\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            s += np.sign(data[j] - data[i])\n",
    "    \n",
    "    # 分散\n",
    "    var_s = n * (n - 1) * (2 * n + 5) / 18\n",
    "    \n",
    "    # Z統計量\n",
    "    if s > 0:\n",
    "        z = (s - 1) / np.sqrt(var_s)\n",
    "    elif s < 0:\n",
    "        z = (s + 1) / np.sqrt(var_s)\n",
    "    else:\n",
    "        pass\n",
    "        z = 0\n",
    "    \n",
    "    # p値（両側検定）\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    \n",
    "    # Kendallのタウ\n",
    "    tau = s / (n * (n - 1) / 2)\n",
    "    \n",
    "    # トレンド判定\n",
    "    if p_value < 0.05:\n",
    "        if tau > 0:\n",
    "            trend = 'increasing'\n",
    "        else:\n",
    "            pass\n",
    "            trend = 'decreasing'\n",
    "    else:\n",
    "        pass\n",
    "        trend = 'no trend'\n",
    "    \n",
    "    return trend, p_value, tau\n",
    "\n",
    "def calculate_cagr(start_value, end_value, periods):\n",
    "    \"\"\"CAGR（年平均成長率）の計算\"\"\"\n",
    "    if start_value <= 0 or end_value <= 0 or periods <= 0:\n",
    "        return np.nan\n",
    "    return (np.power(end_value / start_value, 1 / periods) - 1) * 100\n",
    "\n",
    "# 商品別の日次売上\n",
    "product_trends = []\n",
    "\n",
    "print(\"\\n⏳ 商品別トレンド分析中...\")\n",
    "\n",
    "for product in my_df['商品名'].unique():\n",
    "    product_data = my_df[my_df['商品名'] == product].sort_values('日付')\n",
    "    \n",
    "    if len(product_data) < 10:  # 最低10日以上のデータ\n",
    "        continue\n",
    "    \n",
    "    # 日次集計\n",
    "    daily_sales = product_data.groupby('日付')['売上金額'].sum().reset_index()\n",
    "    \n",
    "    if len(daily_sales) < 10:\n",
    "        continue\n",
    "    \n",
    "    sales_values = daily_sales['売上金額'].values\n",
    "    \n",
    "    # Mann-Kendall検定\n",
    "    trend, p_value, tau = mann_kendall_test(sales_values)\n",
    "    \n",
    "    # 成長率計算\n",
    "    start_value = sales_values[:7].mean()  # 最初の1週間平均\n",
    "    end_value = sales_values[-7:].mean()  # 最後の1週間平均\n",
    "    periods = len(sales_values) / 365  # 年数\n",
    "    \n",
    "    cagr = calculate_cagr(start_value, end_value, periods)\n",
    "    \n",
    "    # 線形回帰（トレンドライン）\n",
    "    x = np.arange(len(sales_values))\n",
    "    slope, intercept = np.polyfit(x, sales_values, 1)\n",
    "    \n",
    "    # 総売上\n",
    "    total_sales = sales_values.sum()\n",
    "    \n",
    "    product_trends.append({\n",
    "        '商品名': product,\n",
    "        'トレンド': trend,\n",
    "        'p値': p_value,\n",
    "        'Kendallのタウ': tau,\n",
    "        '年平均成長率': cagr,\n",
    "        '傾き': slope,\n",
    "        '切片': intercept,\n",
    "        '総売上': total_sales,\n",
    "        'データ日数': len(sales_values),\n",
    "        '平均日販': sales_values.mean(),\n",
    "        '標準偏差': sales_values.std()\n",
    "    })\n",
    "\n",
    "trends_df = pd.DataFrame(product_trends)\n",
    "\n",
    "print(f\"✅ トレンド分析完了: {len(trends_df)}商品\")\n",
    "\n",
    "# トレンド分類\n",
    "increasing = trends_df[trends_df['トレンド'] == 'increasing']\n",
    "decreasing = trends_df[trends_df['トレンド'] == 'decreasing']\n",
    "no_trend = trends_df[trends_df['トレンド'] == 'no trend']\n",
    "\n",
    "print(f\"\\n📊 トレンド分類サマリー\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"   📈 成長トレンド（統計的に有意）: {len(increasing)}商品 ({len(increasing)/len(trends_df)*100:.1f}%)\")\n",
    "print(f\"   📉 衰退トレンド（統計的に有意）: {len(decreasing)}商品 ({len(decreasing)/len(trends_df)*100:.1f}%)\")\n",
    "print(f\"   ➡️ トレンドなし（安定）:         {len(no_trend)}商品 ({len(no_trend)/len(trends_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 成長商品TOP 10\n",
    "\n",
    "print(f\"\\n\\n📈 成長商品 TOP 10（統計的に有意なトレンド）\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "if len(increasing) > 0:\n",
    "    top_growth = increasing.nlargest(10, '年平均成長率')\n",
    "    \n",
    "    print(f\"\\n{'商品名':<40} {'年平均成長率':>10} {'タウ':>8} {'p値':>10} {'平均日販':>12} {'総売上':>15}\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    for _, row in top_growth.iterrows():\n",
    "        product = row['商品名'][:38]\n",
    "        cagr = f\"{row['年平均成長率']:+.1f}%\"\n",
    "        tau = f\"{row['Kendallのタウ']:.3f}\"\n",
    "        p_val = f\"{row['p値']:.4f}\"\n",
    "        avg_sales = f\"¥{row['平均日販']:,.0f}\"\n",
    "        total = f\"¥{row['総売上']:,.0f}\"\n",
    "        \n",
    "        print(f\"{product:<40} {cagr:>10} {tau:>8} {p_val:>10} {avg_sales:>12} {total:>15}\")\n",
    "    \n",
    "    print(f\"\\n💡 成長商品の戦略\")\n",
    "    print(\"-\" * 120)\n",
    "    for _, row in top_growth.head(5).iterrows():\n",
    "        print(f\"\\n   📦 {row['商品名'][:50]}\")\n",
    "        print(f\"      成長率: CAGR {row['年平均成長率']:+.1f}% (統計的有意性: p={row['p値']:.4f})\")\n",
    "        print(f\"      推奨アクション:\")\n",
    "        \n",
    "        if row['年平均成長率'] > 50:\n",
    "            print(f\"         🔥 超高成長商品: フェイス数を2倍に、在庫を3倍に増量\")\n",
    "            print(f\"         🔥 エンド陳列・プロモーション強化\")\n",
    "            print(f\"         🔥 欠品リスク最大注意\")\n",
    "        elif row['年平均成長率'] > 20:\n",
    "            print(f\"         ⭐ 高成長商品: フェイス数を1.5倍に、在庫を2倍に増量\")\n",
    "            print(f\"         ⭐ 関連商品と併売\")\n",
    "        else:\n",
    "            pass\n",
    "            print(f\"         ✅ 成長商品: フェイス数を+20%、在庫を+50%増量\")\n",
    "            print(f\"         ✅ 成長要因を分析・他商品に応用\")\n",
    "\n",
    "else:\n",
    "    pass\n",
    "    print(\"   （該当商品なし）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📉 衰退商品TOP 10\n",
    "\n",
    "print(f\"\\n\\n📉 衰退商品 TOP 10（統計的に有意なトレンド）\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "if len(decreasing) > 0:\n",
    "    bottom_decline = decreasing.nsmallest(10, '年平均成長率')\n",
    "    \n",
    "    print(f\"\\n{'商品名':<40} {'年平均成長率':>10} {'タウ':>8} {'p値':>10} {'平均日販':>12} {'総売上':>15}\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    for _, row in bottom_decline.iterrows():\n",
    "        product = row['商品名'][:38]\n",
    "        cagr = f\"{row['年平均成長率']:+.1f}%\"\n",
    "        tau = f\"{row['Kendallのタウ']:.3f}\"\n",
    "        p_val = f\"{row['p値']:.4f}\"\n",
    "        avg_sales = f\"¥{row['平均日販']:,.0f}\"\n",
    "        total = f\"¥{row['総売上']:,.0f}\"\n",
    "        \n",
    "        print(f\"{product:<40} {cagr:>10} {tau:>8} {p_val:>10} {avg_sales:>12} {total:>15}\")\n",
    "    \n",
    "    print(f\"\\n⚠️ 衰退商品の対策\")\n",
    "    print(\"-\" * 120)\n",
    "    for _, row in bottom_decline.head(5).iterrows():\n",
    "        print(f\"\\n   📦 {row['商品名'][:50]}\")\n",
    "        print(f\"      衰退率: CAGR {row['年平均成長率']:+.1f}% (統計的有意性: p={row['p値']:.4f})\")\n",
    "        print(f\"      推奨アクション:\")\n",
    "        \n",
    "        if row['年平均成長率'] < -50:\n",
    "            print(f\"         🔴 急速衰退: SKU削減を検討、代替商品への切替\")\n",
    "            print(f\"         🔴 在庫を最小限に、発注頻度を下げる\")\n",
    "            print(f\"         🔴 廃棄リスク最大注意\")\n",
    "        elif row['年平均成長率'] < -20:\n",
    "            print(f\"         🟡 衰退傾向: プロモーションでテコ入れ\")\n",
    "            print(f\"         🟡 価格見直し、セット販売を試行\")\n",
    "        else:\n",
    "            pass\n",
    "            print(f\"         📊 緩やかな衰退: 陳列位置の改善\")\n",
    "            print(f\"         📊 POPで訴求強化\")\n",
    "\n",
    "else:\n",
    "    pass\n",
    "    print(\"   （該当商品なし）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 トレンド分析の可視化\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(22, 12))\n",
    "\n",
    "# 1. トレンド分類の分布\n",
    "ax1 = axes[0, 0]\n",
    "trend_counts = trends_df['トレンド'].value_counts()\n",
    "colors_trend = {'increasing': '#2ECC71', 'decreasing': '#E74C3C', 'no trend': '#95A5A6'}\n",
    "colors = [colors_trend.get(x, 'gray') for x in trend_counts.index]\n",
    "trend_counts.plot(kind='pie', ax=ax1, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_ylabel('', fontproperties=JP_FP)\n",
    "ax1.set_title('トレンド Classification Distribution', fontsize=14, fontproperties=JP_FP)\n",
    "\n",
    "# 2. CAGR分布\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(trends_df['年平均成長率'].dropna(), bins=50, color='#3498DB', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Growth')\n",
    "ax2.axvline(x=trends_df['年平均成長率'].median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
    "ax2.set_xlabel('CAGR (%)', fontsize=12, fontproperties=JP_FP)\n",
    "ax2.set_ylabel('Frequency', fontsize=12, fontproperties=JP_FP)\n",
    "ax2.set_title('CAGR Distribution', fontsize=14, fontproperties=JP_FP)\n",
    "ax2.legend(prop=JP_FP)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. 平均日販 vs CAGR（散布図）\n",
    "ax3 = axes[0, 2]\n",
    "scatter_data = trends_df.nlargest(100, '総売上')\n",
    "colors_scatter = scatter_data['トレンド'].map(colors_trend)\n",
    "ax3.scatter(scatter_data['平均日販'], scatter_data['年平均成長率'], \n",
    "           c=colors_scatter, s=100, alpha=0.6, edgecolors='black')\n",
    "ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Avg Daily Sales (JPY)', fontsize=12, fontproperties=JP_FP)\n",
    "ax3.set_ylabel('CAGR (%)', fontsize=12, fontproperties=JP_FP)\n",
    "ax3.set_title('日次 Sales vs Growth Rate (TOP 100)', fontsize=14, fontproperties=JP_FP)\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. 成長商品TOP 10のCAGR\n",
    "ax4 = axes[1, 0]\n",
    "if len(increasing) > 0:\n",
    "    top10_growth = increasing.nlargest(10, '年平均成長率')\n",
    "    product_names_short = [name[:20] + '...' if len(name) > 20 else name for name in top10_growth['商品名']]\n",
    "    ax4.barh(range(len(top10_growth)), top10_growth['年平均成長率'], color='#2ECC71', edgecolor='black')\n",
    "    ax4.set_yticks(range(len(top10_growth)))\n",
    "    ax4.set_yticklabels(product_names_short, fontsize=9)\n",
    "    ax4.set_xlabel('CAGR (%)', fontsize=12, fontproperties=JP_FP)\n",
    "    ax4.set_title('TOP 10 Growing Products', fontsize=14, fontproperties=JP_FP)\n",
    "    ax4.invert_yaxis()\n",
    "    ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 5. 衰退商品TOP 10のCAGR\n",
    "ax5 = axes[1, 1]\n",
    "if len(decreasing) > 0:\n",
    "    bottom10_decline = decreasing.nsmallest(10, '年平均成長率')\n",
    "    product_names_short = [name[:20] + '...' if len(name) > 20 else name for name in bottom10_decline['商品名']]\n",
    "    ax5.barh(range(len(bottom10_decline)), bottom10_decline['年平均成長率'], color='#E74C3C', edgecolor='black')\n",
    "    ax5.set_yticks(range(len(bottom10_decline)))\n",
    "    ax5.set_yticklabels(product_names_short, fontsize=9)\n",
    "    ax5.set_xlabel('CAGR (%)', fontsize=12, fontproperties=JP_FP)\n",
    "    ax5.set_title('TOP 10 Declining Products', fontsize=14, fontproperties=JP_FP)\n",
    "    ax5.invert_yaxis()\n",
    "    ax5.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 6. Kendallのタウ分布\n",
    "ax6 = axes[1, 2]\n",
    "ax6.hist(trends_df['Kendallのタウ'], bins=50, color='#9B59B6', edgecolor='black', alpha=0.7)\n",
    "ax6.axvline(x=0, color='red', linestyle='--', linewidth=2, label='No Correlation')\n",
    "ax6.set_xlabel('Kendall Tau', fontsize=12, fontproperties=JP_FP)\n",
    "ax6.set_ylabel('Frequency', fontsize=12, fontproperties=JP_FP)\n",
    "ax6.set_title('Kendall Tau Distribution', fontsize=14, fontproperties=JP_FP)\n",
    "ax6.legend(prop=JP_FP)\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ トレンド検知・成長率分析完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🚫 【機能3】欠品検知・機会損失定量化\n",
    "\n",
    "## 過去の欠品パターンから損失額を推定\n",
    "\n",
    "### 欠品検知アルゴリズム\n",
    "1. **売上ゼロ日の検出** - 売上が0円の日を欠品候補とする\n",
    "2. **異常な売上減少** - 平均日販の50%以下の日を欠品疑いとする\n",
    "3. **連続欠品の検出** - 2日以上連続で売上ゼロ\n",
    "4. **季節性を考慮** - 同曜日・同月の平均と比較\n",
    "\n",
    "### 機会損失の定量化\n",
    "```\n",
    "機会損失 = 予想売上 - 実際売上\n",
    "予想売上 = (直近7日平均 + 前年同日) ÷ 2\n",
    "```\n",
    "\n",
    "### 欠品コスト\n",
    "- **直接損失**: 販売できなかった売上\n",
    "- **間接損失**: 顧客の店舗離れ（推定20%）\n",
    "- **合計損失**: 直接損失 × 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚫 欠品検知・機会損失定量化エンジン\n",
    "\n",
    "print(\"\\n🚫 欠品検知・機会損失定量化\\n\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# 商品別の日次売上データ\n",
    "stockout_analysis = []\n",
    "\n",
    "print(\"\\n⏳ 商品別欠品分析中...\")\n",
    "\n",
    "for product in my_df['商品名'].unique():\n",
    "    product_data = my_df[my_df['商品名'] == product].copy()\n",
    "    \n",
    "    # 日次集計\n",
    "    daily = product_data.groupby('日付').agg({\n",
    "        '売上金額': 'sum',\n",
    "        '売上数量': 'sum',\n",
    "        '昨年同日_売上': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    if len(daily) < 7:\n",
    "        continue\n",
    "    \n",
    "    # 平均日販\n",
    "    avg_sales = daily['売上金額'].mean()\n",
    "    \n",
    "    if avg_sales <= 0:\n",
    "        continue\n",
    "    \n",
    "    # 欠品候補の検出\n",
    "    # 1. 売上ゼロ日\n",
    "    zero_sales_days = daily[daily['売上金額'] == 0]\n",
    "    \n",
    "    # 2. 異常な売上減少（平均の50%以下）\n",
    "    low_sales_days = daily[daily['売上金額'] < avg_sales * 0.5]\n",
    "    \n",
    "    # 3. 移動平均からの大幅乖離\n",
    "    daily['MA7'] = daily['売上金額'].rolling(window=7, min_periods=1).mean()\n",
    "    severe_drops = daily[daily['売上金額'] < daily['MA7'] * 0.3]\n",
    "    \n",
    "    # 欠品疑い日数\n",
    "    suspected_stockout_days = pd.concat([zero_sales_days, severe_drops]).drop_duplicates()\n",
    "    \n",
    "    if len(suspected_stockout_days) == 0:\n",
    "        continue\n",
    "    \n",
    "    # 機会損失の計算\n",
    "    opportunity_loss = 0\n",
    "    \n",
    "    for _, day in suspected_stockout_days.iterrows():\n",
    "        date = day['日付']\n",
    "        actual_sales = day['売上金額']\n",
    "        \n",
    "        # 予想売上の推定\n",
    "        # 方法1: 直近7日平均\n",
    "        recent_avg = daily[daily['日付'] < date].tail(7)['売上金額'].mean()\n",
    "        \n",
    "        # 方法2: 前年同日\n",
    "        last_year = day['昨年同日_売上']\n",
    "        \n",
    "        # 予想売上 = (直近平均 + 前年) / 2\n",
    "        if pd.notna(last_year) and last_year > 0:\n",
    "            expected_sales = (recent_avg + last_year) / 2\n",
    "        else:\n",
    "            pass\n",
    "            expected_sales = recent_avg\n",
    "        \n",
    "        # 機会損失\n",
    "        loss = max(0, expected_sales - actual_sales)\n",
    "        opportunity_loss += loss\n",
    "    \n",
    "    # 間接損失を加味（顧客離れ効果 +20%）\n",
    "    total_loss = opportunity_loss * 1.2\n",
    "    \n",
    "    stockout_analysis.append({\n",
    "        '商品名': product,\n",
    "        '欠品疑い日数': len(suspected_stockout_days),\n",
    "        'ゼロ売上日数': len(zero_sales_days),\n",
    "        '総販売日数': len(daily),\n",
    "        '欠品率': len(suspected_stockout_days) / len(daily) * 100,\n",
    "        '平均日販': avg_sales,\n",
    "        '直接損失': opportunity_loss,\n",
    "        '総損失': total_loss,\n",
    "        '月間損失推定': total_loss / len(daily) * 30\n",
    "    })\n",
    "\n",
    "stockout_df = pd.DataFrame(stockout_analysis)\n",
    "stockout_df = stockout_df[stockout_df['欠品疑い日数'] > 0].sort_values('総損失', ascending=False)\n",
    "\n",
    "print(f\"✅ 欠品分析完了: {len(stockout_df)}商品で欠品疑いを検出\")\n",
    "\n",
    "# サマリー\n",
    "total_opportunity_loss = stockout_df['総損失'].sum()\n",
    "total_stockout_days = stockout_df['欠品疑い日数'].sum()\n",
    "avg_stockout_rate = stockout_df['欠品率'].mean()\n",
    "\n",
    "print(f\"\\n📊 欠品分析サマリー\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"   欠品疑い商品数:   {len(stockout_df)}商品\")\n",
    "print(f\"   総欠品疑い日数:   {total_stockout_days:.0f}日\")\n",
    "print(f\"   平均欠品率:       {avg_stockout_rate:.1f}%\")\n",
    "print(f\"   総機会損失:       ¥{total_opportunity_loss:,.0f}\")\n",
    "print(f\"   月間損失推定:     ¥{stockout_df['月間損失推定'].sum():,.0f}\")\n",
    "print(f\"   年間損失推定:     ¥{stockout_df['月間損失推定'].sum() * 12:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚫 欠品リスクTOP 20\n",
    "\n",
    "print(f\"\\n\\n🚫 欠品リスクTOP 20商品\")\n",
    "print(\"=\" * 130)\n",
    "\n",
    "if len(stockout_df) > 0:\n",
    "    top20_stockout = stockout_df.head(20)\n",
    "    \n",
    "    print(f\"\\n{'商品名':<40} {'欠品日数':>10} {'欠品率':>10} {'平均日販':>12} {'総損失':>15} {'月間損失':>15}\")\n",
    "    print(\"=\" * 130)\n",
    "    \n",
    "    for _, row in top20_stockout.iterrows():\n",
    "        product = row['商品名'][:38]\n",
    "        days = f\"{row['欠品疑い日数']:.0f}日\"\n",
    "        rate = f\"{row['欠品率']:.1f}%\"\n",
    "        avg_sales = f\"¥{row['平均日販']:,.0f}\"\n",
    "        total_loss = f\"¥{row['総損失']:,.0f}\"\n",
    "        monthly_loss = f\"¥{row['月間損失推定']:,.0f}\"\n",
    "        \n",
    "        print(f\"{product:<40} {days:>10} {rate:>10} {avg_sales:>12} {total_loss:>15} {monthly_loss:>15}\")\n",
    "    \n",
    "    # 詳細対策\n",
    "    print(f\"\\n\\n💡 欠品対策の優先順位\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    for rank, (_, row) in enumerate(top20_stockout.head(5).iterrows(), 1):\n",
    "        print(f\"\\n【第{rank}位】 {row['商品名'][:50]}\")\n",
    "        print(\"-\" * 120)\n",
    "        print(f\"   欠品日数: {row['欠品疑い日数']:.0f}日 / {row['総販売日数']:.0f}日 (欠品率 {row['欠品率']:.1f}%)\")\n",
    "        print(f\"   平均日販: ¥{row['平均日販']:,.0f}\")\n",
    "        print(f\"   機会損失: ¥{row['総損失']:,.0f} (月間推定 ¥{row['月間損失推定']:,.0f})\")\n",
    "        \n",
    "        print(f\"\\n   🎯 推奨対策:\")\n",
    "        \n",
    "        if row['欠品率'] > 20:\n",
    "            print(f\"      🔴 深刻な欠品: 緊急対応が必要\")\n",
    "            print(f\"         1. 発注頻度を毎日に変更\")\n",
    "            print(f\"         2. 安全在庫を現在の3倍に設定\")\n",
    "            print(f\"         3. 複数仕入先の確保を検討\")\n",
    "            print(f\"         4. 代替商品の準備\")\n",
    "        elif row['欠品率'] > 10:\n",
    "            print(f\"      🟡 高頻度欠品: 改善が必要\")\n",
    "            print(f\"         1. 発注頻度を週3-4回に変更\")\n",
    "            print(f\"         2. 安全在庫を現在の2倍に設定\")\n",
    "            print(f\"         3. 発注アラートの設定\")\n",
    "        else:\n",
    "            pass\n",
    "            print(f\"      📊 散発的欠品: 監視強化\")\n",
    "            print(f\"         1. 発注頻度を週2回に変更\")\n",
    "            print(f\"         2. 安全在庫を+50%増量\")\n",
    "            print(f\"         3. 欠品パターンの分析（曜日・イベント）\")\n",
    "        \n",
    "        # ROI計算\n",
    "        additional_inventory_cost = row['平均日販'] * 2 * 0.3  # 在庫2倍、コスト率30%\n",
    "        monthly_benefit = row['月間損失推定']\n",
    "        roi = (monthly_benefit - additional_inventory_cost) / additional_inventory_cost * 100\n",
    "        \n",
    "        print(f\"\\n   💰 ROI試算:\")\n",
    "        print(f\"      在庫増量コスト: ¥{additional_inventory_cost:,.0f}/月\")\n",
    "        print(f\"      欠品削減効果:   ¥{monthly_benefit:,.0f}/月\")\n",
    "        print(f\"      ROI:            {roi:+.0f}%\")\n",
    "        print(f\"      投資回収期間:   即時回収（初月から黒字）\" if roi > 0 else f\"      ⚠️ 要検討\")\n",
    "\n",
    "else:\n",
    "    pass\n",
    "    print(\"   ✅ 欠品リスクが検出されませんでした。excellent！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🏆 【機能4】ベストプラクティス抽出・横展開推奨\n",
    "\n",
    "## トップ店舗の成功要因を自動分析\n",
    "\n",
    "### 分析手法\n",
    "1. **店舗ランキング** - 売上、客数、客単価、成長率で評価\n",
    "2. **TOP vs 自店舗の差分分析** - 何が違うのかを定量化\n",
    "3. **成功商品の抽出** - トップ店で売れているが自店で低調な商品\n",
    "4. **ベストプラクティスの特定** - 時間帯、陳列、販促の違い\n",
    "5. **横展開の優先順位** - 効果×実現性で優先順位付け\n",
    "\n",
    "### ベンチマーク指標\n",
    "- 売上効率（売上/面積）\n",
    "- 客単価\n",
    "- 来店頻度\n",
    "- 商品回転率\n",
    "- 廃棄率（推定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏆 ベストプラクティス抽出エンジン\n",
    "\n",
    "print(\"\\n🏆 ベストプラクティス抽出・横展開推奨\\n\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# 全店舗の実績集計\n",
    "store_performance = []\n",
    "\n",
    "for store in stores:\n",
    "    store_data = df_enriched[df_enriched['店舗'] == store]\n",
    "    \n",
    "    # 日次集計\n",
    "    daily_store = store_data.groupby('日付').agg({\n",
    "        '売上金額': 'sum',\n",
    "        '売上数量': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    if len(daily_store) == 0:\n",
    "        continue\n",
    "    \n",
    "    # 基本指標\n",
    "    total_sales = daily_store['売上金額'].sum()\n",
    "    avg_daily_sales = daily_store['売上金額'].mean()\n",
    "    total_quantity = daily_store['売上数量'].sum()\n",
    "    avg_customer_spend = total_sales / total_quantity if total_quantity > 0 else 0\n",
    "    \n",
    "    # 成長率（前半 vs 後半）\n",
    "    first_half = daily_store.head(len(daily_store)//2)['売上金額'].mean()\n",
    "    second_half = daily_store.tail(len(daily_store)//2)['売上金額'].mean()\n",
    "    growth_rate = (second_half - first_half) / first_half * 100 if first_half > 0 else 0\n",
    "    \n",
    "    # 安定性（変動係数）\n",
    "    cv = daily_store['売上金額'].std() / daily_store['売上金額'].mean() if daily_store['売上金額'].mean() > 0 else 0\n",
    "    \n",
    "    store_performance.append({\n",
    "        '店舗': store,\n",
    "        '総売上': total_sales,\n",
    "        '平均日商': avg_daily_sales,\n",
    "        '総販売数量': total_quantity,\n",
    "        '客単価': avg_customer_spend,\n",
    "        '成長率': growth_rate,\n",
    "        '変動係数': cv,\n",
    "        'データ日数': len(daily_store)\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(store_performance)\n",
    "\n",
    "# 総合スコアの計算（売上60% + 成長率20% + 安定性20%）\n",
    "performance_df['売上スコア'] = (performance_df['総売上'] / performance_df['総売上'].max()) * 60\n",
    "performance_df['成長スコア'] = (performance_df['成長率'] / performance_df['成長率'].max()) * 20 if performance_df['成長率'].max() > 0 else 0\n",
    "performance_df['安定性スコア'] = (1 - performance_df['変動係数'] / performance_df['変動係数'].max()) * 20 if performance_df['変動係数'].max() > 0 else 0\n",
    "performance_df['総合スコア'] = performance_df['売上スコア'] + performance_df['成長スコア'] + performance_df['安定性スコア']\n",
    "\n",
    "performance_df = performance_df.sort_values('総合スコア', ascending=False)\n",
    "performance_df['ランク'] = range(1, len(performance_df) + 1)\n",
    "\n",
    "print(f\"\\n📊 店舗総合ランキング\")\n",
    "print(\"=\" * 130)\n",
    "print(f\"{'ランク':<6} {'店舗':<30} {'総売上':>15} {'平均日商':>12} {'客単価':>10} {'成長率':>10} {'総合スコア':>12}\")\n",
    "print(\"=\" * 130)\n",
    "\n",
    "for _, row in performance_df.iterrows():\n",
    "    rank = row['ランク']\n",
    "    store = row['店舗'][:28]\n",
    "    total = f\"¥{row['総売上']:,.0f}\"\n",
    "    daily = f\"¥{row['平均日商']:,.0f}\"\n",
    "    spend = f\"¥{row['客単価']:.0f}\"\n",
    "    growth = f\"{row['成長率']:+.1f}%\"\n",
    "    score = f\"{row['総合スコア']:.1f}\"\n",
    "    \n",
    "    marker = \"★\" if store == MY_STORE[:28] else \"\"\n",
    "    \n",
    "    print(f\"{rank:<6} {store:<30} {total:>15} {daily:>12} {spend:>10} {growth:>10} {score:>12} {marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏆 トップ店舗のベストプラクティス分析\n",
    "\n",
    "top_store = performance_df.iloc[0]['店舗']\n",
    "my_rank = performance_df[performance_df['店舗'] == MY_STORE]['ランク'].values[0]\n",
    "\n",
    "print(f\"\\n\\n🏆 トップ店舗: {top_store}\")\n",
    "print(f\"   自店舗: {MY_STORE} (ランク: {my_rank}位/{len(performance_df)}店舗)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "if top_store != MY_STORE:\n",
    "    # トップ店舗のデータ\n",
    "    top_store_data = df_enriched[df_enriched['店舗'] == top_store]\n",
    "    \n",
    "    # 商品別売上（トップ店 vs 自店）\n",
    "    top_product_sales = top_store_data.groupby('商品名')['売上金額'].sum().sort_values(ascending=False)\n",
    "    my_product_sales = my_df.groupby('商品名')['売上金額'].sum()\n",
    "    \n",
    "    # 差分分析\n",
    "    comparison = pd.DataFrame({\n",
    "        'トップ店売上': top_product_sales,\n",
    "        '自店売上': my_product_sales\n",
    "    }).fillna(0)\n",
    "    \n",
    "    comparison['差分'] = comparison['トップ店売上'] - comparison['自店売上']\n",
    "    comparison['比率'] = comparison['自店売上'] / comparison['トップ店売上']\n",
    "    comparison = comparison[comparison['トップ店売上'] > 0].sort_values('差分', ascending=False)\n",
    "    \n",
    "    # トップ店で売れているが自店で弱い商品\n",
    "    underperforming = comparison[comparison['比率'] < 0.7].head(15)\n",
    "    \n",
    "    print(f\"\\n🎯 横展開推奨商品 TOP 15\")\n",
    "    print(\"   （トップ店で好調だが自店で弱い商品）\")\n",
    "    print(\"-\" * 120)\n",
    "    print(f\"\\n{'商品名':<40} {'トップ店売上':>15} {'自店売上':>15} {'差分':>15} {'比率':>8}\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    for product, row in underperforming.iterrows():\n",
    "        prod_name = product[:38]\n",
    "        top_sales = f\"¥{row['トップ店売上']:,.0f}\"\n",
    "        my_sales = f\"¥{row['自店売上']:,.0f}\"\n",
    "        diff = f\"¥{row['差分']:,.0f}\"\n",
    "        ratio = f\"{row['比率']*100:.0f}%\"\n",
    "        \n",
    "        print(f\"{prod_name:<40} {top_sales:>15} {my_sales:>15} {diff:>15} {ratio:>8}\")\n",
    "    \n",
    "    # 具体的なアクションプラン\n",
    "    print(f\"\\n\\n💡 ベストプラクティス横展開プラン\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    total_gap = underperforming['差分'].sum()\n",
    "    \n",
    "    print(f\"\\n   📊 ギャップ分析\")\n",
    "    print(f\"      トップ店との売上差: ¥{total_gap:,.0f}\")\n",
    "    print(f\"      月間機会損失:       ¥{total_gap * 30 / comparison.sum()['トップ店売上']:,.0f}\")\n",
    "    print(f\"      年間機会損失:       ¥{total_gap * 365 / comparison.sum()['トップ店売上']:,.0f}\")\n",
    "    \n",
    "    print(f\"\\n   🎯 優先アクション（効果×実現性で選定）\")\n",
    "    \n",
    "    for rank, (product, row) in enumerate(underperforming.head(5).iterrows(), 1):\n",
    "        print(f\"\\n   【第{rank}位】 {product[:50]}\")\n",
    "        print(f\"      現状: 自店 ¥{row['自店売上']:,.0f} / トップ店 ¥{row['トップ店売上']:,.0f} ({row['比率']*100:.0f}%)\")\n",
    "        print(f\"      機会: ¥{row['差分']:,.0f}/期間\")\n",
    "        \n",
    "        print(f\"\\n      実施ステップ:\")\n",
    "        print(f\"         1. トップ店の陳列・販促を視察\")\n",
    "        print(f\"         2. フェイス数を現在の1.5倍に増量\")\n",
    "        print(f\"         3. エンド陳列または目立つ位置に配置\")\n",
    "        print(f\"         4. POP・試食などの販促実施\")\n",
    "        print(f\"         5. 1週間後に効果を検証\")\n",
    "        \n",
    "        # ROI推定\n",
    "        additional_cost = row['トップ店売上'] * 0.1  # 販促コスト10%\n",
    "        expected_benefit = row['差分'] * 0.5  # 50%改善を想定\n",
    "        roi = (expected_benefit - additional_cost) / additional_cost * 100\n",
    "        \n",
    "        print(f\"\\n      ROI推定:\")\n",
    "        print(f\"         投資額:   ¥{additional_cost:,.0f} (販促・陳列変更)\")\n",
    "        print(f\"         期待効果: ¥{expected_benefit:,.0f} (50%改善想定)\")\n",
    "        print(f\"         ROI:      {roi:+.0f}%\")\n",
    "\n",
    "else:\n",
    "    pass\n",
    "    print(f\"\\n   🎉 おめでとうございます！あなたの店舗がトップです！\")\n",
    "    print(f\"   この成功を他店に横展開しましょう\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🛒 【機能5】マーケットバスケット分析・クロスセル提案\n",
    "\n",
    "## Aprioriアルゴリズムで商品間の関連性を発見\n",
    "\n",
    "### アソシエーションルール\n",
    "```\n",
    "A → B\n",
    "商品Aを買った人は商品Bも買う傾向がある\n",
    "```\n",
    "\n",
    "### 評価指標\n",
    "1. **Support（支持度）**: A ∩ B の出現頻度\n",
    "2. **Confidence（確信度）**: P(B|A) = P(A ∩ B) / P(A)\n",
    "3. **Lift（リフト値）**: Confidence / P(B)\n",
    "   - Lift > 1: 正の相関（一緒に買われる）\n",
    "   - Lift = 1: 独立\n",
    "   - Lift < 1: 負の相関（一緒に買われない）\n",
    "\n",
    "### 活用方法\n",
    "- 併売陳列（関連商品を隣に配置）\n",
    "- セット販売\n",
    "- クロスセル提案\n",
    "- POPでの訴求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛒 マーケットバスケット分析エンジン\n",
    "\n",
    "if MLXTEND_AVAILABLE:\n",
    "    print(\"\\n🛒 マーケットバスケット分析・クロスセル提案\\n\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    print(\"\\n⏳ トランザクションデータ準備中...\")\n",
    "    \n",
    "    # 日付×商品のトランザクション行列作成\n",
    "    # 各日に購入された商品のリストを作成\n",
    "    transactions = my_df.groupby('日付')['商品名'].apply(list).tolist()\n",
    "    \n",
    "    print(f\"   トランザクション数: {len(transactions)}件\")\n",
    "    print(f\"   ユニーク商品数: {my_df['商品名'].nunique()}商品\")\n",
    "    \n",
    "    # One-Hot Encoding\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    basket_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    print(f\"\\n⏳ Aprioriアルゴリズム実行中...\")\n",
    "    \n",
    "    # Aprioriで頻出アイテムセットを抽出\n",
    "    frequent_itemsets = apriori(basket_df, min_support=0.01, use_colnames=True)\n",
    "    \n",
    "    print(f\"   頻出アイテムセット: {len(frequent_itemsets)}個\")\n",
    "    \n",
    "    if len(frequent_itemsets) > 0:\n",
    "        # アソシエーションルールの生成\n",
    "        print(f\"\\n⏳ アソシエーションルール生成中...\")\n",
    "        \n",
    "        rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "        \n",
    "        print(f\"   アソシエーションルール: {len(rules)}個\")\n",
    "        \n",
    "        if len(rules) > 0:\n",
    "            # Lift値で並び替え\n",
    "            rules = rules.sort_values('lift', ascending=False)\n",
    "            \n",
    "            # Confidenceが高い（確実性が高い）ルールを抽出\n",
    "            strong_rules = rules[rules['confidence'] > 0.3]\n",
    "            \n",
    "            print(f\"\\n📊 強いアソシエーションルール TOP 20\")\n",
    "            print(\"   （Confidence > 30%, Lift値順）\")\n",
    "            print(\"=\" * 130)\n",
    "            print(f\"\\n{'商品A':<35} {'→':<3} {'商品B':<35} {'Support':>10} {'Confidence':>12} {'Lift':>8}\")\n",
    "            print(\"=\" * 130)\n",
    "            \n",
    "            for _, rule in strong_rules.head(20).iterrows():\n",
    "                antecedent = ', '.join(list(rule['antecedents']))[:33]\n",
    "                consequent = ', '.join(list(rule['consequents']))[:33]\n",
    "                support = f\"{rule['support']*100:.1f}%\"\n",
    "                confidence = f\"{rule['confidence']*100:.1f}%\"\n",
    "                lift = f\"{rule['lift']:.2f}\"\n",
    "                \n",
    "                print(f\"{antecedent:<35} {'→':<3} {consequent:<35} {support:>10} {confidence:>12} {lift:>8}\")\n",
    "            \n",
    "            # クロスセル提案\n",
    "            print(f\"\\n\\n💡 クロスセル提案（実践的な活用方法）\")\n",
    "            print(\"=\" * 120)\n",
    "            \n",
    "            for rank, (_, rule) in enumerate(strong_rules.head(10).iterrows(), 1):\n",
    "                antecedent_list = list(rule['antecedents'])\n",
    "                consequent_list = list(rule['consequents'])\n",
    "                \n",
    "                print(f\"\\n【提案{rank}】\")\n",
    "                print(f\"   IF: {', '.join(antecedent_list[:2])}\")\n",
    "                print(f\"   THEN: {', '.join(consequent_list[:2])}\")\n",
    "                print(f\"   確信度: {rule['confidence']*100:.1f}% (Lift: {rule['lift']:.2f}倍)\")\n",
    "                \n",
    "                print(f\"\\n   実施方法:\")\n",
    "                print(f\"      1. 陳列: {antecedent_list[0]}の隣に{consequent_list[0]}を配置\")\n",
    "                print(f\"      2. POP: 「{antecedent_list[0]}と一緒にいかがですか？」\")\n",
    "                print(f\"      3. セット販売: 2商品で○○円のセット企画\")\n",
    "                print(f\"      4. レジ提案: 「{consequent_list[0]}はお求めですか？」\")\n",
    "                \n",
    "                # 期待効果の試算\n",
    "                antecedent_sales = my_df[my_df['商品名'].isin(antecedent_list)]['売上金額'].sum()\n",
    "                consequent_price = my_df[my_df['商品名'].isin(consequent_list)]['売上金額'].mean()\n",
    "                \n",
    "                # 現在のクロスセル率\n",
    "                current_rate = rule['support'] / (basket_df[antecedent_list[0]].sum() / len(basket_df))\n",
    "                \n",
    "                # 施策後の期待クロスセル率（+20%向上を想定）\n",
    "                expected_rate = current_rate * 1.2\n",
    "                \n",
    "                # 期待増収\n",
    "                expected_revenue = (antecedent_sales / len(basket_df)) * (expected_rate - current_rate) * consequent_price\n",
    "                \n",
    "                print(f\"\\n   期待効果:\")\n",
    "                print(f\"      現在のクロスセル率: {current_rate*100:.1f}%\")\n",
    "                print(f\"      施策後の目標:       {expected_rate*100:.1f}% (+20%)\")\n",
    "                print(f\"      期待増収:           ¥{expected_revenue:,.0f}/期間\")\n",
    "                print(f\"      月間増収推定:       ¥{expected_revenue * 30:,.0f}\")\n",
    "            \n",
    "            # ネットワーク図の作成\n",
    "            print(f\"\\n\\n🕸️ 商品関連ネットワーク図\")\n",
    "            print(\"-\" * 120)\n",
    "            \n",
    "            # TOP 30ルールでネットワーク作成\n",
    "            top_rules = strong_rules.head(30)\n",
    "            \n",
    "            G = nx.DiGraph()\n",
    "            \n",
    "            for _, rule in top_rules.iterrows():\n",
    "                for ant in rule['antecedents']:\n",
    "                    for con in rule['consequents']:\n",
    "                        G.add_edge(ant[:20], con[:20], weight=rule['lift'])\n",
    "            \n",
    "            if len(G.nodes()) > 0:\n",
    "                plt.figure(figsize=(20, 16))\n",
    "                \n",
    "                # レイアウト\n",
    "                pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "                \n",
    "                # ノードの描画\n",
    "                nx.draw_networkx_nodes(G, pos, node_color='#4ECDC4', node_size=3000, alpha=0.8)\n",
    "                \n",
    "                # エッジの描画（太さ = Lift値）\n",
    "                edges = G.edges()\n",
    "                weights = [G[u][v]['weight'] for u, v in edges]\n",
    "                nx.draw_networkx_edges(G, pos, width=[w*2 for w in weights], \n",
    "                                      alpha=0.5, arrows=True, arrowsize=20,\n",
    "                                      edge_color='#95A5A6')\n",
    "                \n",
    "                # ラベルの描画\n",
    "                nx.draw_networkx_labels(G, pos, font_size=9, font_weight='bold')\n",
    "                \n",
    "                plt.title('Product Association Network (TOP 30 Rules)', \n",
    "                         fontsize=18, pad=20)\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"   📝 ネットワーク図の見方:\")\n",
    "                print(\"      - ノード: 商品\")\n",
    "                print(\"      - エッジ: 関連性（矢印の方向 = A→B）\")\n",
    "                print(\"      - 太さ: Lift値（太いほど強い関連）\")\n",
    "        else:\n",
    "            pass\n",
    "            print(\"   ⚠️ 有意なアソシエーションルールが見つかりませんでした\")\n",
    "    else:\n",
    "        pass\n",
    "        print(\"   ⚠️ 頻出アイテムセットが見つかりませんでした\")\n",
    "        print(\"   min_supportを下げるか、データ量を増やしてください\")\n",
    "\n",
    "else:\n",
    "    pass\n",
    "    print(\"\\n⚠️ mlxtendがインストールされていないため、この機能はスキップされます\")\n",
    "    print(\"   pip install mlxtend でインストールしてください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📝 Phase 3実装まとめ\n",
    "\n",
    "## ✅ 実装完了した5つの高度な分析機能\n",
    "\n",
    "1. **PyCaret自動特徴量選択** - SHAP値で重要特徴量を自動抽出、モデルの解釈性向上\n",
    "2. **トレンド検知・成長率分析** - Mann-Kendall検定で統計的にトレンドを検証\n",
    "3. **欠品検知・機会損失定量化** - 過去の欠品パターンから年間損失額を推定\n",
    "4. **ベストプラクティス抽出** - トップ店舗の成功要因を分析・横展開推奨\n",
    "5. **マーケットバスケット分析** - Aprioriアルゴリズムで商品間の関連性を発見\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Phase 3の成果\n",
    "\n",
    "### Phase 1・2との違い\n",
    "- **Phase 1**: 「現状を把握する」（見える化）\n",
    "- **Phase 2**: 「問題を予防し、最適行動を導く」（最適化）\n",
    "- **Phase 3**: 「AIで売上を最大化する」（自動化・高度化）\n",
    "\n",
    "### 導入効果（想定）\n",
    "- 特徴量削減による学習時間: **-40%**\n",
    "- 欠品による機会損失: **年間数百万円を可視化**\n",
    "- ベストプラクティス横展開: **+5-10%の売上向上**\n",
    "- クロスセル施策: **+3-5%の客単価向上**\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 次のステップ（Phase 4）\n",
    "\n",
    "1. **C2. 時間帯別分析** - ピークタイムの最適化\n",
    "2. **G2. プロモーション効果測定** - キャンペーンROI分析\n",
    "3. **J1. What-ifシミュレーション** - 施策の事前評価\n",
    "4. **C4. クロスセル提案の自動化** - リアルタイムレコメンデーション\n",
    "5. **H2. モバイル対応レイアウト** - スマホ・タブレット最適化\n",
    "\n",
    "---\n",
    "\n",
    "**Phase 3により、店舗運営が「経験則」から「AIドリブン」に進化しました！** 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}